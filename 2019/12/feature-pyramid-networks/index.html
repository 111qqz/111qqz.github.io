<!doctype html><html lang=zh-cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta property="og:site_name" content="111qqz的小窝"><meta property="og:type" content="article"><meta property="og:image" content="https://111qqz.github.io/img/2.png"><meta property="twitter:image" content="https://111qqz.github.io/img/2.png"><meta name=title content="FPN:Feature Pyramid Networks 学习笔记"><meta property="og:title" content="FPN:Feature Pyramid Networks 学习笔记"><meta property="twitter:title" content="FPN:Feature Pyramid Networks 学习笔记"><meta name=description content><meta property="og:description" content><meta property="twitter:description" content><meta property="twitter:card" content="summary"><meta name=keyword content="ICPC,111qqz,商汤科技,hust,华中科技大学"><link rel="shortcut icon" href=/img/favicon.ico><title>FPN:Feature Pyramid Networks 学习笔记-111qqz的小窝</title><link rel=canonical href=/2019/12/feature-pyramid-networks/><link rel=stylesheet href=/css/iDisqus.min.css><link rel=stylesheet href=/css/bootstrap.min.css><link rel=stylesheet href=/css/hux-blog.min.css><link rel=stylesheet href=/css/syntax.css><link rel=stylesheet href=/css/zanshang.css><link href=//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css rel=stylesheet type=text/css><script src=/js/jquery.min.js></script><script src=/js/bootstrap.min.js></script><script src=/js/hux-blog.min.js></script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/styles/docco.min.css><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/highlight.min.js></script><script>hljs.initHighlightingOnLoad();</script><link rel=stylesheet href=/css/hux-blog.min.css><link rel=stylesheet href=/css/hux-blog.min-custom.css></head><nav class="navbar navbar-default navbar-custom navbar-fixed-top"><div class=container-fluid><div class="navbar-header page-scroll"><button type=button class=navbar-toggle>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span><span class=icon-bar></span><span class=icon-bar></span></button>
<a class=navbar-brand href=/>111qqz的小窝</a></div><div id=huxblog_navbar><div class=navbar-collapse><ul class="nav navbar-nav navbar-right"><li><a href=/>Home</a></li><li><a href=/categories/acm/>ACM-ICPC</a></li><li><a href=/categories/deep-learning/>深度学习</a></li><li><a href=/categories/mooc/>公开课</a></li><li><a href=/categories/%e5%85%b6%e4%bb%96/>其他</a></li><li><a href=/top/about/>ABOUT</a></li><li><a href=/search>SEARCH <img src=/img/search.png height=15 style=cursor:pointer alt=Search></a></li></ul></div></div></div></nav><script>var $body=document.body;var $toggle=document.querySelector('.navbar-toggle');var $navbar=document.querySelector('#huxblog_navbar');var $collapse=document.querySelector('.navbar-collapse');$toggle.addEventListener('click',handleMagic)
function handleMagic(e){if($navbar.className.indexOf('in')>0){$navbar.className=" ";setTimeout(function(){if($navbar.className.indexOf('in')<0){$collapse.style.height="0px"}},400)}else{$collapse.style.height="auto"
$navbar.className+=" in";}}</script><style type=text/css>header.intro-header{background-image:url(/img/2.png)}</style><header class=intro-header><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class=post-heading><div class=tags><a class=tag href=/tags/feature-pyramid-networks title=feature-pyramid-networks>feature-pyramid-networks</a>
<a class=tag href=/tags/fpn title=FPN>FPN</a></div><h1>FPN:Feature Pyramid Networks 学习笔记</h1><h2 class=subheading></h2><span class=meta>Posted by
111qqz
on
Sunday, December 8, 2019
<span id=/2019/12/feature-pyramid-networks/ class="leancloud_visitors meta_data_item" data-flag-title><span class=post-meta-item-icon><span class="octicon octicon-eye"></span></span><i class="fa fa-eye"></i><span class=old-visitors-count style=display:none></span><span class=leancloud-visitors-count></span></span><script src=https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js></script><script>AV.initialize("2dzJwxGKq4hbtg5R5NM8NTzJ-gzGzoHsz","RaYu8uGTiuiIjLISQppPVYWw");</script><script type=text/javascript>function showTime(Counter){var query=new AV.Query(Counter);var entries=[];var $visitors=$(".leancloud_visitors");$visitors.each(function(){entries.push($(this).attr("id").trim());});query.containedIn('url',entries);query.find().done(function(results){var COUNT_CONTAINER_REF='.leancloud-visitors-count';var OLD_COUNT_CONTAINER_REF='.old-visitors-count';for(var i=0;i<results.length;i++){var item=results[i];var url=item.get('url');var time=item.get('time');var element=document.getElementById(url);$(element).find(COUNT_CONTAINER_REF).text(time);}
for(var i=0;i<entries.length;i++){var url=entries[i];var element=document.getElementById(url);var countSpan=$(element).find(COUNT_CONTAINER_REF);if(countSpan.text()==''){var oldCountSpan=$(element).find(OLD_COUNT_CONTAINER_REF).text();if(oldCountSpan!=''){countSpan.text(0+parseInt(oldCountSpan));}else{countSpan.text(0);}}}}).fail(function(object,error){console.log("Error: "+error.code+" "+error.message);});}
function addCount(Counter){var $visitors=$(".leancloud_visitors");var url=$visitors.attr('id').trim();var title=$visitors.attr('data-flag-title').trim();var query=new AV.Query(Counter);query.equalTo("url",url);query.find({success:function(results){if(results.length>0){var counter=results[0];counter.fetchWhenSave(true);counter.increment("time");counter.save(null,{success:function(counter){var $element=$(document.getElementById(url));$element.find('.leancloud-visitors-count').text(counter.get('time'));},error:function(counter,error){console.log('Failed to save Visitor num, with error message: '+error.message);}});}else{var newcounter=new Counter();var acl=new AV.ACL();acl.setPublicReadAccess(true);acl.setPublicWriteAccess(true);newcounter.setACL(acl);newcounter.set("title",title);newcounter.set("url",url);var OLD_COUNT_CONTAINER_REF='.old-visitors-count';var $element=$(document.getElementById(url));var oldCountSpan=$element.find(OLD_COUNT_CONTAINER_REF).text();if(oldCountSpan!=''){newcounter.set("time",parseInt(oldCountSpan)+1);}else{newcounter.set("time",1);}
newcounter.save(null,{success:function(newcounter){var $element=$(document.getElementById(url));$element.find('.leancloud-visitors-count').text(newcounter.get('time'));},error:function(newcounter,error){console.log('Failed to create');}});}},error:function(error){console.log('Error:'+error.code+" "+error.message);}});}
$(function(){var Counter=AV.Object.extend("Counter");if($('.leancloud_visitors').length==1){addCount(Counter);}else{showTime(Counter);}});</script></span></div></div></div></div></header><article><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2
col-md-10 col-md-offset-1
post-container"><header><h2>TOC</h2></header><nav id=TableOfContents><ol><li><a href=#之前的工作>之前的工作</a><ol><li><a href=#featurized-image-pyramid>Featurized image pyramid</a></li><li><a href=#single-feature-map>Single feature map</a></li><li><a href=#pyramidal-feature-hierarchy>Pyramidal feature hierarchy</a></li></ol></li><li><a href=#feature-pyramid-networks>Feature Pyramid Networks</a></li><li><a href=#fpn-用于-faster-rcnn>FPN 用于 faster rcnn</a><ol><li><a href=#fpn-作用于rpn>FPN 作用于RPN</a></li><li><a href=#fpn-作用于fast-rcnn>FPN 作用于fast rcnn</a></li></ol></li><li><a href=#参考>参考</a></li></ol></nav><p>检测不同尺度的物体一直是计算机视觉领域中比较有挑战性的事情．我们先从之前的工作出发，并对比FPN比起之前的工作有哪些改进．</p><h2 id=之前的工作>之前的工作</h2><h3 id=featurized-image-pyramid>Featurized image pyramid</h3><p><img src=https://i.loli.net/2019/12/08/vhsEbJoYNBcMKdk.png alt="Featurized image pyramid.png"></p><p>思路是对于同一张图，生成不同的scale，然后每个scale的image单独去做检测．
这个方法是手工设计feautre时代的常用办法．
这个办法是比较显然的，也的确可以解决检测不同尺度物体的问题．
缺点非常明显&mldr;inference的速度几乎和scale的个数线性相关．
以及由于显存的开销，没办法做end-to-end 的training.</p><h3 id=single-feature-map>Single feature map</h3><p><img src=https://i.loli.net/2019/12/08/prs9x427mKRWv1o.png alt=single_feature_map.png></p><p>再之后，手工设计的feature逐渐被由CNN生成的feature取代了．
这种办法更加鲁棒，对image的一些变化不敏感．
但是如果只有一个scale 的图片去过这个feature map,只有最终的feature map去做predict..准确率不太行．．因此还是要与Featurized image pyramid一起．只是优化了得到feature 的部分．</p><h3 id=pyramidal-feature-hierarchy>Pyramidal feature hierarchy</h3><p>就..CNN本身就有显然的层次结构啊．．．
为什么不直接拿来用，而是提前scale image呢．．．</p><p><img src=https://i.loli.net/2019/12/08/vhsEbJoYNBcMKdk.png alt="Featurized image pyramid.png"></p><p>也就是选若干个feature map直接去做predict..
这个办法美滋滋，既有多个feature map保证了一定的准确率，同时也没有增加很多inference的cost.</p><p>SSD应该是率先使用这种方法的．
但是这种办法仍然有不足之处，就是低层的高分辨率的feature map的semantics 太弱了．．
这就导致说对小物体的检测效果不太理想．．．</p><p>那么该怎么办呢．．．这时候就该介绍FPN啦</p><h2 id=feature-pyramid-networks>Feature Pyramid Networks</h2><p><img src=https://i.loli.net/2019/12/08/WLNExRUl4ozFcIk.png alt=feature_pyramid_network.png></p><p>后面再更．</p><h2 id=fpn-用于-faster-rcnn>FPN 用于 faster rcnn</h2><p>FPN同时作用于RPN阶段和fast-rcnn detector</p><p>以下的代码实现出自　<a href=https://github.com/jwyang/fpn.pytorch>fpn.pytorch</a></p><h3 id=fpn-作用于rpn>FPN 作用于RPN</h3><p>感觉直接上代码比较容易理解</p><p>先看　整个网络的forward函数</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>

 <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>forward</span>(self, im_data, im_info, gt_boxes, num_boxes):
        batch_size <span style=color:#f92672>=</span> im_data<span style=color:#f92672>.</span>size(<span style=color:#ae81ff>0</span>)

        im_info <span style=color:#f92672>=</span> im_info<span style=color:#f92672>.</span>data
        gt_boxes <span style=color:#f92672>=</span> gt_boxes<span style=color:#f92672>.</span>data
        num_boxes <span style=color:#f92672>=</span> num_boxes<span style=color:#f92672>.</span>data

        <span style=color:#75715e># feed image data to base model to obtain base feature map</span>
        <span style=color:#75715e># Bottom-up</span>
        c1 <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>RCNN_layer0(im_data)
        c2 <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>RCNN_layer1(c1)
        c3 <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>RCNN_layer2(c2)
        c4 <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>RCNN_layer3(c3)
        c5 <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>RCNN_layer4(c4)
        <span style=color:#75715e># Top-down</span>
        p5 <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>RCNN_toplayer(c5)
        p4 <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>_upsample_add(p5, self<span style=color:#f92672>.</span>RCNN_latlayer1(c4))
        p4 <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>RCNN_smooth1(p4)
        p3 <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>_upsample_add(p4, self<span style=color:#f92672>.</span>RCNN_latlayer2(c3))
        p3 <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>RCNN_smooth2(p3)
        p2 <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>_upsample_add(p3, self<span style=color:#f92672>.</span>RCNN_latlayer3(c2))
        p2 <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>RCNN_smooth3(p2)

        p6 <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>maxpool2d(p5)

        rpn_feature_maps <span style=color:#f92672>=</span> [p2, p3, p4, p5, p6]
        mrcnn_feature_maps <span style=color:#f92672>=</span> [p2, p3, p4, p5]

        rois, rpn_loss_cls, rpn_loss_bbox <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>RCNN_rpn(rpn_feature_maps, im_info, gt_boxes, num_boxes)

</code></pre></div><p>其中RCNN_layer就是用了resnet对应的layer. 可以看出c1,c2,c3,c4是bottom-up的几个feature map, p对应的是top-down的feature map</p><p><strong>需要注意这里的下标,不管是p还是c,数字越大表示的都是feature map越小. 相同数字的p和c(比如p4和c4)是同一个level的feature.</strong></p><p>然后中间是通过　_upsample_add　直接元素相加</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>
 <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>_upsample_add</span>(self, x, y):
        <span style=color:#e6db74></span><span style=color:#e6db74>&#39;&#39;&#39;</span><span style=color:#e6db74>Upsample and add two feature maps.</span><span style=color:#e6db74>
</span><span style=color:#e6db74></span><span style=color:#e6db74>        Args:</span><span style=color:#e6db74>
</span><span style=color:#e6db74></span><span style=color:#e6db74>          x: (Variable) top feature map to be upsampled.</span><span style=color:#e6db74>
</span><span style=color:#e6db74></span><span style=color:#e6db74>          y: (Variable) lateral feature map.</span><span style=color:#e6db74>
</span><span style=color:#e6db74></span><span style=color:#e6db74>        Returns:</span><span style=color:#e6db74>
</span><span style=color:#e6db74></span><span style=color:#e6db74>          (Variable) added feature map.</span><span style=color:#e6db74>
</span><span style=color:#e6db74></span><span style=color:#e6db74>        Note in PyTorch, when input size is odd, the upsampled feature map</span><span style=color:#e6db74>
</span><span style=color:#e6db74></span><span style=color:#e6db74>        with `F.upsample(..., scale_factor=2, mode=</span><span style=color:#e6db74>&#39;</span><span style=color:#e6db74>nearest</span><span style=color:#e6db74>&#39;</span><span style=color:#e6db74>)`</span><span style=color:#e6db74>
</span><span style=color:#e6db74></span><span style=color:#e6db74>        maybe not equal to the lateral feature map size.</span><span style=color:#e6db74>
</span><span style=color:#e6db74></span><span style=color:#e6db74>        e.g.</span><span style=color:#e6db74>
</span><span style=color:#e6db74></span><span style=color:#e6db74>        original input size: [N,_,15,15] -&gt;</span><span style=color:#e6db74>
</span><span style=color:#e6db74></span><span style=color:#e6db74>        conv2d feature map size: [N,_,8,8] -&gt;</span><span style=color:#e6db74>
</span><span style=color:#e6db74></span><span style=color:#e6db74>        upsampled feature map size: [N,_,16,16]</span><span style=color:#e6db74>
</span><span style=color:#e6db74></span><span style=color:#e6db74>        So we choose bilinear upsample which supports arbitrary output sizes.</span><span style=color:#e6db74>
</span><span style=color:#e6db74></span><span style=color:#e6db74>        </span><span style=color:#e6db74>&#39;&#39;&#39;</span>
        _,_,H,W <span style=color:#f92672>=</span> y<span style=color:#f92672>.</span>size()
        <span style=color:#66d9ef>return</span> F<span style=color:#f92672>.</span>upsample(x, size<span style=color:#f92672>=</span>(H,W), mode<span style=color:#f92672>=</span><span style=color:#e6db74></span><span style=color:#e6db74>&#39;</span><span style=color:#e6db74>bilinear</span><span style=color:#e6db74>&#39;</span>) <span style=color:#f92672>+</span> y

</code></pre></div><p>至于为什么能相加，</p><blockquote><blockquote><p>作者解释说这个原因在于我们做了 end-to-end 的 training，因为不同层的参数不是固定的，不同层同时给监督做 end-to-end training，所以相加训练出来的东西能够更有效地融合浅层和深层的信息。</p></blockquote></blockquote><blockquote><blockquote><p>da哥解释说，只要work了，故事随便讲</p></blockquote></blockquote><p>我们看到这里拿了[p2, p3, p4, p5, p6] 这几个feature 输入到rpn网络中．</p><p>然后我们看一下RPN-FPN的forward 部分</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>

    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>forward</span>(self, rpn_feature_maps, im_info, gt_boxes, num_boxes):        


        n_feat_maps <span style=color:#f92672>=</span> len(rpn_feature_maps)

        rpn_cls_scores <span style=color:#f92672>=</span> []
        rpn_cls_probs <span style=color:#f92672>=</span> []
        rpn_bbox_preds <span style=color:#f92672>=</span> []
        rpn_shapes <span style=color:#f92672>=</span> []
        <span style=color:#75715e>#  对于每一个feature map，来做rpn得到prob和bbox </span>
        <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(n_feat_maps):
            feat_map <span style=color:#f92672>=</span> rpn_feature_maps[i]
            batch_size <span style=color:#f92672>=</span> feat_map<span style=color:#f92672>.</span>size(<span style=color:#ae81ff>0</span>)
            
            <span style=color:#75715e># return feature map after convrelu layer</span>
            rpn_conv1 <span style=color:#f92672>=</span> F<span style=color:#f92672>.</span>relu(self<span style=color:#f92672>.</span>RPN_Conv(feat_map), inplace<span style=color:#f92672>=</span>True)
            <span style=color:#75715e># get rpn classification score</span>
            rpn_cls_score <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>RPN_cls_score(rpn_conv1)

            rpn_cls_score_reshape <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>reshape(rpn_cls_score, <span style=color:#ae81ff>2</span>)
            rpn_cls_prob_reshape <span style=color:#f92672>=</span> F<span style=color:#f92672>.</span>softmax(rpn_cls_score_reshape)
            rpn_cls_prob <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>reshape(rpn_cls_prob_reshape, self<span style=color:#f92672>.</span>nc_score_out)

            <span style=color:#75715e># get rpn offsets to the anchor boxes</span>
            rpn_bbox_pred <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>RPN_bbox_pred(rpn_conv1)

            rpn_shapes<span style=color:#f92672>.</span>append([rpn_cls_score<span style=color:#f92672>.</span>size()[<span style=color:#ae81ff>2</span>], rpn_cls_score<span style=color:#f92672>.</span>size()[<span style=color:#ae81ff>3</span>]])
            <span style=color:#75715e># permute是为了把坐标/分数放在最外面一个维度</span>
            rpn_cls_scores<span style=color:#f92672>.</span>append(rpn_cls_score<span style=color:#f92672>.</span>permute(<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>1</span>)<span style=color:#f92672>.</span>contiguous()<span style=color:#f92672>.</span>view(batch_size, <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>2</span>))
            rpn_cls_probs<span style=color:#f92672>.</span>append(rpn_cls_prob<span style=color:#f92672>.</span>permute(<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>1</span>)<span style=color:#f92672>.</span>contiguous()<span style=color:#f92672>.</span>view(batch_size, <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>2</span>))
            rpn_bbox_preds<span style=color:#f92672>.</span>append(rpn_bbox_pred<span style=color:#f92672>.</span>permute(<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>1</span>)<span style=color:#f92672>.</span>contiguous()<span style=color:#f92672>.</span>view(batch_size, <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>4</span>))

        rpn_cls_score_alls <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>cat(rpn_cls_scores, <span style=color:#ae81ff>1</span>)
        rpn_cls_prob_alls <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>cat(rpn_cls_probs, <span style=color:#ae81ff>1</span>)
        rpn_bbox_pred_alls <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>cat(rpn_bbox_preds, <span style=color:#ae81ff>1</span>)

        n_rpn_pred <span style=color:#f92672>=</span> rpn_cls_score_alls<span style=color:#f92672>.</span>size(<span style=color:#ae81ff>1</span>)

        <span style=color:#75715e># proposal layer</span>
        cfg_key <span style=color:#f92672>=</span> <span style=color:#e6db74></span><span style=color:#e6db74>&#39;</span><span style=color:#e6db74>TRAIN</span><span style=color:#e6db74>&#39;</span> <span style=color:#66d9ef>if</span> self<span style=color:#f92672>.</span>training <span style=color:#66d9ef>else</span> <span style=color:#e6db74></span><span style=color:#e6db74>&#39;</span><span style=color:#e6db74>TEST</span><span style=color:#e6db74>&#39;</span>
        <span style=color:#75715e># 　现在rpn网络已经对anchors的好坏做出了学习，这里的好坏只是指前景或者背景，不包括具体类别的分数．</span>
        <span style=color:#75715e>#   同时rpn 也学习到了这些anchor的偏移，使得anchor的坐标往更好的方向做一些微调</span>

        <span style=color:#75715e># 组成了一个tuple,把这些输入作为一个整体的Input输入了进去</span>
        rois <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>RPN_proposal((rpn_cls_prob_alls<span style=color:#f92672>.</span>data, rpn_bbox_pred_alls<span style=color:#f92672>.</span>data,
                                 im_info, cfg_key, rpn_shapes))

</code></pre></div><p>可以看到是对于每一个scale的feaute_map单独过rpn,然后把得到的结果concat到了一起去做proposal</p><p>接下来我们看一下proposal的代码，细节稍微多一些．</p><p>简单来说,proposal　layer按照顺序大概做了如下几件事．</p><ul><li>bbox_transform_inv　根据rpn的结果调整anchors，得到更好的anchors</li><li>clip_boxes　把调整后的anchors根据图片尺寸进行截断，使得所有anchors都在图片范围内</li><li>按照分数高低选一定数量的anchors做nms,作为nms得到的这些anchors再取topk就称之为rois(或者proposals)</li></ul><p>整个proposals流程的代码如下，添加了必要的注释</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>
<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>forward</span>(self, input):

        <span style=color:#75715e># Algorithm:</span>
        <span style=color:#75715e>#</span>
        <span style=color:#75715e># for each (H, W) location i</span>
        <span style=color:#75715e>#   generate A anchor boxes centered on cell i</span>
        <span style=color:#75715e>#   apply predicted bbox deltas at cell i to each of the A anchors</span>
        <span style=color:#75715e># clip predicted boxes to image</span>
        <span style=color:#75715e># remove predicted boxes with either height or width &lt; threshold</span>
        <span style=color:#75715e># sort all (proposal, score) pairs by score from highest to lowest</span>
        <span style=color:#75715e># take top pre_nms_topN proposals before NMS</span>
        <span style=color:#75715e># apply NMS with threshold 0.7 to remaining proposals</span>
        <span style=color:#75715e># take after_nms_topN proposals after NMS</span>
        <span style=color:#75715e># return the top proposals (-&gt; RoIs top, scores top)</span>


        <span style=color:#75715e># the first set of _num_anchors channels are bg probs</span>
        <span style=color:#75715e># the second set are the fg probs</span>
        scores <span style=color:#f92672>=</span> input[<span style=color:#ae81ff>0</span>][:, :, <span style=color:#ae81ff>1</span>]  <span style=color:#75715e># batch_size x num_rois x 1</span>
        <span style=color:#75715e>#  0是背景分数,1是前景分数．　这里我们直接取了前景分数</span>

        bbox_deltas <span style=color:#f92672>=</span> input[<span style=color:#ae81ff>1</span>]      <span style=color:#75715e># batch_size x num_rois x 4</span>
        im_info <span style=color:#f92672>=</span> input[<span style=color:#ae81ff>2</span>]
        cfg_key <span style=color:#f92672>=</span> input[<span style=color:#ae81ff>3</span>]
        feat_shapes <span style=color:#f92672>=</span> input[<span style=color:#ae81ff>4</span>]        

        pre_nms_topN  <span style=color:#f92672>=</span> cfg[cfg_key]<span style=color:#f92672>.</span>RPN_PRE_NMS_TOP_N
        post_nms_topN <span style=color:#f92672>=</span> cfg[cfg_key]<span style=color:#f92672>.</span>RPN_POST_NMS_TOP_N
        nms_thresh    <span style=color:#f92672>=</span> cfg[cfg_key]<span style=color:#f92672>.</span>RPN_NMS_THRESH
        min_size      <span style=color:#f92672>=</span> cfg[cfg_key]<span style=color:#f92672>.</span>RPN_MIN_SIZE

        batch_size <span style=color:#f92672>=</span> bbox_deltas<span style=color:#f92672>.</span>size(<span style=color:#ae81ff>0</span>)

        anchors <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>from_numpy(generate_anchors_all_pyramids(self<span style=color:#f92672>.</span>_fpn_scales, self<span style=color:#f92672>.</span>_anchor_ratios, 
                feat_shapes, self<span style=color:#f92672>.</span>_fpn_feature_strides, self<span style=color:#f92672>.</span>_fpn_anchor_stride))<span style=color:#f92672>.</span>type_as(scores)
        <span style=color:#75715e># 　anchors shape : [anchor_count, (y1, x1, y2, x2)] 其中anchor_count是所有scale的feature map上的anchor总和</span>
        num_anchors <span style=color:#f92672>=</span> anchors<span style=color:#f92672>.</span>size(<span style=color:#ae81ff>0</span>)

        anchors <span style=color:#f92672>=</span> anchors<span style=color:#f92672>.</span>view(<span style=color:#ae81ff>1</span>, num_anchors, <span style=color:#ae81ff>4</span>)<span style=color:#f92672>.</span>expand(batch_size, num_anchors, <span style=color:#ae81ff>4</span>)
        <span style=color:#75715e># Any dimension of size 1 can be expanded to an arbitrary value without allocating new memory.　</span>
        <span style=color:#75715e># 所以其实是同一份anchor,为了每个batch使用,expand成了batch_size份．</span>
        <span style=color:#75715e># 　先view从(num_anchors,4)变成(1,num_anchors,4)增加一个维度</span>
        <span style=color:#75715e>#   然后变成了(batch_size,num_anchors,4)的维度</span>

        <span style=color:#75715e># Convert anchors into proposals via bbox transformations</span>
        proposals <span style=color:#f92672>=</span> bbox_transform_inv(anchors, bbox_deltas, batch_size)

        <span style=color:#75715e># 2. clip predicted boxes to image</span>
        proposals <span style=color:#f92672>=</span> clip_boxes(proposals, im_info, batch_size)
        <span style=color:#75715e># keep_idx = self._filter_boxes(proposals, min_size).squeeze().long().nonzero().squeeze()</span>
                
        scores_keep <span style=color:#f92672>=</span> scores
        proposals_keep <span style=color:#f92672>=</span> proposals

        _, order <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>sort(scores_keep, <span style=color:#ae81ff>1</span>, True)
        <span style=color:#75715e># torch.sort(tensor,dim,descending)</span>
        <span style=color:#75715e>#  因此这里是把分数在num_rois的维度降序排列，返回(values, indices)</span>
        <span style=color:#75715e># 我们要用的是indices，就是在排序前的下标</span>
        output <span style=color:#f92672>=</span> scores<span style=color:#f92672>.</span>new(batch_size, post_nms_topN, <span style=color:#ae81ff>5</span>)<span style=color:#f92672>.</span>zero_()
        <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(batch_size):
            <span style=color:#75715e># # 3. remove predicted boxes with either height or width &lt; threshold</span>
            <span style=color:#75715e># # (NOTE: convert min_size to input image scale stored in im_info[2])</span>
            proposals_single <span style=color:#f92672>=</span> proposals_keep[i]
            scores_single <span style=color:#f92672>=</span> scores_keep[i]

            <span style=color:#75715e># # 4. sort all (proposal, score) pairs by score from highest to lowest</span>
            <span style=color:#75715e># # 5. take top pre_nms_topN (e.g. 6000)</span>
            order_single <span style=color:#f92672>=</span> order[i]
            <span style=color:#75715e># 　torch.numel() : Returns the total number of elements in the input tensor.</span>
            <span style=color:#66d9ef>if</span> pre_nms_topN <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>0</span> <span style=color:#f92672>and</span> pre_nms_topN <span style=color:#f92672>&lt;</span> scores_keep<span style=color:#f92672>.</span>numel():
                order_single <span style=color:#f92672>=</span> order_single[:pre_nms_topN]
            <span style=color:#75715e># 　得到分数最高的前pre_nms_topN个的下标　</span>

            proposals_single <span style=color:#f92672>=</span> proposals_single[order_single, :]
            <span style=color:#75715e># 从下标得到具体的proposals(就是调整过后的anchors)</span>
            scores_single <span style=color:#f92672>=</span> scores_single[order_single]<span style=color:#f92672>.</span>view(<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>,<span style=color:#ae81ff>1</span>)

            <span style=color:#75715e># 6. apply nms (e.g. threshold = 0.7)</span>
            <span style=color:#75715e># 7. take after_nms_topN (e.g. 300)</span>
            <span style=color:#75715e># 8. return the top proposals (-&gt; RoIs top)</span>

            keep_idx_i <span style=color:#f92672>=</span> nms(torch<span style=color:#f92672>.</span>cat((proposals_single, scores_single), <span style=color:#ae81ff>1</span>), nms_thresh)
            keep_idx_i <span style=color:#f92672>=</span> keep_idx_i<span style=color:#f92672>.</span>long()<span style=color:#f92672>.</span>view(<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>)

            <span style=color:#66d9ef>if</span> post_nms_topN <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>0</span>:
                keep_idx_i <span style=color:#f92672>=</span> keep_idx_i[:post_nms_topN]
            proposals_single <span style=color:#f92672>=</span> proposals_single[keep_idx_i, :]
            scores_single <span style=color:#f92672>=</span> scores_single[keep_idx_i, :]

            <span style=color:#75715e># padding 0 at the end.</span>
            num_proposal <span style=color:#f92672>=</span> proposals_single<span style=color:#f92672>.</span>size(<span style=color:#ae81ff>0</span>)
            output[i,:,<span style=color:#ae81ff>0</span>] <span style=color:#f92672>=</span> i
            output[i,:num_proposal,<span style=color:#ae81ff>1</span>:] <span style=color:#f92672>=</span> proposals_single
            <span style=color:#75715e># 　output: (batch_size, post_nms_topN, 5)</span>

        <span style=color:#66d9ef>return</span> output

</code></pre></div><p>其中　bbox_transform_inv和　clip_boxes的代码分别如下:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>

<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>bbox_transform_inv</span>(boxes, deltas, batch_size):
    <span style=color:#75715e># 　boxes: 　(batch_size,num_anchors,4), 4的坐标顺序为(x1, y1, x2, y2)</span>
    <span style=color:#75715e># 　（原代码注释写的是　(y1,x1,y2,x2),似乎不正确）　</span>

    <span style=color:#75715e># deltas: batch_size x num_rois x 4</span>
    widths <span style=color:#f92672>=</span> boxes[:, :, <span style=color:#ae81ff>2</span>] <span style=color:#f92672>-</span> boxes[:, :, <span style=color:#ae81ff>0</span>] <span style=color:#f92672>+</span> <span style=color:#ae81ff>1.0</span>
    heights <span style=color:#f92672>=</span> boxes[:, :, <span style=color:#ae81ff>3</span>] <span style=color:#f92672>-</span> boxes[:, :, <span style=color:#ae81ff>1</span>] <span style=color:#f92672>+</span> <span style=color:#ae81ff>1.0</span>
    ctr_x <span style=color:#f92672>=</span> boxes[:, :, <span style=color:#ae81ff>0</span>] <span style=color:#f92672>+</span> <span style=color:#ae81ff>0.5</span> <span style=color:#f92672>*</span> widths
    ctr_y <span style=color:#f92672>=</span> boxes[:, :, <span style=color:#ae81ff>1</span>] <span style=color:#f92672>+</span> <span style=color:#ae81ff>0.5</span> <span style=color:#f92672>*</span> heights
    <span style=color:#75715e># 　widths,heights,ctr_x,ctr_y的维度都是(batch_size,num_rois)</span>

    <span style=color:#75715e>#  ctx是中心点坐标</span>

    dx <span style=color:#f92672>=</span> deltas[:, :, <span style=color:#ae81ff>0</span>::<span style=color:#ae81ff>4</span>]
    dy <span style=color:#f92672>=</span> deltas[:, :, <span style=color:#ae81ff>1</span>::<span style=color:#ae81ff>4</span>]
    <span style=color:#75715e># 　dx,dy是预测得到的中心点偏移距离相对width和height的比例</span>
    dw <span style=color:#f92672>=</span> deltas[:, :, <span style=color:#ae81ff>2</span>::<span style=color:#ae81ff>4</span>]
    dh <span style=color:#f92672>=</span> deltas[:, :, <span style=color:#ae81ff>3</span>::<span style=color:#ae81ff>4</span>]
    <span style=color:#75715e># 把　deltas的坐标展开，每一个的shape为(batch_size,num_rois,1),为了方便做向量化操作</span>

    pred_ctr_x <span style=color:#f92672>=</span> dx <span style=color:#f92672>*</span> widths<span style=color:#f92672>.</span>unsqueeze(<span style=color:#ae81ff>2</span>) <span style=color:#f92672>+</span> ctr_x<span style=color:#f92672>.</span>unsqueeze(<span style=color:#ae81ff>2</span>)
    pred_ctr_y <span style=color:#f92672>=</span> dy <span style=color:#f92672>*</span> heights<span style=color:#f92672>.</span>unsqueeze(<span style=color:#ae81ff>2</span>) <span style=color:#f92672>+</span> ctr_y<span style=color:#f92672>.</span>unsqueeze(<span style=color:#ae81ff>2</span>)
    <span style=color:#75715e>#  dx的维度是(batch_size,num_rois,1),widths和ctr_x的维度为(batch_size,num_rios),unsqueeze是为了做ele-wise的运算</span>

    pred_w <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>exp(dw) <span style=color:#f92672>*</span> widths<span style=color:#f92672>.</span>unsqueeze(<span style=color:#ae81ff>2</span>)
    pred_h <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>exp(dh) <span style=color:#f92672>*</span> heights<span style=color:#f92672>.</span>unsqueeze(<span style=color:#ae81ff>2</span>)

    <span style=color:#75715e># 　按照原公式的log做了逆向运算</span>

    pred_boxes <span style=color:#f92672>=</span> deltas<span style=color:#f92672>.</span>clone()
    <span style=color:#75715e># x1</span>
    pred_boxes[:, :, <span style=color:#ae81ff>0</span>::<span style=color:#ae81ff>4</span>] <span style=color:#f92672>=</span> pred_ctr_x <span style=color:#f92672>-</span> <span style=color:#ae81ff>0.5</span> <span style=color:#f92672>*</span> pred_w
    <span style=color:#75715e># y1</span>
    pred_boxes[:, :, <span style=color:#ae81ff>1</span>::<span style=color:#ae81ff>4</span>] <span style=color:#f92672>=</span> pred_ctr_y <span style=color:#f92672>-</span> <span style=color:#ae81ff>0.5</span> <span style=color:#f92672>*</span> pred_h
    <span style=color:#75715e># x2</span>
    pred_boxes[:, :, <span style=color:#ae81ff>2</span>::<span style=color:#ae81ff>4</span>] <span style=color:#f92672>=</span> pred_ctr_x <span style=color:#f92672>+</span> <span style=color:#ae81ff>0.5</span> <span style=color:#f92672>*</span> pred_w
    <span style=color:#75715e># y2</span>
    pred_boxes[:, :, <span style=color:#ae81ff>3</span>::<span style=color:#ae81ff>4</span>] <span style=color:#f92672>=</span> pred_ctr_y <span style=color:#f92672>+</span> <span style=color:#ae81ff>0.5</span> <span style=color:#f92672>*</span> pred_h

    <span style=color:#75715e># 得到的是经过　deltas修正过的anchors</span>

    <span style=color:#66d9ef>return</span> pred_boxes

</code></pre></div><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>
<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>clip_boxes</span>(boxes, im_shape, batch_size):
    <span style=color:#75715e>#  把修正过的anchors截断到图片范围之内．　</span>
    　
    <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(batch_size):
        boxes[i,:,<span style=color:#ae81ff>0</span>::<span style=color:#ae81ff>4</span>]<span style=color:#f92672>.</span>clamp_(<span style=color:#ae81ff>0</span>, im_shape[i, <span style=color:#ae81ff>1</span>]<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>)
        boxes[i,:,<span style=color:#ae81ff>1</span>::<span style=color:#ae81ff>4</span>]<span style=color:#f92672>.</span>clamp_(<span style=color:#ae81ff>0</span>, im_shape[i, <span style=color:#ae81ff>0</span>]<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>)
        boxes[i,:,<span style=color:#ae81ff>2</span>::<span style=color:#ae81ff>4</span>]<span style=color:#f92672>.</span>clamp_(<span style=color:#ae81ff>0</span>, im_shape[i, <span style=color:#ae81ff>1</span>]<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>)
        boxes[i,:,<span style=color:#ae81ff>3</span>::<span style=color:#ae81ff>4</span>]<span style=color:#f92672>.</span>clamp_(<span style=color:#ae81ff>0</span>, im_shape[i, <span style=color:#ae81ff>0</span>]<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>)

    <span style=color:#66d9ef>return</span> boxes


</code></pre></div><p><strong>这两个函数是各种对不齐的重灾区</strong></p><p>至此，我们得到了roi,完成了rpn和proposal 阶段</p><h3 id=fpn-作用于fast-rcnn>FPN 作用于fast rcnn</h3><p>回想faster rcnn,我们只有一个feature map,因此所有的roi都会作用在feature map上.</p><p>但是现在我们有多个不同scale的feature map,因此每个roi作用在哪个feature map上就是一个问题.</p><p>按照paper中的描述,我们不妨将这些由FPN生成的不同scale的feature map考虑成是由image pyramid 生成的.</p><blockquote><p>We view our feature pyramid as if it were produced from
an image pyramid. Thus we can adapt the assignment strategy
of region-based detectors [15, 11] in the case when they
are run on image pyramids</p></blockquote><p>那么显然,越大的roi应该是由越大scale的image得到的. 对应回我们的FPN,也就是越大的roi对应越大scale的feature map.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>
  <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>_PyramidRoI_Feat</span>(self, feat_maps, rois, im_info):
        <span style=color:#e6db74></span><span style=color:#e6db74>&#39;&#39;&#39;</span><span style=color:#e6db74> roi pool on pyramid feature maps</span><span style=color:#e6db74>&#39;&#39;&#39;</span>
        <span style=color:#75715e># do roi pooling based on predicted rois</span>
        img_area <span style=color:#f92672>=</span> im_info[<span style=color:#ae81ff>0</span>][<span style=color:#ae81ff>0</span>] <span style=color:#f92672>*</span> im_info[<span style=color:#ae81ff>0</span>][<span style=color:#ae81ff>1</span>]
        h <span style=color:#f92672>=</span> rois<span style=color:#f92672>.</span>data[:, <span style=color:#ae81ff>4</span>] <span style=color:#f92672>-</span> rois<span style=color:#f92672>.</span>data[:, <span style=color:#ae81ff>2</span>] <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>
        w <span style=color:#f92672>=</span> rois<span style=color:#f92672>.</span>data[:, <span style=color:#ae81ff>3</span>] <span style=color:#f92672>-</span> rois<span style=color:#f92672>.</span>data[:, <span style=color:#ae81ff>1</span>] <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>
        <span style=color:#75715e># 基于roi的scale来判断这个roi对应哪一层的feature </span>
        <span style=color:#75715e># 对于大尺度的roi,就用更深的feature map</span>
        roi_level <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>log(torch<span style=color:#f92672>.</span>sqrt(h <span style=color:#f92672>*</span> w) <span style=color:#f92672>/</span> <span style=color:#ae81ff>224.0</span>)
        roi_level <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>round(roi_level <span style=color:#f92672>+</span> <span style=color:#ae81ff>4</span>)
        roi_level[roi_level <span style=color:#f92672>&lt;</span> <span style=color:#ae81ff>2</span>] <span style=color:#f92672>=</span> <span style=color:#ae81ff>2</span>
        roi_level[roi_level <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>5</span>] <span style=color:#f92672>=</span> <span style=color:#ae81ff>5</span>
        <span style=color:#75715e># 保护边界为[2,5]</span>
        
</code></pre></div><h2 id=参考>参考</h2><ul><li><a href=https://arxiv.org/abs/1612.03144>Feature Pyramid Networks for Object Detection</a></li><li><a href=https://github.com/jwyang/fpn.pytorch>fpn.pytorch</a></li></ul><hr><ul class=pager><li class=previous><a href=/2019/12/single-short-detector/ data-toggle=tooltip data-placement=top title="SSD: Single Shot MultiBox Detector　学习笔记">&larr;
Previous Post</a></li><li class=next><a href=/2019/12/debug-faster-rcnn-once-again/ data-toggle=tooltip data-placement=top title="记一次faster-rcnn debug记录">Next
Post &rarr;</a></li></ul><div class=post-comment><span id=/2019/12/feature-pyramid-networks/ class=leancloud_visitors data-flag-title="FPN:Feature Pyramid Networks 学习笔记"><span class=post-meta-item-text>访问量</span>
<span class=leancloud-visitors-count></span><p></p></span><div id=vcomments></div><script src=//cdn1.lncld.net/static/js/3.0.4/av-min.js></script><script src=//unpkg.com/valine/dist/Valine.min.js></script><script type=text/javascript>new Valine({el:'#vcomments',appId:'2dzJwxGKq4hbtg5R5NM8NTzJ-gzGzoHsz',appKey:'RaYu8uGTiuiIjLISQppPVYWw',notify:true,verify:false,avatar:'retro',placeholder:'说点什么吧...',visitor:true});</script></div></div><div class="col-lg-8 col-lg-offset-2
col-md-10 col-md-offset-1
sidebar-container"><section><hr class="hidden-sm hidden-xs"><h5><a href=/tags/>FEATURED TAGS</a></h5><div class=tags><a href=/tags/bfs title=bfs>bfs</a>
<a href=/tags/binary-search title=binary-search>binary-search</a>
<a href=/tags/brute-force title=brute-force>brute-force</a>
<a href=/tags/dfs title=dfs>dfs</a>
<a href=/tags/dp title=dp>dp</a>
<a href=/tags/greedy title=greedy>greedy</a>
<a href=/tags/kmp title=kmp>kmp</a>
<a href=/tags/leetcode title=leetcode>leetcode</a>
<a href=/tags/math title=math>math</a>
<a href=/tags/number-theory title=number-theory>number-theory</a>
<a href=/tags/rmq title=rmq>rmq</a>
<a href=/tags/stl title=stl>stl</a>
<a href=/tags/%E5%89%8D%E7%BC%80%E5%92%8C title=前缀和>前缀和</a>
<a href=/tags/%E5%8D%9A%E5%BC%88%E8%AE%BA title=博弈论>博弈论</a>
<a href=/tags/%E5%9B%BE%E8%AE%BA title=图论>图论</a>
<a href=/tags/%E5%BF%AB%E9%80%9F%E5%B9%82 title=快速幂>快速幂</a>
<a href=/tags/%E6%95%B0%E4%BD%8Ddp title=数位dp>数位dp</a>
<a href=/tags/%E6%9E%84%E9%80%A0 title=构造>构造</a>
<a href=/tags/%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84 title=树状数组>树状数组</a>
<a href=/tags/%E6%A8%A1%E6%8B%9F title=模拟>模拟</a>
<a href=/tags/%E6%AF%8D%E5%87%BD%E6%95%B0 title=母函数>母函数</a>
<a href=/tags/%E7%9F%A9%E9%98%B5 title=矩阵>矩阵</a>
<a href=/tags/%E7%BA%BF%E6%AE%B5%E6%A0%91 title=线段树>线段树</a>
<a href=/tags/%E8%AE%A1%E7%AE%97%E5%87%A0%E4%BD%95 title=计算几何>计算几何</a></div></section><section><hr><h5>FRIENDS</h5><ul class=list-inline><li><a target=_blank href=https://111qqz.com>111qqz的wordpress博客</a></li></ul></section></div></div></div></article><footer><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><ul class="list-inline text-center"><li><a href rel=alternate type=application/rss+xml title=111qqz的小窝><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-rss fa-stack-1x fa-inverse"></i></span></a></li><li><a href=mailto:hust.111qqz@gmail.com><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-envelope fa-stack-1x fa-inverse"></i></span></a></li><li><a target=_blank href=/img/wechat.jpg><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-wechat fa-stack-1x fa-inverse"></i></span></a></li><li><a target=_blank href=https://github.com/111qqz/><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-github fa-stack-1x fa-inverse"></i></span></a></li></ul><p class="copyright text-muted">Copyright &copy; 111qqz的小窝 2022<br><a href=https://beian.miit.gov.cn/>粤ICP备18103363号</a><br><a href=https://themes.gohugo.io/hugo-theme-cleanwhite>CleanWhite Hugo Theme</a> by <a href=https://zhaohuabing.com>Huabing</a> |
<iframe style=margin-left:2px;margin-bottom:-5px frameborder=0 scrolling=0 width=100px height=20px src="https://ghbtns.com/github-btn.html?user=zhaohuabing&repo=hugo-theme-cleanwhite&type=star&count=true"></iframe></p></div></div></div></footer><script>function async(u,c){var d=document,t='script',o=d.createElement(t),s=d.getElementsByTagName(t)[0];o.src=u;if(c){o.addEventListener('load',function(e){c(null,e);},false);}
s.parentNode.insertBefore(o,s);}</script><script>if($('#tag_cloud').length!==0){async("/js/jquery.tagcloud.js",function(){$.fn.tagcloud.defaults={color:{start:'#bbbbee',end:'#0085a1'},};$('#tag_cloud a').tagcloud();})}</script><script>async("https://cdnjs.cloudflare.com/ajax/libs/fastclick/1.0.6/fastclick.js",function(){var $nav=document.querySelector("nav");if($nav)FastClick.attach($nav);})</script></body></html>
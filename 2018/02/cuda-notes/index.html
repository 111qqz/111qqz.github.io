<!doctype html><html lang=zh-cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta property="og:site_name" content="111qqz的小窝"><meta property="og:type" content="article"><meta property="og:image" content="https://111qqz.github.io/img/2.png"><meta property="twitter:image" content="https://111qqz.github.io/img/2.png"><meta name=title content="cuda 学习笔记"><meta property="og:title" content="cuda 学习笔记"><meta property="twitter:title" content="cuda 学习笔记"><meta name=description content><meta property="og:description" content><meta property="twitter:description" content><meta property="twitter:card" content="summary"><meta name=keyword content="ACM,111qqz,商汤科技,hust,华中科技大学"><link rel="shortcut icon" href=/img/favicon.ico><title>cuda 学习笔记-111qqz的小窝</title><link rel=canonical href=/2018/02/cuda-notes/><link rel=stylesheet href=/css/iDisqus.min.css><link rel=stylesheet href=/css/bootstrap.min.css><link rel=stylesheet href=/css/hux-blog.min.css><link rel=stylesheet href=/css/syntax.css><link rel=stylesheet href=/css/zanshang.css><link href=//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css rel=stylesheet type=text/css><script src=/js/jquery.min.js></script><script src=/js/bootstrap.min.js></script><script src=/js/hux-blog.min.js></script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/styles/docco.min.css><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/highlight.min.js></script><script>hljs.initHighlightingOnLoad();</script><link rel=stylesheet href=/css/hux-blog.min.css><link rel=stylesheet href=/css/hux-blog.min-custom.css><script data-ad-client=ca-pub-2010211964550865 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><nav class="navbar navbar-default navbar-custom navbar-fixed-top"><div class=container-fluid><div class="navbar-header page-scroll"><button type=button class=navbar-toggle>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span><span class=icon-bar></span><span class=icon-bar></span></button>
<a class=navbar-brand href=/>111qqz的小窝</a></div><div id=huxblog_navbar><div class=navbar-collapse><ul class="nav navbar-nav navbar-right"><li><a href=/>Home</a></li><li><a href=/categories/acm/>ACM-ICPC</a></li><li><a href=/categories/deep-learning/>深度学习</a></li><li><a href=/categories/mooc/>公开课</a></li><li><a href=/categories/%e5%85%b6%e4%bb%96/>其他</a></li><li><a href=/top/about/>ABOUT</a></li><li><a href=/search>SEARCH <img src=/img/search.png height=15 style=cursor:pointer alt=Search></a></li></ul></div></div></div></nav><script>var $body=document.body;var $toggle=document.querySelector('.navbar-toggle');var $navbar=document.querySelector('#huxblog_navbar');var $collapse=document.querySelector('.navbar-collapse');$toggle.addEventListener('click',handleMagic)
function handleMagic(e){if($navbar.className.indexOf('in')>0){$navbar.className=" ";setTimeout(function(){if($navbar.className.indexOf('in')<0){$collapse.style.height="0px"}},400)}else{$collapse.style.height="auto"
$navbar.className+=" in";}}</script><style type=text/css>header.intro-header{background-image:url(/img/2.png)}</style><header class=intro-header><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class=post-heading><div class=tags><a class=tag href=/tags/cuda title=cuda>cuda</a></div><h1>cuda 学习笔记</h1><h2 class=subheading></h2><span class=meta>Posted by
111qqz
on
Thursday, February 1, 2018
<span id=/2018/02/cuda-notes/ class="leancloud_visitors meta_data_item" data-flag-title><span class=post-meta-item-icon><span class="octicon octicon-eye"></span></span><i class="fa fa-eye"></i><span class=old-visitors-count style=display:none></span><span class=leancloud-visitors-count></span></span><script src=https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js></script><script>AV.initialize("UzhnsgbPvx1RFb2kNXUHpPtf-gzGzoHsz","OXOvoYGuwMv70Os5GOgaGEWT");</script><script type=text/javascript>function showTime(Counter){var query=new AV.Query(Counter);var entries=[];var $visitors=$(".leancloud_visitors");console.log("aaa")
$visitors.each(function(){entries.push($(this).attr("id").trim());});query.containedIn('url',entries);query.find().done(function(results){var COUNT_CONTAINER_REF='.leancloud-visitors-count';var OLD_COUNT_CONTAINER_REF='.old-visitors-count';for(var i=0;i<results.length;i++){var item=results[i];var url=item.get('url');var time=item.get('time');var element=document.getElementById(url);$(element).find(COUNT_CONTAINER_REF).text(time);}
for(var i=0;i<entries.length;i++){var url=entries[i];var element=document.getElementById(url);var countSpan=$(element).find(COUNT_CONTAINER_REF);if(countSpan.text()==''){var oldCountSpan=$(element).find(OLD_COUNT_CONTAINER_REF).text();if(oldCountSpan!=''){countSpan.text(0+parseInt(oldCountSpan));}else{countSpan.text(0);}}}}).fail(function(object,error){console.log("Error: "+error.code+" "+error.message);});}
function addCount(Counter){var $visitors=$(".leancloud_visitors");var url=$visitors.attr('id').trim();var title=$visitors.attr('data-flag-title').trim();var query=new AV.Query(Counter);con
query.equalTo("url",url);query.find({success:function(results){if(results.length>0){var counter=results[0];counter.fetchWhenSave(true);counter.increment("time");counter.save(null,{success:function(counter){var $element=$(document.getElementById(url));$element.find('.leancloud-visitors-count').text(counter.get('time'));},error:function(counter,error){console.log('Failed to save Visitor num, with error message: '+error.message);}});}else{var newcounter=new Counter();var acl=new AV.ACL();acl.setPublicReadAccess(true);acl.setPublicWriteAccess(true);newcounter.setACL(acl);newcounter.set("title",title);newcounter.set("url",url);var OLD_COUNT_CONTAINER_REF='.old-visitors-count';var $element=$(document.getElementById(url));var oldCountSpan=$element.find(OLD_COUNT_CONTAINER_REF).text();if(oldCountSpan!=''){newcounter.set("time",parseInt(oldCountSpan)+1);}else{newcounter.set("time",1);}
newcounter.save(null,{success:function(newcounter){var $element=$(document.getElementById(url));$element.find('.leancloud-visitors-count').text(newcounter.get('time'));},error:function(newcounter,error){console.log('Failed to create');}});}},error:function(error){console.log('Error:'+error.code+" "+error.message);}});}
$(function(){var Counter=AV.Object.extend("Counter");console.log("miao miao miao")
if($('.leancloud_visitors').length==1){addCount(Counter);}else{showTime(Counter);}});</script></span></div></div></div></div></header><article><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2
col-md-10 col-md-offset-1
post-container"><header><h2>TOC</h2></header><nav id=TableOfContents></nav><p>uodate:有毒吧。kernel中出问题原来是不会报错的。。。。</p><p>请教了组里的hust学长orz..、</p><p>学到了cuda-memcheck命令和cudaGetLastError来查看问题。。可以参考<a href=https://stackoverflow.com/questions/14038589/what-is-the-canonical-way-to-check-for-errors-using-the-cuda-runtime-api>What is the canonical way to check for errors using the CUDA runtime API?</a></p><p>先放一波资料。</p><pre><code>  * &lt;del&gt;[An Even Easier Introduction to CUDA](https://devblogs.nvidia.com/even-easier-introduction-cuda/)&lt;/del&gt;
  * &lt;del&gt;[CUDA C/C++ Basics](https://drive.google.com/open?id=1kHYyM4yiJoyjkWjp7FJp0vae_TcvskjK)&lt;/del&gt;
  * &lt;del&gt;[nvidia-thrust 官方文档](http://docs.nvidia.com/cuda/thrust/index.html)&lt;/del&gt;
  * [how-access-global-memory-efficiently-cuda-c-kernels](https://devblogs.nvidia.com/how-access-global-memory-efficiently-cuda-c-kernels/)
  * [efficient-matrix-transpose-cuda-cc](https://devblogs.nvidia.com/efficient-matrix-transpose-cuda-cc/)
  * [很强大的warp内shuffle](https://devblogs.nvidia.com/faster-parallel-reductions-kepler/)
  * [cuda-GDB官方文档](http://docs.nvidia.com/cuda/cuda-gdb/index.html)
  * [cuda-c-best-practices-guide](http://docs.nvidia.com/cuda/cuda-c-best-practices-guide/)
</code></pre><p>cuda 提出的目的是能够让程序员透明地使用GPU来高效地进行并行运算。</p><p>kernel和c语言中的函数相似，函数名字前通常用<strong>global</strong>来标识。</p><p>下面考虑一个2个大小的1M的数组相加的例子。</p><p>总的思路是通过并行，来观察到计算速度的加快。</p><p>如果不考虑并行，2个数组相加的代码，如下：</p><pre><code>#include &lt;iostream&gt;
#include &lt;math.h&gt;

// function to add the elements of two arrays
void add(int n, float *x, float *y)
{
  for (int i = 0; i &lt; n; i++)
      y[i] = x[i] + y[i];
}

int main(void)
{
  int N = 1&lt;&lt;20; // 1M elements

  float *x = new float[N];
  float *y = new float[N];

  // initialize x and y arrays on the host
  for (int i = 0; i &lt; N; i++) {
    x[i] = 1.0f;
    y[i] = 2.0f;
  }
</code></pre><p>如果用cuda的方式来搞，代码如下：</p><pre><code>#include &lt;iostream&gt;
#include &lt;math.h&gt;
// Kernel function to add the elements of two arrays
__global__
void add(int n, float *x, float *y)
{
  for (int i = 0; i &lt; n; i++)
    y[i] = x[i] + y[i];
}

int main(void)
{
  int N = 1&lt;&lt;20;
  float *x, *y;

  // Allocate Unified Memory – accessible from CPU or GPU
  cudaMallocManaged(&amp;x, N*sizeof(float));
  cudaMallocManaged(&amp;y, N*sizeof(float));

  // initialize x and y arrays on the host
  for (int i = 0; i &lt; N; i++) {
    x[i] = 1.0f;
    y[i] = 2.0f;
  }

  // Run kernel on 1M elements on the GPU
  add&lt;&lt;&lt;1, 1&gt;&gt;&gt;(N, x, y);

  // Wait for GPU to finish before accessing on host
  cudaDeviceSynchronize();

  // Check for errors (all values should be 3.0f)
  float maxError = 0.0f;
  for (int i = 0; i &lt; N; i++)
    maxError = fmax(maxError, fabs(y[i]-3.0f));
  std::cout &lt;&lt; &quot;Max error: &quot; &lt;&lt; maxError &lt;&lt; std::endl;

  // Free memory
  cudaFree(x);
  cudaFree(y);
  
  return 0;
}
</code></pre><p>除了代码注释，还有几个地方要说明：</p><pre><code>  * 函数名字前面的global 是 cuda kernel  标识符
  * cuda kernel的调用方式是 &lt;&lt;&lt;,&gt;&gt;&gt;  更具体地说，是add&lt;&lt;&lt;numBlocks,blockSize&gt;&gt;&gt;(N,x,y)
  * .cu是 cuda C++ 文件的后缀，类似.cpp
  * nvcc是cuda C++ 的编译器，其将source code分成**host code**和**device code**两部分。前者通过c++编译器编译，后者通过nvidia编译器编译。
</code></pre><p>关于devide code 和 host code，参考下图。</p><p><a href=https://111qqz.com/wordpress/wp-content/uploads/2018/02/Screenshot-from-2018-02-08-145751.png><img src=https://111qqz.com/wordpress/wp-content/uploads/2018/02/Screenshot-from-2018-02-08-145751.png alt></a></p><p>现在我们单线程地跑了一个cuda kernel, 接下来是如何使它并行.关键在于&#171;&lt;1,1&#187;>这部分。</p><p>这行代码告诉了cuda runtime 有多少个并行的线程要被执行。
这里有2个参数，不过我们可以先改变第二个，也就是一个线程block中线程的个数。
cuda GPu的kernel 使用的blocks中线程的个数应该是32的倍数（后面会解释32代表什么），所以256看起来很合理。</p><pre><code>#include &lt;cstdio&gt;
#include &lt;iostream&gt;
#include &lt;math.h&gt;
// Kernel function to add the elements of two arrays
    __global__
void add(int n, float *x, float *y)
{


     int index = blockIdx.x * blockDim.x + threadIdx.x;
    int stride = blockDim.x * gridDim.x;
printf(&quot; %d %d&quot;,index,stride);
    for ( int i = index ; i &lt; n ; i += stride)
    y[i] = x[i] + y[i];
}

int main(void)
{
    int N = 1&lt;&lt;20;
    float *x, *y;

    // Allocate Unified Memory – accessible from CPU or GPU
    cudaMallocManaged(&amp;x, N*sizeof(float));
    cudaMallocManaged(&amp;y, N*sizeof(float));

    // initialize x and y arrays on the host
    for (int i = 0; i &lt; N; i++) {
    x[i] = 1.0f;
    y[i] = 2.0f;
    }


    int blockSize = 256;
    int numBlocks = (N + blockSize - 1) / blockSize;
    add&lt;&lt;&lt;numBlocks, blockSize&gt;&gt;&gt;(N, x, y);
    // Wait for GPU to finish before accessing on host
    cudaDeviceSynchronize();

    // Check for errors (all values should be 3.0f)
    float maxError = 0.0f;
    for (int i = 0; i &lt; N; i++)
    maxError = fmax(maxError, fabs(y[i]-3.0f));
//    std::cout &lt;&lt; &quot;Max error: &quot; &lt;&lt; maxError &lt;&lt; std::endl;

    // Free memory
    cudaFree(x);
    cudaFree(y);

    return 0;
}
</code></pre><p>不过如果只是修改了&#171;&lt;1,1&#187;> 到  &#171;&lt;1,256&#187;>
那实际上是对于每个线程都算了整个array的相加，而没有将整个计算任务分给多个并行的线程。
为了解决这个问题，我们需要修改kernel的代码。
cuda C++ 提供了关键字，允许kernel得到正要执行的thread是哪一个
threadIdx.x  表示当前运行的thread是block中的哪一个
blockDim.x 表示block中的线程个数</p><p>关于threadIdx.x等 下标问题，参考下图。</p><p><a href=https://111qqz.com/wordpress/wp-content/uploads/2018/02/Screenshot-from-2018-02-08-151308.png><img src=https://111qqz.com/wordpress/wp-content/uploads/2018/02/Screenshot-from-2018-02-08-151308.png alt></a></p><p>我们需要观察到使用cuda的方法之后时间的变化。</p><p>可以使用nvprof命令</p><pre><code>➜ learn&gt;nvprof ./add_cuda
==9312== NVPROF is profiling process 9312, command: ./add_cuda
Max error: 0
==9312== Profiling application: ./add_cuda
==9312== Profiling result:
Time(%)      Time     Calls       Avg       Min       Max  Name
100.00%  167.48ms         1  167.48ms  167.48ms  167.48ms  add(int, float*, float*)








==9382== Profiling application: ./add_block
==9382== Profiling result:
Time(%)      Time     Calls       Avg       Min       Max  Name
100.00%  3.5144ms         1  3.5144ms  3.5144ms  3.5144ms  add(int, float*, float*)







==9447== Profiling application: ./add_grid
==9447== Profiling result:
Time(%)      Time     Calls       Avg       Min       Max  Name
100.00%  1.8084ms         1  1.8084ms  1.8084ms  1.8084ms  add(int, float*, float*)
</code></pre><p>可以看出时间的变化，从167.48ms到3.5144ms，再到1.8084ms</p><p>我们注意到，对线程的管理实际上是三维的 :grid,block,thread.</p><p>为什么要这样设计？</p><p>一个这样做的目的是，在一个block中，thread可以通过share_memory 来共享数据。</p><p>通过在声明的变量前面添加 <strong>shared</strong>  来表示，这个变量是声明在share memory部分了。</p><p>share memory类似与缓存，容量小，但是速度快。不过这个cache是可以编程控制的。</p><p><strong>在一个block中共享的data,对于其他block是不可见的。</strong></p><p>我们不妨考虑一个例子，有2个数组a,b</p><p>进行如下运算：</p><p><a href=https://111qqz.com/wordpress/wp-content/uploads/2018/02/Screenshot-from-2018-02-08-210339.png><img src=https://111qqz.com/wordpress/wp-content/uploads/2018/02/Screenshot-from-2018-02-08-210339.png alt></a></p><p>为了加快运行速度，我们还是考虑多线程的办法。</p><p>让每一个线程处理一个输出。</p><p><a href=https://111qqz.com/wordpress/wp-content/uploads/2018/02/Screenshot-from-2018-02-09-095804.png><img src=https://111qqz.com/wordpress/wp-content/uploads/2018/02/Screenshot-from-2018-02-09-095804.png alt></a></p><p>然而我们发现，in中除了边界元素，每一个元素都被读了7次。</p><p>这显然是没有必要的。</p><p>问题的关键在于，不同的线程之间，不知道某个元素已经被读入了。</p><p>更进一步，不同线程之间可以共享数据吗？</p><p>答案是可以的。也就是上面提到的shared_memory</p><p>然而这样就可以了吗。。</p><p>由于线程的访问顺序是不固定的(?</p><p>会发生如下的问题：</p><p><a href=https://111qqz.com/wordpress/wp-content/uploads/2018/02/Screenshot-from-2018-02-09-100824.png><img src=https://111qqz.com/wordpress/wp-content/uploads/2018/02/Screenshot-from-2018-02-09-100824.png alt></a></p><p>解决办法很无脑。。。因为cuda并没有想象中得那么底层。。。</p><p>就是使用__syncthreads(); 来同步一个block中的所有进程。。。</p><p>完整代码如下：</p><pre><code>#include &lt;iostream&gt;
#include &lt;cstdio&gt;
#include &lt;cmath&gt;
#include &lt;ctime&gt;

const int R=3;
const int N=1&lt;&lt;20;
const int BLOCK_SIZE=256;
    __global__ 
void solve( int *in,int *out)
{
    __shared__ int tmp[BLOCK_SIZE + 2*R];
    int gindex = threadIdx.x + blockIdx.x * blockDim.x;
    int lindex = threadIdx.x + R;
//     printf (&quot;%d %d\n&quot;,gindex,lindex-R);
//    printf(&quot;wang\n&quot;);
    //if (lindex &lt; BLOCK_SIZE+2*R &amp;&amp; gindex &lt; N)
      tmp[lindex] = in[gindex];


//    if 这部分有问题。。。貌似是访问越界。。
    if (threadIdx.x &lt; R)
    {
    if (lindex&gt;=R &amp;&amp; gindex&gt;=R&amp;&amp;lindex-R&lt;BLOCK_SIZE+2*R&amp;&amp;gindex-R&lt;N)
       tmp[lindex-R] = in[gindex-R];
    if (lindex + BLOCK_SIZE&lt; BLOCK_SIZE+2*R &amp;&amp; gindex + BLOCK_SIZE &lt; N )
       tmp[lindex+BLOCK_SIZE] = in[gindex + BLOCK_SIZE];
    }
    
  //  printf(&quot;miao\n&quot;);
    __syncthreads();
    int res = 0 ;
    
    for ( int offset = -R ; offset &lt;= R ; offset++)
    {
//  printf (&quot;offset:%d\n&quot;,offset);
//  if (lindex + offset &lt; BLOCK_SIZE+2*R)
    res += tmp[lindex + offset];
    }
    
    out[gindex] = res;
    printf(&quot;res=%d\n&quot;,res);
}

void pr( int *A,int n)
{
    for ( int i = 0 ;i  &lt;  10 ; i++) printf (&quot;%d%c&quot;,A[i*10],i==9?'\n':' ');
}

int main(void)
{
    int *a,*b;
    if (cudaSuccess != cudaMallocManaged(&amp;a,N*sizeof(int)))
    printf(&quot;Cuda Malloc error\n&quot;);

    if (cudaSuccess != cudaMallocManaged(&amp;b,N*sizeof(int)))
    printf(&quot;Cuda Malloc error\n&quot;);
    for ( int i = 0 ; i &lt; N ; i++)
    {
    a[i] = 1;
    }
    pr(a,N);
    pr(b,N);
    int numBlocks = ( N + BLOCK_SIZE -1 ) / BLOCK_SIZE;
    //solve&lt;&lt;&lt;numBlocks,BLOCK_SIZE&gt;&gt;&gt;(a,b);
    solve&lt;&lt;&lt;1,256&gt;&gt;&gt;(a,b);
    if (cudaSuccess !=cudaGetLastError())
    printf(&quot;kernel error!&quot;);
    // prt&lt;&lt;&lt;numBlocks,BLOCK_SIZE&gt;&gt;&gt;();
    cudaDeviceSynchronize();
    pr(b,N);

    //printf(cudaGetLastError());
    cudaFree(a);
    cudaFree(b);

    return 0;
}
</code></pre><p>需要特别强调的是，cuda代码的debug问题，很多错误，不用特定的工具查看是不会显示的。
以及，虽然cuda代码是在c++上添加了一些东西，但是device code部分用的是nvidia的编译器。
所以c/cpp中，对于访问非法内存不敏感的特点，在cuda代码中不存在（我猜是因为编译器&mldr;）
<strong>在访问之前，一定要check访问地址合法性。。。。</strong></p><p><strong>在访问之前，一定要check访问地址合法性。。。。</strong></p><p><strong>在访问之前，一定要check访问地址合法性。。。。</strong></p><hr><ul class=pager><li class=previous><a href=/2018/01/non-local-means-algorithm-notes/ data-toggle=tooltip data-placement=top title="non-local means algorithm 学习笔记">&larr;
Previous Post</a></li><li class=next><a href=/2018/02/non-local-neural-networks-notes/ data-toggle=tooltip data-placement=top title="Non-local Neural Networks 阅读笔记">Next
Post &rarr;</a></li></ul><div class=post-comment><span id=/2018/02/cuda-notes/ class=leancloud_visitors data-flag-title="cuda 学习笔记"><span class=post-meta-item-text>访问量 "/2018/02/cuda-notes/"</span>
<span class=leancloud-visitors-count></span><p></p></span><div id=vcomments></div><script src=//cdn1.lncld.net/static/js/3.0.4/av-min.js></script><script src=//unpkg.com/valine/dist/Valine.min.js></script><script type=text/javascript>new Valine({el:'#vcomments',appId:'UzhnsgbPvx1RFb2kNXUHpPtf-gzGzoHsz',appKey:'OXOvoYGuwMv70Os5GOgaGEWT',notify:true,verify:false,avatar:'retro',placeholder:'说点什么吧...',visitor:true});</script></div></div><div class="col-lg-8 col-lg-offset-2
col-md-10 col-md-offset-1
sidebar-container"><section><hr class="hidden-sm hidden-xs"><h5><a href=/tags/>FEATURED TAGS</a></h5><div class=tags><a href=/tags/bfs title=bfs>bfs</a>
<a href=/tags/binary-search title=binary-search>binary-search</a>
<a href=/tags/brute-force title=brute-force>brute-force</a>
<a href=/tags/dfs title=dfs>dfs</a>
<a href=/tags/dp title=dp>dp</a>
<a href=/tags/greedy title=greedy>greedy</a>
<a href=/tags/kmp title=kmp>kmp</a>
<a href=/tags/leetcode title=leetcode>leetcode</a>
<a href=/tags/math title=math>math</a>
<a href=/tags/number-theory title=number-theory>number-theory</a>
<a href=/tags/rmq title=rmq>rmq</a>
<a href=/tags/stl title=stl>stl</a>
<a href=/tags/%E5%89%8D%E7%BC%80%E5%92%8C title=前缀和>前缀和</a>
<a href=/tags/%E5%8D%9A%E5%BC%88%E8%AE%BA title=博弈论>博弈论</a>
<a href=/tags/%E5%9B%BE%E8%AE%BA title=图论>图论</a>
<a href=/tags/%E5%BF%AB%E9%80%9F%E5%B9%82 title=快速幂>快速幂</a>
<a href=/tags/%E6%95%B0%E4%BD%8Ddp title=数位dp>数位dp</a>
<a href=/tags/%E6%9E%84%E9%80%A0 title=构造>构造</a>
<a href=/tags/%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84 title=树状数组>树状数组</a>
<a href=/tags/%E6%A8%A1%E6%8B%9F title=模拟>模拟</a>
<a href=/tags/%E6%AF%8D%E5%87%BD%E6%95%B0 title=母函数>母函数</a>
<a href=/tags/%E7%9F%A9%E9%98%B5 title=矩阵>矩阵</a>
<a href=/tags/%E7%BA%BF%E6%AE%B5%E6%A0%91 title=线段树>线段树</a>
<a href=/tags/%E8%AE%A1%E7%AE%97%E5%87%A0%E4%BD%95 title=计算几何>计算几何</a></div></section><section><hr><h5>FRIENDS</h5><ul class=list-inline><li><a target=_blank href=https://111qqz.com>111qqz的wordpress博客</a></li></ul></section></div></div></div></article><footer><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><ul class="list-inline text-center"><li><a href rel=alternate type=application/rss+xml title=111qqz的小窝><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-rss fa-stack-1x fa-inverse"></i></span></a></li><li><a href=mailto:hust.111qqz@gmail.com><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-envelope fa-stack-1x fa-inverse"></i></span></a></li><li><a target=_blank href=/img/wechat.jpg><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-wechat fa-stack-1x fa-inverse"></i></span></a></li><li><a target=_blank href=https://github.com/111qqz/><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-github fa-stack-1x fa-inverse"></i></span></a></li></ul><p class="copyright text-muted">Copyright &copy; 111qqz的小窝 2022<br><a href=https://beian.miit.gov.cn/>粤ICP备18103363号</a><br><a href=https://themes.gohugo.io/hugo-theme-cleanwhite>CleanWhite Hugo Theme</a> by <a href=https://zhaohuabing.com>Huabing</a> |
<iframe style=margin-left:2px;margin-bottom:-5px frameborder=0 scrolling=0 width=100px height=20px src="https://ghbtns.com/github-btn.html?user=zhaohuabing&repo=hugo-theme-cleanwhite&type=star&count=true"></iframe></p></div></div></div></footer><script>function async(u,c){var d=document,t='script',o=d.createElement(t),s=d.getElementsByTagName(t)[0];o.src=u;if(c){o.addEventListener('load',function(e){c(null,e);},false);}
s.parentNode.insertBefore(o,s);}</script><script>if($('#tag_cloud').length!==0){async("/js/jquery.tagcloud.js",function(){$.fn.tagcloud.defaults={color:{start:'#bbbbee',end:'#0085a1'},};$('#tag_cloud a').tagcloud();})}</script><script>async("https://cdnjs.cloudflare.com/ajax/libs/fastclick/1.0.6/fastclick.js",function(){var $nav=document.querySelector("nav");if($nav)FastClick.attach($nav);})</script></body></html>
<!doctype html><html lang=zh-cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta property="og:site_name" content="111qqz的小窝"><meta property="og:type" content="article"><meta property="og:image" content="https://111qqz.github.io/img/2.png"><meta property="twitter:image" content="https://111qqz.github.io/img/2.png"><meta name=title content="Similarity learning 和Metric learning"><meta property="og:title" content="Similarity learning 和Metric learning"><meta property="twitter:title" content="Similarity learning 和Metric learning"><meta name=description content><meta property="og:description" content><meta property="twitter:description" content><meta property="twitter:card" content="summary"><meta name=keyword content="ACM,111qqz,商汤科技,hust,华中科技大学"><link rel="shortcut icon" href=/img/favicon.ico><title>Similarity learning 和Metric learning-111qqz的小窝</title><link rel=canonical href=/2018/02/similarity-learning-metric-learning/><link rel=stylesheet href=/css/iDisqus.min.css><link rel=stylesheet href=/css/bootstrap.min.css><link rel=stylesheet href=/css/hux-blog.min.css><link rel=stylesheet href=/css/syntax.css><link rel=stylesheet href=/css/zanshang.css><link href=//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css rel=stylesheet type=text/css><script src=/js/jquery.min.js></script><script src=/js/bootstrap.min.js></script><script src=/js/hux-blog.min.js></script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/styles/docco.min.css><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/highlight.min.js></script><script>hljs.initHighlightingOnLoad();</script><link rel=stylesheet href=/css/hux-blog.min.css><link rel=stylesheet href=/css/hux-blog.min-custom.css></head><nav class="navbar navbar-default navbar-custom navbar-fixed-top"><div class=container-fluid><div class="navbar-header page-scroll"><button type=button class=navbar-toggle>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span><span class=icon-bar></span><span class=icon-bar></span></button>
<a class=navbar-brand href=/>111qqz的小窝</a></div><div id=huxblog_navbar><div class=navbar-collapse><ul class="nav navbar-nav navbar-right"><li><a href=/>Home</a></li><li><a href=/categories/acm/>ACM-ICPC</a></li><li><a href=/categories/deep-learning/>深度学习</a></li><li><a href=/categories/mooc/>公开课</a></li><li><a href=/categories/%e5%85%b6%e4%bb%96/>其他</a></li><li><a href=/top/about/>ABOUT</a></li><li><a href=/search>SEARCH <img src=/img/search.png height=15 style=cursor:pointer alt=Search></a></li></ul></div></div></div></nav><script>var $body=document.body;var $toggle=document.querySelector('.navbar-toggle');var $navbar=document.querySelector('#huxblog_navbar');var $collapse=document.querySelector('.navbar-collapse');$toggle.addEventListener('click',handleMagic)
function handleMagic(e){if($navbar.className.indexOf('in')>0){$navbar.className=" ";setTimeout(function(){if($navbar.className.indexOf('in')<0){$collapse.style.height="0px"}},400)}else{$collapse.style.height="auto"
$navbar.className+=" in";}}</script><style type=text/css>header.intro-header{background-image:url(/img/2.png)}</style><header class=intro-header><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class=post-heading><div class=tags><a class=tag href=/tags/metric-learning title="Metric learning">Metric learning</a>
<a class=tag href=/tags/similarity-learning title="Similarity learning">Similarity learning</a>
<a class=tag href=/tags/triplet-loss title="triplet loss">triplet loss</a></div><h1>Similarity learning 和Metric learning</h1><h2 class=subheading></h2><span class=meta>Posted by
111qqz
on
Sunday, February 18, 2018
<span id=/2018/02/similarity-learning-metric-learning/ class="leancloud_visitors meta_data_item" data-flag-title><span class=post-meta-item-icon><span class="octicon octicon-eye"></span></span><i class="fa fa-eye"></i><span class=old-visitors-count style=display:none></span><span class=leancloud-visitors-count></span></span><script src=https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js></script><script>AV.initialize("UzhnsgbPvx1RFb2kNXUHpPtf-gzGzoHsz","OXOvoYGuwMv70Os5GOgaGEWT");</script><script type=text/javascript>function showTime(Counter){var query=new AV.Query(Counter);var entries=[];var $visitors=$(".leancloud_visitors");console.log("aaa")
$visitors.each(function(){entries.push($(this).attr("id").trim());});query.containedIn('url',entries);query.find().done(function(results){var COUNT_CONTAINER_REF='.leancloud-visitors-count';var OLD_COUNT_CONTAINER_REF='.old-visitors-count';for(var i=0;i<results.length;i++){var item=results[i];var url=item.get('url');var time=item.get('time');var element=document.getElementById(url);$(element).find(COUNT_CONTAINER_REF).text(time);}
for(var i=0;i<entries.length;i++){var url=entries[i];var element=document.getElementById(url);var countSpan=$(element).find(COUNT_CONTAINER_REF);if(countSpan.text()==''){var oldCountSpan=$(element).find(OLD_COUNT_CONTAINER_REF).text();if(oldCountSpan!=''){countSpan.text(0+parseInt(oldCountSpan));}else{countSpan.text(0);}}}}).fail(function(object,error){console.log("Error: "+error.code+" "+error.message);});}
function addCount(Counter){var $visitors=$(".leancloud_visitors");var url=$visitors.attr('id').trim();var title=$visitors.attr('data-flag-title').trim();var query=new AV.Query(Counter);con
query.equalTo("url",url);query.find({success:function(results){if(results.length>0){var counter=results[0];counter.fetchWhenSave(true);counter.increment("time");counter.save(null,{success:function(counter){var $element=$(document.getElementById(url));$element.find('.leancloud-visitors-count').text(counter.get('time'));},error:function(counter,error){console.log('Failed to save Visitor num, with error message: '+error.message);}});}else{var newcounter=new Counter();var acl=new AV.ACL();acl.setPublicReadAccess(true);acl.setPublicWriteAccess(true);newcounter.setACL(acl);newcounter.set("title",title);newcounter.set("url",url);var OLD_COUNT_CONTAINER_REF='.old-visitors-count';var $element=$(document.getElementById(url));var oldCountSpan=$element.find(OLD_COUNT_CONTAINER_REF).text();if(oldCountSpan!=''){newcounter.set("time",parseInt(oldCountSpan)+1);}else{newcounter.set("time",1);}
newcounter.save(null,{success:function(newcounter){var $element=$(document.getElementById(url));$element.find('.leancloud-visitors-count').text(newcounter.get('time'));},error:function(newcounter,error){console.log('Failed to create');}});}},error:function(error){console.log('Error:'+error.code+" "+error.message);}});}
$(function(){var Counter=AV.Object.extend("Counter");console.log("miao miao miao")
if($('.leancloud_visitors').length==1){addCount(Counter);}else{showTime(Counter);}});</script></span></div></div></div></div></header><article><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2
col-md-10 col-md-offset-1
post-container"><header><h2>TOC</h2></header><nav id=TableOfContents><ol><li><a href=#similarity_learninghttpsenwikipediaorgwikisimilarity_learning>Similarity_learning</a></li><li><a href=#metric-learning>Metric learning</a></li></ol></nav><h2 id=similarity_learninghttpsenwikipediaorgwikisimilarity_learning><a href=https://en.wikipedia.org/wiki/Similarity_learning>Similarity_learning</a></h2><p>相似性学习（Similarity learning ）有监督机器学习，它与回归和分类密切相关，但目标是从实例中学习一个相似函数，<strong>以衡量两个对象的相似程度或相关程度。</strong></p><p>Similarity learning通常有四种setups:</p><pre><code>  * regression similarity learning  在这种方式中，给出的数据是 ![(x_{i}^{1},x_{i}^{2})](https://wikimedia.org/api/rest_v1/media/math/render/svg/cfa249357a1b4a7baf332041d67e480d6bb1f8fb)
</code></pre><p>  和他们的相似度 <img src=https://wikimedia.org/api/rest_v1/media/math/render/svg/e8a6d6289f0a0adb278812a8723b4077de79a421 alt="y_{i}\in R">
.  目标是学习到一个函数<img src=https://wikimedia.org/api/rest_v1/media/math/render/svg/d91180d029bb8a4f43be5d76060581b861f65fb7 alt="f(x_{i}^{1},x_{i}^{2})\sim y_{i}">
，对于<img src=https://wikimedia.org/api/rest_v1/media/math/render/svg/cfa249357a1b4a7baf332041d67e480d6bb1f8fb alt=(x_{i}^{1},x_{i}^{2})>
 给出<strong>yi</strong>的近似值。
* Classification similarity learning  给出数据 <img src=https://wikimedia.org/api/rest_v1/media/math/render/svg/cfa249357a1b4a7baf332041d67e480d6bb1f8fb alt=(x_{i}^{1},x_{i}^{2})>
  和他们是否相似<img src=https://wikimedia.org/api/rest_v1/media/math/render/svg/e5c2ebeb5127a5306baf27c9c622a86aa35625f2 alt="y_{i}\in \{0,1\}">
 。目标是训练出一个分类器，能够完成对一组<img src=https://wikimedia.org/api/rest_v1/media/math/render/svg/cfa249357a1b4a7baf332041d67e480d6bb1f8fb alt=(x_{i}^{1},x_{i}^{2})>
 是否相似的二分类判断。
* Ranking similarity learning 给出有序三元组<img src=https://wikimedia.org/api/rest_v1/media/math/render/svg/1bb03478aa729d594350565f174c78a4b7d9e87c alt=(x_{i},x_{i}^{+},x_{i}^{-})>
，其中 <img src=https://wikimedia.org/api/rest_v1/media/math/render/svg/e87000dd6142b81d041896a30fe58f0c3acb2158 alt=x_{i}>
 is known to be more similar to <img src=https://wikimedia.org/api/rest_v1/media/math/render/svg/89b5a4feb798c9d34d33200239a28f02cc6df2c4 alt=x_{i}^{+}>
 than to <img src=https://wikimedia.org/api/rest_v1/media/math/render/svg/202021401f451c2ba4ab43eddb2f8644e2610249 alt=x_{i}^{-}>
 。目标是训练出一个函数，使得对于新的三元组 <img src=https://wikimedia.org/api/rest_v1/media/math/render/svg/2578f37761a5f2937eedca81f4c96b0ba45fbc15 alt=(x,x^{+},x^{-})>
，满足<img src=https://wikimedia.org/api/rest_v1/media/math/render/svg/c27924f2eec770183ce65e3c653e74a5c1c79c7e alt="f(x,x^{+})>f(x,x^{-})">
。容易看出，这种方式采取了比回归更弱的监督形式，因为不需要提供精确的相似性度量，只需要提供相似性的相对顺序。因此，这种ranking-based的相似性学习更容易应用于实际的大规模应用
* Locality sensitive hashing (LSH)   局部敏感哈希和普通哈希的不同就是，相似的项有更大的概率被放到同一个桶中。</p><p>顺便一提，这里有一个叫triplet loss 的概念，</p><p><img src=http://img.blog.csdn.net/20150707120209693 alt=这里写图片描述></p><p>如上图所示，triplet是一个三元组，这个三元组是这样构成的：从训练数据集中随机选一个样本，该样本称为Anchor，然后再随机选取一个和Anchor (记为x_a)属于同一类的样本和不同类的样本,这两个样本对应的称为Positive (记为x_p)和Negative (记为x_n)，由此构成一个（Anchor，Positive，Negative）三元组。</p><p><strong>我们发现，triplet loss 其实就是在ranking similarity learning 问题中，学习similarity function时的loss</strong></p><h2 id=metric-learning>Metric learning</h2><p>相似性学习与距离度量学习密切相关。度量学习的目标是在对象上学习一个距离函数。度量或距离函数必须遵循四个公理:<strong>非负性、不可分辨的恒等式、对称性和次可加性/三角形不等式</strong>。在实际应用中，度量学习算法忽略了不可分辨物体的身份条件，学习了一个伪度量。</p><hr><ul class=pager><li class=previous><a href=/2018/02/persion-reid-paper-list/ data-toggle=tooltip data-placement=top title="persion reid 论文列表">&larr;
Previous Post</a></li><li class=next><a href=/2018/02/deep-mutual-learning-notes/ data-toggle=tooltip data-placement=top title="Deep Mutual Learning（相互学习） 阅读笔记">Next
Post &rarr;</a></li></ul><div class=post-comment><span id=/2018/02/similarity-learning-metric-learning/ class=leancloud_visitors data-flag-title="Similarity learning 和Metric learning"><span class=post-meta-item-text>访问量 "/2018/02/similarity-learning-metric-learning/"</span>
<span class=leancloud-visitors-count></span><p></p></span><div id=vcomments></div><script src=//cdn1.lncld.net/static/js/3.0.4/av-min.js></script><script src=//unpkg.com/valine/dist/Valine.min.js></script><script type=text/javascript>new Valine({el:'#vcomments',appId:'UzhnsgbPvx1RFb2kNXUHpPtf-gzGzoHsz',appKey:'OXOvoYGuwMv70Os5GOgaGEWT',notify:true,verify:false,avatar:'retro',placeholder:'说点什么吧...',visitor:true});</script></div></div><div class="col-lg-8 col-lg-offset-2
col-md-10 col-md-offset-1
sidebar-container"><section><hr class="hidden-sm hidden-xs"><h5><a href=/tags/>FEATURED TAGS</a></h5><div class=tags><a href=/tags/bfs title=bfs>bfs</a>
<a href=/tags/binary-search title=binary-search>binary-search</a>
<a href=/tags/brute-force title=brute-force>brute-force</a>
<a href=/tags/dfs title=dfs>dfs</a>
<a href=/tags/dp title=dp>dp</a>
<a href=/tags/greedy title=greedy>greedy</a>
<a href=/tags/kmp title=kmp>kmp</a>
<a href=/tags/leetcode title=leetcode>leetcode</a>
<a href=/tags/math title=math>math</a>
<a href=/tags/number-theory title=number-theory>number-theory</a>
<a href=/tags/rmq title=rmq>rmq</a>
<a href=/tags/stl title=stl>stl</a>
<a href=/tags/%E5%89%8D%E7%BC%80%E5%92%8C title=前缀和>前缀和</a>
<a href=/tags/%E5%8D%9A%E5%BC%88%E8%AE%BA title=博弈论>博弈论</a>
<a href=/tags/%E5%9B%BE%E8%AE%BA title=图论>图论</a>
<a href=/tags/%E5%BF%AB%E9%80%9F%E5%B9%82 title=快速幂>快速幂</a>
<a href=/tags/%E6%95%B0%E4%BD%8Ddp title=数位dp>数位dp</a>
<a href=/tags/%E6%9E%84%E9%80%A0 title=构造>构造</a>
<a href=/tags/%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84 title=树状数组>树状数组</a>
<a href=/tags/%E6%A8%A1%E6%8B%9F title=模拟>模拟</a>
<a href=/tags/%E6%AF%8D%E5%87%BD%E6%95%B0 title=母函数>母函数</a>
<a href=/tags/%E7%9F%A9%E9%98%B5 title=矩阵>矩阵</a>
<a href=/tags/%E7%BA%BF%E6%AE%B5%E6%A0%91 title=线段树>线段树</a>
<a href=/tags/%E8%AE%A1%E7%AE%97%E5%87%A0%E4%BD%95 title=计算几何>计算几何</a></div></section><section><hr><h5>FRIENDS</h5><ul class=list-inline><li><a target=_blank href=https://111qqz.com>111qqz的wordpress博客</a></li></ul></section></div></div></div></article><footer><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><ul class="list-inline text-center"><li><a href rel=alternate type=application/rss+xml title=111qqz的小窝><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-rss fa-stack-1x fa-inverse"></i></span></a></li><li><a href=mailto:hust.111qqz@gmail.com><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-envelope fa-stack-1x fa-inverse"></i></span></a></li><li><a target=_blank href=/img/wechat.jpg><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-wechat fa-stack-1x fa-inverse"></i></span></a></li><li><a target=_blank href=https://github.com/111qqz/><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-github fa-stack-1x fa-inverse"></i></span></a></li></ul><p class="copyright text-muted">Copyright &copy; 111qqz的小窝 2022<br><a href=https://beian.miit.gov.cn/>粤ICP备18103363号</a><br><a href=https://themes.gohugo.io/hugo-theme-cleanwhite>CleanWhite Hugo Theme</a> by <a href=https://zhaohuabing.com>Huabing</a> |
<iframe style=margin-left:2px;margin-bottom:-5px frameborder=0 scrolling=0 width=100px height=20px src="https://ghbtns.com/github-btn.html?user=zhaohuabing&repo=hugo-theme-cleanwhite&type=star&count=true"></iframe></p></div></div></div></footer><script>function async(u,c){var d=document,t='script',o=d.createElement(t),s=d.getElementsByTagName(t)[0];o.src=u;if(c){o.addEventListener('load',function(e){c(null,e);},false);}
s.parentNode.insertBefore(o,s);}</script><script>if($('#tag_cloud').length!==0){async("/js/jquery.tagcloud.js",function(){$.fn.tagcloud.defaults={color:{start:'#bbbbee',end:'#0085a1'},};$('#tag_cloud a').tagcloud();})}</script><script>async("https://cdnjs.cloudflare.com/ajax/libs/fastclick/1.0.6/fastclick.js",function(){var $nav=document.querySelector("nav");if($nav)FastClick.attach($nav);})</script></body></html>
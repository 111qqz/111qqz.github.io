<!doctype html><html lang=zh-cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta property="og:site_name" content="111qqz的小窝"><meta property="og:type" content="article"><meta property="og:image" content="https://111qqz.github.io/img/2.png"><meta property="twitter:image" content="https://111qqz.github.io/img/2.png"><meta name=title content="推荐系统之 LFM (Latent Factor Model) 隐因子模型  学习笔记"><meta property="og:title" content="推荐系统之 LFM (Latent Factor Model) 隐因子模型  学习笔记"><meta property="twitter:title" content="推荐系统之 LFM (Latent Factor Model) 隐因子模型  学习笔记"><meta name=description content><meta property="og:description" content><meta property="twitter:description" content><meta property="twitter:card" content="summary"><meta name=keyword content="ACM,111qqz,商汤科技,hust,华中科技大学"><link rel="shortcut icon" href=/img/favicon.ico><title>推荐系统之 LFM (Latent Factor Model) 隐因子模型 学习笔记-111qqz的小窝</title><link rel=canonical href=/2018/02/Latent-Factor-Model-notes/><link rel=stylesheet href=/css/iDisqus.min.css><link rel=stylesheet href=/css/bootstrap.min.css><link rel=stylesheet href=/css/hux-blog.min.css><link rel=stylesheet href=/css/syntax.css><link rel=stylesheet href=/css/zanshang.css><link href=//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css rel=stylesheet type=text/css><script src=/js/jquery.min.js></script><script src=/js/bootstrap.min.js></script><script src=/js/hux-blog.min.js></script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/styles/docco.min.css><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/highlight.min.js></script><script>hljs.initHighlightingOnLoad();</script><link rel=stylesheet href=/css/hux-blog.min.css><link rel=stylesheet href=/css/hux-blog.min-custom.css></head><nav class="navbar navbar-default navbar-custom navbar-fixed-top"><div class=container-fluid><div class="navbar-header page-scroll"><button type=button class=navbar-toggle>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span><span class=icon-bar></span><span class=icon-bar></span></button>
<a class=navbar-brand href=/>111qqz的小窝</a></div><div id=huxblog_navbar><div class=navbar-collapse><ul class="nav navbar-nav navbar-right"><li><a href=/>Home</a></li><li><a href=/categories/acm/>ACM-ICPC</a></li><li><a href=/categories/deep-learning/>深度学习</a></li><li><a href=/categories/mooc/>公开课</a></li><li><a href=/categories/%e5%85%b6%e4%bb%96/>其他</a></li><li><a href=/top/about/>ABOUT</a></li><li><a href=/search>SEARCH <img src=/img/search.png height=15 style=cursor:pointer alt=Search></a></li></ul></div></div></div></nav><script>var $body=document.body;var $toggle=document.querySelector('.navbar-toggle');var $navbar=document.querySelector('#huxblog_navbar');var $collapse=document.querySelector('.navbar-collapse');$toggle.addEventListener('click',handleMagic)
function handleMagic(e){if($navbar.className.indexOf('in')>0){$navbar.className=" ";setTimeout(function(){if($navbar.className.indexOf('in')<0){$collapse.style.height="0px"}},400)}else{$collapse.style.height="auto"
$navbar.className+=" in";}}</script><style type=text/css>header.intro-header{background-image:url(/img/2.png)}</style><header class=intro-header><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class=post-heading><div class=tags><a class=tag href=/tags/latent-factor-model title="Latent Factor Model">Latent Factor Model</a>
<a class=tag href=/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F title=推荐系统>推荐系统</a></div><h1>推荐系统之 LFM (Latent Factor Model) 隐因子模型 学习笔记</h1><h2 class=subheading></h2><span class=meta>Posted by
111qqz
on
Friday, February 9, 2018
<span id=/2018/02/Latent-Factor-Model-notes/ class="leancloud_visitors meta_data_item" data-flag-title><span class=post-meta-item-icon><span class="octicon octicon-eye"></span></span><i class="fa fa-eye"></i><span class=old-visitors-count style=display:none></span><span class=leancloud-visitors-count></span></span><script src=https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js></script><script>AV.initialize("2dzJwxGKq4hbtg5R5NM8NTzJ-gzGzoHsz","RaYu8uGTiuiIjLISQppPVYWw");</script><script type=text/javascript>function showTime(Counter){var query=new AV.Query(Counter);var entries=[];var $visitors=$(".leancloud_visitors");$visitors.each(function(){entries.push($(this).attr("id").trim());});query.containedIn('url',entries);query.find().done(function(results){var COUNT_CONTAINER_REF='.leancloud-visitors-count';var OLD_COUNT_CONTAINER_REF='.old-visitors-count';for(var i=0;i<results.length;i++){var item=results[i];var url=item.get('url');var time=item.get('time');var element=document.getElementById(url);$(element).find(COUNT_CONTAINER_REF).text(time);}
for(var i=0;i<entries.length;i++){var url=entries[i];var element=document.getElementById(url);var countSpan=$(element).find(COUNT_CONTAINER_REF);if(countSpan.text()==''){var oldCountSpan=$(element).find(OLD_COUNT_CONTAINER_REF).text();if(oldCountSpan!=''){countSpan.text(0+parseInt(oldCountSpan));}else{countSpan.text(0);}}}}).fail(function(object,error){console.log("Error: "+error.code+" "+error.message);});}
function addCount(Counter){var $visitors=$(".leancloud_visitors");var url=$visitors.attr('id').trim();var title=$visitors.attr('data-flag-title').trim();var query=new AV.Query(Counter);query.equalTo("url",url);query.find({success:function(results){if(results.length>0){var counter=results[0];counter.fetchWhenSave(true);counter.increment("time");counter.save(null,{success:function(counter){var $element=$(document.getElementById(url));$element.find('.leancloud-visitors-count').text(counter.get('time'));},error:function(counter,error){console.log('Failed to save Visitor num, with error message: '+error.message);}});}else{var newcounter=new Counter();var acl=new AV.ACL();acl.setPublicReadAccess(true);acl.setPublicWriteAccess(true);newcounter.setACL(acl);newcounter.set("title",title);newcounter.set("url",url);var OLD_COUNT_CONTAINER_REF='.old-visitors-count';var $element=$(document.getElementById(url));var oldCountSpan=$element.find(OLD_COUNT_CONTAINER_REF).text();if(oldCountSpan!=''){newcounter.set("time",parseInt(oldCountSpan)+1);}else{newcounter.set("time",1);}
newcounter.save(null,{success:function(newcounter){var $element=$(document.getElementById(url));$element.find('.leancloud-visitors-count').text(newcounter.get('time'));},error:function(newcounter,error){console.log('Failed to create');}});}},error:function(error){console.log('Error:'+error.code+" "+error.message);}});}
$(function(){var Counter=AV.Object.extend("Counter");if($('.leancloud_visitors').length==1){addCount(Counter);}else{showTime(Counter);}});</script></span></div></div></div></div></header><article><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2
col-md-10 col-md-offset-1
post-container"><header><h2>TOC</h2></header><nav id=TableOfContents></nav><p>起因是被assgin了一个新的任务&mldr;..要死.</p><p>参考资料:</p><p><a href=http://blog.csdn.net/asd136912/article/details/78290679>推荐系统学习笔记之三 LFM (Latent Factor Model) 隐因子模型 + SVD (singular value decomposition) 奇异值分解</a></p><p><a href=http://blog.csdn.net/ice110956/article/details/21955461>基于矩阵分解的隐因子模型</a></p><p><a href=https://www.jianshu.com/p/356656ce2901>实时推荐系统的三种方式</a></p><p>先说下我的理解&mldr;</p><p>隐因子模型(LFM)是一种推荐算法,&ldquo;隐"可以理解成用户喜欢某个item的间接原因.</p><p>该算法的核心思想是转化成一个矩阵分解问题..</p><p>然后用传统机器学习算法去优化分解得到的矩阵&mldr;</p><blockquote>主要的优势如下：<blockquote></blockquote><pre><code>  * 比较容易编程实现，随机梯度下降方法依次迭代即可训练出模型。
  * 预测的精度比较高，预测准确率要高于基于领域的协同过滤以及基于内容CBR等方法。
  * 比较低的时间和空间复杂度，高维矩阵映射为两个低维矩阵节省了存储空间，训练过程比较费时，但是可以离线完成；评分预测一般在线计算，直接使用离线训练得到的参数，可以实时推荐。
  * 非常好的扩展性，如由SVD拓展而来的SVD++和 TIME SVD++。
</code></pre><p>矩阵分解的不足主要有：</blockquote></p><pre><code>  * 
</code></pre><blockquote>训练模型较为费时。</blockquote><pre><code>  * 
</code></pre><blockquote>推荐结果不具有很好的可解释性，无法用现实概念给分解出来的用户和物品矩阵的每个维度命名，只能理解为潜在语义空间。</blockquote><p>我们用user1,2,3表示用户，item 1,2,3表示物品，Rij表示用户i对于物品j的评分，也就是喜好度。那么我们需要得到一个关于用户-物品的二维矩阵，如下面的R。</p><p><img src=http://img.blog.csdn.net/20140324143046953 alt></p><p>常见的系统中，R是一个非常稀疏的矩阵，因为我们不可能得到所有用户对于所有物品的评分。于是利用稀疏的R，填充得到一个满矩阵R’就是我们的目的。</p><p>下面我们就来看看LFM是如何解决上面的问题的？对于一个给定的用户行为数据集（数据集包含的是所有的user, 所有的item，以及每个user有过行为的item列表），使用LFM对其建模后，我们可以得到如下图所示的模型：（假设数据集中有3个user, 4个item, LFM建模的分类数为4）</p><p> <img src=http://img.blog.csdn.net/20130812142043312 alt></p><p>R矩阵是user-item矩阵，矩阵值Rij表示的是user i 对item j的兴趣度，这正是我们要求的值。对于一个user来说，当计算出他对所有item的兴趣度后，就可以进行排序并作出推荐。LFM算法从数据集中抽取出若干主题，作为user和item之间连接的桥梁，将R矩阵表示为P矩阵和Q矩阵相乘。其中P矩阵是user-class矩阵，矩阵值Pij表示的是user i对class j的兴趣度；Q矩阵式class-item矩阵，矩阵值Qij表示的是item j在class i中的权重，权重越高越能作为该类的代表。所以LFM根据如下公式来计算用户U对物品I的兴趣度</p><p><img src=http://img.blog.csdn.net/20130812142048593 alt></p><p>我们发现使用LFM后，</p><pre><code>  1. 我们不需要关心分类的角度，结果都是基于用户行为统计自动聚类的，全凭数据自己说了算。
  2. 不需要关心分类粒度的问题，通过设置LFM的最终分类数就可控制粒度，分类数越大，粒度约细。
  3. 对于一个item，并不是明确的划分到某一类，而是计算其属于每一类的概率，是一种标准的软分类。
  4. 对于一个user，我们可以得到他对于每一类的兴趣度，而不是只关心可见列表中的那几个类。
  5. 对于每一个class，我们可以得到类中每个item的权重，越能代表这个类的item，权重越高。
</code></pre><p><strong>于是隐因子模型转化为矩阵分解问题</strong></p><p>然后就是通过传统机器学习算法训练</p><p>最优化问题&mldr;怎么训练就不说了&mldr;</p><p>看到很多地方问的P,Q矩阵的初始化的问题&mldr;</p><p>我看到的比较一般的做法是,全都随机,或者如果有pre train的数据,则使用这些数据&mldr;</p><hr><ul class=pager><li class=previous><a href=/2018/02/cuda-error-checking-notes/ data-toggle=tooltip data-placement=top title="cuda error checking 学习笔记">&larr;
Previous Post</a></li><li class=next><a href=/2018/02/cuda-thrust-notes/ data-toggle=tooltip data-placement=top title="cuda c++  基础算法库 thrust 学习笔记">Next
Post &rarr;</a></li></ul><div class=post-comment><span id=/2018/02/Latent-Factor-Model-notes/ class=leancloud_visitors data-flag-title="推荐系统之 LFM (Latent Factor Model) 隐因子模型  学习笔记"><span class=post-meta-item-text>访问量</span>
<span class=leancloud-visitors-count></span><p></p></span><div id=vcomments></div><script src=//cdn1.lncld.net/static/js/3.0.4/av-min.js></script><script src=//unpkg.com/valine/dist/Valine.min.js></script><script type=text/javascript>new Valine({el:'#vcomments',appId:'2dzJwxGKq4hbtg5R5NM8NTzJ-gzGzoHsz',appKey:'RaYu8uGTiuiIjLISQppPVYWw',notify:true,verify:false,avatar:'retro',placeholder:'说点什么吧...',visitor:true});</script></div></div><div class="col-lg-8 col-lg-offset-2
col-md-10 col-md-offset-1
sidebar-container"><section><hr class="hidden-sm hidden-xs"><h5><a href=/tags/>FEATURED TAGS</a></h5><div class=tags><a href=/tags/bfs title=bfs>bfs</a>
<a href=/tags/binary-search title=binary-search>binary-search</a>
<a href=/tags/brute-force title=brute-force>brute-force</a>
<a href=/tags/dfs title=dfs>dfs</a>
<a href=/tags/dp title=dp>dp</a>
<a href=/tags/greedy title=greedy>greedy</a>
<a href=/tags/kmp title=kmp>kmp</a>
<a href=/tags/leetcode title=leetcode>leetcode</a>
<a href=/tags/math title=math>math</a>
<a href=/tags/number-theory title=number-theory>number-theory</a>
<a href=/tags/rmq title=rmq>rmq</a>
<a href=/tags/stl title=stl>stl</a>
<a href=/tags/%E5%89%8D%E7%BC%80%E5%92%8C title=前缀和>前缀和</a>
<a href=/tags/%E5%8D%9A%E5%BC%88%E8%AE%BA title=博弈论>博弈论</a>
<a href=/tags/%E5%9B%BE%E8%AE%BA title=图论>图论</a>
<a href=/tags/%E5%BF%AB%E9%80%9F%E5%B9%82 title=快速幂>快速幂</a>
<a href=/tags/%E6%95%B0%E4%BD%8Ddp title=数位dp>数位dp</a>
<a href=/tags/%E6%9E%84%E9%80%A0 title=构造>构造</a>
<a href=/tags/%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84 title=树状数组>树状数组</a>
<a href=/tags/%E6%A8%A1%E6%8B%9F title=模拟>模拟</a>
<a href=/tags/%E6%AF%8D%E5%87%BD%E6%95%B0 title=母函数>母函数</a>
<a href=/tags/%E7%9F%A9%E9%98%B5 title=矩阵>矩阵</a>
<a href=/tags/%E7%BA%BF%E6%AE%B5%E6%A0%91 title=线段树>线段树</a>
<a href=/tags/%E8%AE%A1%E7%AE%97%E5%87%A0%E4%BD%95 title=计算几何>计算几何</a></div></section><section><hr><h5>FRIENDS</h5><ul class=list-inline><li><a target=_blank href=https://111qqz.com>111qqz的wordpress博客</a></li></ul></section></div></div></div></article><footer><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><ul class="list-inline text-center"><li><a href rel=alternate type=application/rss+xml title=111qqz的小窝><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-rss fa-stack-1x fa-inverse"></i></span></a></li><li><a href=mailto:hust.111qqz@gmail.com><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-envelope fa-stack-1x fa-inverse"></i></span></a></li><li><a target=_blank href=/img/wechat.jpg><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-wechat fa-stack-1x fa-inverse"></i></span></a></li><li><a target=_blank href=https://github.com/111qqz/><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-github fa-stack-1x fa-inverse"></i></span></a></li></ul><p class="copyright text-muted">Copyright &copy; 111qqz的小窝 2022<br><a href=https://beian.miit.gov.cn/>粤ICP备18103363号</a><br><a href=https://themes.gohugo.io/hugo-theme-cleanwhite>CleanWhite Hugo Theme</a> by <a href=https://zhaohuabing.com>Huabing</a> |
<iframe style=margin-left:2px;margin-bottom:-5px frameborder=0 scrolling=0 width=100px height=20px src="https://ghbtns.com/github-btn.html?user=zhaohuabing&repo=hugo-theme-cleanwhite&type=star&count=true"></iframe></p></div></div></div></footer><script>function async(u,c){var d=document,t='script',o=d.createElement(t),s=d.getElementsByTagName(t)[0];o.src=u;if(c){o.addEventListener('load',function(e){c(null,e);},false);}
s.parentNode.insertBefore(o,s);}</script><script>if($('#tag_cloud').length!==0){async("/js/jquery.tagcloud.js",function(){$.fn.tagcloud.defaults={color:{start:'#bbbbee',end:'#0085a1'},};$('#tag_cloud a').tagcloud();})}</script><script>async("https://cdnjs.cloudflare.com/ajax/libs/fastclick/1.0.6/fastclick.js",function(){var $nav=document.querySelector("nav");if($nav)FastClick.attach($nav);})</script></body></html>
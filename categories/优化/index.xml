<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>优化 on 111qqz的小窝</title><link>https://111qqz.com/categories/%E4%BC%98%E5%8C%96/</link><description>Recent content in 优化 on 111qqz的小窝</description><generator>Hugo -- gohugo.io</generator><language>zh</language><copyright>Copyright © 2012-2022 all rights reserved.</copyright><lastBuildDate>Sat, 21 Aug 2021 17:43:02 +0800</lastBuildDate><atom:link href="https://111qqz.com/categories/%E4%BC%98%E5%8C%96/index.xml" rel="self" type="application/rss+xml"/><item><title>ska::flat_hash_map 源码分析</title><link>https://111qqz.com/2021/08/ska_flat_hash_map_notes/</link><pubDate>Sat, 21 Aug 2021 17:43:02 +0800</pubDate><guid>https://111qqz.com/2021/08/ska_flat_hash_map_notes/</guid><description>
&lt;h2 id="背景">背景&lt;/h2>
&lt;p>最近在调研各种hashmap..
发现ska::flat hash map性能优秀。。于是来看看代码。。
发现最大的特点是,ska::flat_hash_map使用了带probe count上限的robin hood hashing&lt;/p></description></item><item><title>一次avx2在gcc上core dump的排查经历</title><link>https://111qqz.com/2021/07/core-dump-on-gcc-4-with-avx2/</link><pubDate>Thu, 22 Jul 2021 20:01:50 +0800</pubDate><guid>https://111qqz.com/2021/07/core-dump-on-gcc-4-with-avx2/</guid><description>
&lt;h2 id="背景">背景&lt;/h2>
&lt;p>起因是同事在实现int4的功能，结果流水线有一条死活过不了(gcc版本为4.8.5),一直core dump
经过初步排查，找出了如下最小可以复现的代码:&lt;/p></description></item><item><title>tensorRT 模型兼容性说明</title><link>https://111qqz.com/2020/03/tensorrt-model-compatibility-notes/</link><pubDate>Tue, 24 Mar 2020 12:26:01 +0800</pubDate><guid>https://111qqz.com/2020/03/tensorrt-model-compatibility-notes/</guid><description>
&lt;h2 id="名词说明">名词说明&lt;/h2>
&lt;ul>
&lt;li>CUDA. 一般来说指的是CUDA SDK. 目前经常使用的是CUDA 8.0和CUDA 10.1两个版本. 8.0和10.1都是SDK的版本号.&lt;/li>
&lt;li>CUDNN. The NVIDIA CUDA® Deep Neural Network library (cuDNN). 是一个可以为神经网络提供GPU加速的库&lt;/li>
&lt;li>compute capability. 是GPU的固有参数,可以理解为GPU的版本.越新的显卡该数值往往越高.&lt;/li>
&lt;li>tensorRT.NVIDIA TensorRT™ is an SDK for high-performance deep learning inference. 是一个深度学习推理库,旨在提供高性能的推理速度.&lt;/li>
&lt;li>plan file,也称为 engine plan. 是生成的tensorRT 模型文件.&lt;/li>
&lt;/ul>
&lt;h2 id="兼容性说明">兼容性说明&lt;/h2>
&lt;p>&lt;strong>Engine plan 的兼容性依赖于GPU的compute capability 和 TensorRT 版本, 不依赖于CUDA和CUDNN版本.&lt;/strong>&lt;/p></description></item><item><title>【施工中】 halide学习笔记</title><link>https://111qqz.com/2019/02/halide-notes/</link><pubDate>Mon, 18 Feb 2019 06:00:51 +0000</pubDate><guid>https://111qqz.com/2019/02/halide-notes/</guid><description>
&lt;blockquote>
&lt;blockquote>
&lt;h3 id="halide-is-a-programming-language-designed-to-make-it-easier-to-write-high-performance-image-and-array-processing-code-on-modern-machines">**Halide is a programming language designed to make it easier to write high-performance image and array processing code on modern machines. **&lt;/h3>&lt;/blockquote>
&lt;/blockquote>
&lt;p>halide有两个特性比较吸引人。一个是对于各种平台架构的支持。&lt;/p>
&lt;blockquote>
&lt;blockquote>
&lt;/blockquote>
&lt;pre>&lt;code> * CPU architectures: X86, ARM, MIPS, Hexagon, PowerPC
* Operating systems: Linux, Windows, macOS, Android, iOS, Qualcomm QuRT
* GPU Compute APIs: CUDA, OpenCL, OpenGL, OpenGL Compute Shaders, Apple Metal, Microsoft Direct X 12
&lt;/code>&lt;/pre>
&lt;/blockquote>
&lt;p>另一个是把计算什么和怎么计算(何时计算)分离开来。&lt;/p></description></item><item><title>优化学习笔记(1):Loop unrolling</title><link>https://111qqz.com/2019/01/loop-unrolling/</link><pubDate>Wed, 23 Jan 2019 11:51:46 +0000</pubDate><guid>https://111qqz.com/2019/01/loop-unrolling/</guid><description>
&lt;p>&lt;del>迫于生计，&lt;/del>最近要学习&lt;a href="http://halide-lang.org/">halide&lt;/a>&lt;/p>
&lt;p>先去学习/复习一下常见的编译优化技巧。&lt;/p>
&lt;p>loop unrolling，也就是循环展开，顾名思义，就是把循环展开来写。&lt;/p>
&lt;pre>&lt;code>normal loop:
int x;
for (x = 0; x &amp;lt; 100; x++)
{
delete(x);
}
after loop unrolling:
int x;
for (x = 0; x &amp;lt; 100; x += 5 )
{
delete(x);
delete(x + 1);
delete(x + 2);
delete(x + 3);
delete(x + 4);
}
&lt;/code>&lt;/pre>
&lt;p>循环展开是一种优化，可以手动实现也可以编译器自动实现。&lt;/p></description></item><item><title>CUDA C Best Practices Guide 阅读笔记（二） Heterogeneous Computing</title><link>https://111qqz.com/2018/02/cuda-c-best-practices-guide-heterogeneous-computing/</link><pubDate>Tue, 13 Feb 2018 06:38:38 +0000</pubDate><guid>https://111qqz.com/2018/02/cuda-c-best-practices-guide-heterogeneous-computing/</guid><description>
&lt;p>CUDA 编程涉及到在不同的平台上同时运行代码:包含CPU的host 和包含GPU的device.&lt;/p>
&lt;p>所以了解host和device的对性能优化是非常重要的。&lt;/p></description></item><item><title>CUDA C Best Practices Guide 阅读笔记（1） 并行计算方法论(APOD)</title><link>https://111qqz.com/2018/02/cuda-c-best-practices-parallel-computing-methodology/</link><pubDate>Mon, 12 Feb 2018 04:58:31 +0000</pubDate><guid>https://111qqz.com/2018/02/cuda-c-best-practices-parallel-computing-methodology/</guid><description>
&lt;p>APOD指的是Assess, Parallelize, Optimize, Deploy&lt;/p>
&lt;p>
&lt;img class="image_figure image_external" loading="lazy" src="http://docs.nvidia.com/cuda/cuda-c-best-practices-guide/graphics/apod-cycle.png" alt="Assess, Parallelize, Optimize, Deploy." />
&lt;/p>
&lt;p>如图所示，APOD过程是一个循环的过程，每次只进行一部分，从A到P到O到D,然后再进行下一轮的APOD&lt;/p></description></item><item><title>cuda c++ 基础算法库 thrust 学习笔记</title><link>https://111qqz.com/2018/02/cuda-thrust-notes/</link><pubDate>Sat, 10 Feb 2018 08:43:54 +0000</pubDate><guid>https://111qqz.com/2018/02/cuda-thrust-notes/</guid><description>
&lt;p>可以了解成并行版的STL(?&lt;/p>
&lt;p>过了一遍&lt;a href="http://docs.nvidia.com/cuda/thrust/index.html">nvidia的官方网文档&lt;/a>&lt;/p>
&lt;p>发现如果熟悉STL的话,thrust没什么太多好说的,看起来很简单&amp;hellip;&lt;/p>
&lt;p>不过还是开一篇记录一下,一段时间内估计要和cuda c++ 打交道,就当记录使用过程中遇到的问题吧.&lt;/p></description></item><item><title>cuda error checking 学习笔记</title><link>https://111qqz.com/2018/02/cuda-error-checking-notes/</link><pubDate>Fri, 09 Feb 2018 06:55:00 +0000</pubDate><guid>https://111qqz.com/2018/02/cuda-error-checking-notes/</guid><description>
&lt;p>由于发现cuda c++ 的 debug方式和c++ 差别很大,因此打算再开一篇,专门记录一些和error checking 以及debug有关的内容.&lt;/p>
&lt;p>Error checks in CUDA code can help catch CUDA errors at their source. There are 2 sources of errors in CUDA source code:&lt;/p></description></item><item><title>cuda 学习笔记</title><link>https://111qqz.com/2018/02/cuda-notes/</link><pubDate>Thu, 01 Feb 2018 07:20:04 +0000</pubDate><guid>https://111qqz.com/2018/02/cuda-notes/</guid><description>
&lt;p>uodate:有毒吧。kernel中出问题原来是不会报错的。。。。&lt;/p>
&lt;p>请教了组里的hust学长orz..、&lt;/p>
&lt;p>学到了cuda-memcheck命令和cudaGetLastError来查看问题。。可以参考&lt;a href="https://stackoverflow.com/questions/14038589/what-is-the-canonical-way-to-check-for-errors-using-the-cuda-runtime-api">What is the canonical way to check for errors using the CUDA runtime API?&lt;/a>&lt;/p></description></item></channel></rss>
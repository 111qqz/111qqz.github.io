<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>计算机视觉 on 111qqz的小窝</title><link>https://111qqz.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/</link><description>Recent content in 计算机视觉 on 111qqz的小窝</description><generator>Hugo -- gohugo.io</generator><language>zh</language><copyright>Copyright © 2012-2022 all rights reserved.</copyright><lastBuildDate>Sat, 02 May 2020 18:50:06 +0800</lastBuildDate><atom:link href="https://111qqz.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/index.xml" rel="self" type="application/rss+xml"/><item><title>Focal Loss for Dense Object Detection(RetinaNet) 学习笔记</title><link>https://111qqz.com/2020/05/retinanet-notes/</link><pubDate>Sat, 02 May 2020 18:50:06 +0800</pubDate><guid>https://111qqz.com/2020/05/retinanet-notes/</guid><description>
&lt;p&gt;先写个简略版的笔记..看之后的情况要不要读得更精细一点..&lt;/p&gt;
&lt;h2 id="背景"&gt;背景&lt;/h2&gt;
&lt;p&gt;two stage的检测比one stage的检测效果好,原因是啥?&lt;/p&gt;
&lt;p&gt;作者认为是正负样本不平衡导致的. two stage的方法在proposal 的时候干掉了大部分负样本,所以效果好.&lt;/p&gt;</description></item><item><title>记一次faster-rcnn debug记录</title><link>https://111qqz.com/2019/12/debug-faster-rcnn-once-again/</link><pubDate>Fri, 13 Dec 2019 16:32:14 +0800</pubDate><guid>https://111qqz.com/2019/12/debug-faster-rcnn-once-again/</guid><description>
&lt;h2 id="问题描述"&gt;问题描述&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;一年debug 三次faster rcnn,每次都有新感觉（不&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;接到一个bug report,现象为某人脸模型，转换成trt模型，当batch size为1时结果完全正确，但是batch size大于1时结果不正确。
具体的现象是，如果跑多张不同的图，只有第一张图有结果，后面的图都没有结果。
如果跑的图中有相同的，那么和第一张相同的图都会有结果，其余的图没有结果。&lt;/p&gt;</description></item><item><title>FPN:Feature Pyramid Networks 学习笔记</title><link>https://111qqz.com/2019/12/feature-pyramid-networks/</link><pubDate>Sun, 08 Dec 2019 17:30:50 +0800</pubDate><guid>https://111qqz.com/2019/12/feature-pyramid-networks/</guid><description>
&lt;p&gt;检测不同尺度的物体一直是计算机视觉领域中比较有挑战性的事情．我们先从之前的工作出发，并对比FPN比起之前的工作有哪些改进．&lt;/p&gt;
&lt;h2 id="之前的工作"&gt;之前的工作&lt;/h2&gt;
&lt;h3 id="featurized-image-pyramid"&gt;Featurized image pyramid&lt;/h3&gt;
&lt;p&gt;
&lt;img class="image_figure image_external" loading="lazy" src="https://111qqz.com/images/migrated/loli/vhsEbJoYNBcMKdk.png" alt="Featurized image pyramid.png" /&gt;
&lt;/p&gt;
&lt;p&gt;思路是对于同一张图，生成不同的scale，然后每个scale的image单独去做检测．
这个方法是手工设计feautre时代的常用办法．
这个办法是比较显然的，也的确可以解决检测不同尺度物体的问题．
缺点非常明显...inference的速度几乎和scale的个数线性相关．
以及由于显存的开销，没办法做end-to-end 的training.&lt;/p&gt;</description></item><item><title>SSD: Single Shot MultiBox Detector 学习笔记</title><link>https://111qqz.com/2019/12/single-short-detector/</link><pubDate>Sun, 08 Dec 2019 15:00:15 +0800</pubDate><guid>https://111qqz.com/2019/12/single-short-detector/</guid><description>
&lt;h2 id="概述"&gt;概述&lt;/h2&gt;
&lt;p&gt;SSD是一种单阶段目标检测算法．所谓单阶段，是指只使用了一个deep neural network,而不是像faster-rcnn这种两阶段网络．
为什么有了faster-rcnn还要使用SSD? 最主要是慢...
两阶段网络虽然准确率高，但是在嵌入式等算力不足的设备上做inference速度非常感人，很难达到real time的要求．
（实际业务上也是这样，公有云上的检测模型几乎都是faster-rcnn,而到了一些盒子之类的硬件设备，检测模型就全是SSD等single stage 模型了)&lt;/p&gt;</description></item><item><title>Kubernetes(k8s)在深度学习模型转换方面的探索</title><link>https://111qqz.com/2019/11/K8s-for-Model-Conversion/</link><pubDate>Fri, 22 Nov 2019 11:14:19 +0800</pubDate><guid>https://111qqz.com/2019/11/K8s-for-Model-Conversion/</guid><description>
&lt;p&gt;年中的时候接了离职的同事模型转换的锅，在不断地更新迭代的过程中，发现了一些痛点。
发现k8s能够解决一部分痛点，因此来分享一下在这方面的探索。&lt;/p&gt;
&lt;h2 id="什么是模型转换"&gt;什么是模型转换&lt;/h2&gt;
&lt;p&gt;简单来说，深度学习模型的流程分为training和inference两部分。训练时用的一般是pytorch等框架，这些框架训练出的model是没办法直接部署在各个硬件平台上做inference的。因此需要将使用训练框架得到的模型，转换为能够部署到各个硬件平台上的模型。这个过程就是模型转换。&lt;/p&gt;</description></item><item><title>faster rcnn 模型 tensorrt4与tensorrt5 结果不一致 踩坑记录</title><link>https://111qqz.com/2019/11/debug-Frcnn-Model-When-Upgrading-From-Tensorrt4-to-Tensorrt5/</link><pubDate>Thu, 07 Nov 2019 23:40:39 +0800</pubDate><guid>https://111qqz.com/2019/11/debug-Frcnn-Model-When-Upgrading-From-Tensorrt4-to-Tensorrt5/</guid><description>
&lt;p&gt;最近有同事report给我们,用同一个模型转换工具,转同一个faster rcnn 模型, 同样的sdk代码,在有些显卡上结果正常,但是再比较新的显卡上(比如Titan V)上 结果完全不正确.&lt;/p&gt;</description></item><item><title>Anchor Box Algorithm</title><link>https://111qqz.com/2019/07/Anchor-Box-Algorithm/</link><pubDate>Mon, 01 Jul 2019 19:53:24 +0800</pubDate><guid>https://111qqz.com/2019/07/Anchor-Box-Algorithm/</guid><description>
&lt;h2 id="动机"&gt;动机&lt;/h2&gt;
&lt;p&gt;将一张图分成多个grid cell进行检测之后,每个cell只能检测到一个object.
如果这个grid cell中不止有一个物体要怎么办呢? 因此提出了anchor box algorithm来解决这个问题.&lt;/p&gt;</description></item><item><title>目标检测领域的滑动窗口算法</title><link>https://111qqz.com/2019/06/sliding-windows/</link><pubDate>Sun, 30 Jun 2019 16:55:40 +0800</pubDate><guid>https://111qqz.com/2019/06/sliding-windows/</guid><description>
&lt;p&gt;对象检测（Object Detection）的目的是”识别对象并给出其在图中的确切位置”，其内容可解构为三部分：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;识别某个对象（Classification）；&lt;/li&gt;
&lt;li&gt;给出对象在图中的位置（Localization）；&lt;/li&gt;
&lt;li&gt;识别图中所有的目标及其位置（Detection）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;本文将介绍&lt;strong&gt;滑动窗口&lt;/strong&gt;这一方法.&lt;/p&gt;</description></item><item><title>caffe2 添加自定义operater</title><link>https://111qqz.com/2018/04/add-custom-operation-in-caffe2/</link><pubDate>Fri, 13 Apr 2018 03:08:19 +0000</pubDate><guid>https://111qqz.com/2018/04/add-custom-operation-in-caffe2/</guid><description>
&lt;p&gt;记录一些一个没有之前没有接触过caffe/caffe2的人为了添加自定义的op 到caffe2需要做的工作.&lt;/p&gt;
&lt;p&gt;首先参考caffe2 tutorial,随便跑个op来试试,不妨以比较简单的  &lt;a href="https://caffe2.ai/docs/operators-catalogue.html#accumulate"&gt;Accumulate_op&lt;/a&gt; 为例子.&lt;/p&gt;</description></item><item><title>非极大值抑制（Non-Maximum Suppression，NMS）</title><link>https://111qqz.com/2018/03/non-maximum-suppression/</link><pubDate>Fri, 16 Mar 2018 02:56:14 +0000</pubDate><guid>https://111qqz.com/2018/03/non-maximum-suppression/</guid><description>
&lt;p&gt;NMS是为了在诸多CV任务如边缘检测，目标检测等，找到&lt;strong&gt;局部最大值&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;其主要思想是先设定一个阈值，然后计算检测框的IOU(所谓IOU，也就是intersection-over-union，指的是相交面积除以相并面积，是来衡量overlap程度的指数）。如果IOU大于阈值，说明overlap过大，我们要通过某种算法来将其剔除。&lt;/strong&gt;&lt;/p&gt;</description></item><item><title>reid 相关任务记录</title><link>https://111qqz.com/2018/02/reid-task-notes/</link><pubDate>Sat, 24 Feb 2018 04:34:02 +0000</pubDate><guid>https://111qqz.com/2018/02/reid-task-notes/</guid><description>
&lt;p&gt;被师兄（同事？）普及了一番实验规范orz...&lt;/p&gt;
&lt;p&gt;我还是太年轻了&lt;/p&gt;
&lt;p&gt;所谓的一个fc的版本是右边的．一个放着不动，另一个在sequence_len（１０）的维度上做ave,然后再expand成原来的维度．如下图．&lt;/p&gt;</description></item><item><title>分类评价指标之Cumulative Match Characteristi (CMC)曲线</title><link>https://111qqz.com/2018/02/cumulative-Match-characteristi/</link><pubDate>Fri, 23 Feb 2018 08:20:55 +0000</pubDate><guid>https://111qqz.com/2018/02/cumulative-Match-characteristi/</guid><description>
&lt;p&gt;CMC曲线全称是Cumulative Match Characteristic (CMC) curve，也就是累积匹配曲线，同ROC曲线Receiver Operating Characteristic (ROC) curve一样，是模式识别系统，如人脸，指纹，虹膜等的重要评价指标，尤其是在生物特征识别系统中，一般同ROC曲线（ &lt;a href="https://111qqz.com/2021/08/ska_flat_hash_map_notes/"&gt;多标签图像分类任务的评价方法-mean average precision(mAP) 以及top x的评价方法&lt;/a&gt;）一起给出，能够综合评价出算法的好坏。&lt;/p&gt;</description></item><item><title>光流法初探</title><link>https://111qqz.com/2018/02/Optical-flow-notes/</link><pubDate>Thu, 22 Feb 2018 09:03:48 +0000</pubDate><guid>https://111qqz.com/2018/02/Optical-flow-notes/</guid><description>
&lt;p&gt;算是CV领域的传统算法了&lt;/p&gt;
&lt;p&gt;只写两句话就够了。&lt;/p&gt;
&lt;blockquote&gt;**它是空间运动物体在观察成像平面上的像素运动的瞬时速度，是利用图像序列中像素在时间域上的变化以及相邻帧之间的相关性来找到上一帧跟当前帧之间存在的对应关系，从而计算出相邻帧之间物体的运动信息的一种方法。**
&lt;p&gt;&lt;strong&gt;研究光流场的目的就是为了从图片序列中近似得到不能直接得到的运动场。运动场，其实就是物体在三维真实世界中的运动；光流场，是运动场在二维图像平面上（人的眼睛或者摄像头）的投影。&lt;/strong&gt;&lt;/blockquote&gt;&lt;/p&gt;</description></item><item><title>end-to-end 神经网络</title><link>https://111qqz.com/2018/02/end-to-end-neural-network/</link><pubDate>Thu, 22 Feb 2018 02:53:01 +0000</pubDate><guid>https://111qqz.com/2018/02/end-to-end-neural-network/</guid><description>
&lt;p&gt;所谓end-to-end 神经网络，更多是一种思想。&lt;/p&gt;
&lt;p&gt;这种思想的核心是，比如对于图像处理，输入原始图像数据，输出的是直接有用的结果（有用取决于具体的任务，比如自动驾驶)&lt;/p&gt;</description></item><item><title>Pose-driven Deep Convolutional Model for Person Re-identification 阅读笔记</title><link>https://111qqz.com/2018/02/pose-driven-deep-convolutional-model-for-person-re-identification/</link><pubDate>Thu, 22 Feb 2018 02:25:00 +0000</pubDate><guid>https://111qqz.com/2018/02/pose-driven-deep-convolutional-model-for-person-re-identification/</guid><description>
&lt;p&gt;&lt;a href="https://arxiv.org/abs/1709.08325"&gt;1709.08325&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Reid问题指的是判断一个probe person 是否在被不同的camera捕获的gallery person 中出现。&lt;/p&gt;
&lt;p&gt;通常是如下情景：给出一个特定camera下某个特定人的probe image 或者 video sequence，从其他camera处询问这个人的图像，地点，时间戳。&lt;/p&gt;</description></item><item><title>Deep Mutual Learning（相互学习） 阅读笔记</title><link>https://111qqz.com/2018/02/deep-mutual-learning-notes/</link><pubDate>Sun, 18 Feb 2018 10:46:35 +0000</pubDate><guid>https://111qqz.com/2018/02/deep-mutual-learning-notes/</guid><description>
&lt;p&gt;&lt;a href="https://arxiv.org/abs/1706.00384"&gt;原始论文&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;DNN在很多问题上效果很不错，但是由于深度和宽度过大，导致需要的执行时间和内存过大。我们需要讨论一些能快速执行并且对内存的需要不大的模型。&lt;/p&gt;
&lt;p&gt;已经有很多方法来做这件事，比较重要的是Model distillation（模型蒸馏）&lt;/p&gt;</description></item><item><title>Similarity learning 和Metric learning</title><link>https://111qqz.com/2018/02/similarity-learning-metric-learning/</link><pubDate>Sun, 18 Feb 2018 08:14:10 +0000</pubDate><guid>https://111qqz.com/2018/02/similarity-learning-metric-learning/</guid><description>
&lt;h2 id="similarity_"&gt;&lt;a href="https://en.wikipedia.org/wiki/Similarity_learning"&gt;Similarity_learning&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;相似性学习（Similarity learning ）有监督机器学习，它与回归和分类密切相关，但目标是从实例中学习一个相似函数，&lt;strong&gt;以衡量两个对象的相似程度或相关程度。&lt;/strong&gt;&lt;/p&gt;</description></item><item><title>persion reid 论文列表</title><link>https://111qqz.com/2018/02/persion-reid-paper-list/</link><pubDate>Sat, 17 Feb 2018 07:17:49 +0000</pubDate><guid>https://111qqz.com/2018/02/persion-reid-paper-list/</guid><description>
&lt;p&gt;Key:&lt;/p&gt;
&lt;p&gt;(1). Pose-driven, body part alignment, combine whole feature and body part feature, focus on alignment of part model,&lt;/p&gt;
&lt;p&gt;(2). Combine image label and human attributes classes, do classification with attributes and identity learning&lt;/p&gt;
&lt;p&gt;(3). Based on triplet loss, improve metric learning for an end to end learning&lt;/p&gt;
&lt;p&gt;(4). Post-process, re-ranking&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;AlignedReID: Surpassing Human-Level Performance in Person Re-Identification&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Hydraplus-net: Attentive deep features for pedestrian analysis.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Darkrank: Accelerating deep metric learning via cross sample similarities transfer.&lt;/p&gt;</description></item><item><title>多标签图像分类任务的评价方法-mean average precision(mAP) 以及top x的评价方法</title><link>https://111qqz.com/2018/02/mean-average-precision-for-multi-label-classification-task/</link><pubDate>Fri, 09 Feb 2018 03:53:09 +0000</pubDate><guid>https://111qqz.com/2018/02/mean-average-precision-for-multi-label-classification-task/</guid><description>
&lt;p&gt;参考资料:&lt;/p&gt;
&lt;p&gt;&lt;a href="http://blog.sina.com.cn/s/blog_9db078090102whzw.html"&gt;多标签图像分类任务的评价方法-mAP&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity"&gt;wiki_Sensitivity and specificity&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://blog.sciencenet.cn/blog-605185-617068.html"&gt;False Positives和False Negative等含义&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.zhihu.com/question/41540197/answer/91698989"&gt;mean average precision（MAP）在计算机视觉中是如何计算和应用的？&lt;/a&gt;&lt;/p&gt;</description></item><item><title>Non-local Neural Networks 阅读笔记</title><link>https://111qqz.com/2018/02/non-local-neural-networks-notes/</link><pubDate>Mon, 05 Feb 2018 02:24:34 +0000</pubDate><guid>https://111qqz.com/2018/02/non-local-neural-networks-notes/</guid><description>
&lt;p&gt;先粗略读了2遍orz.可能不够严谨，先写一些high-level的理解。&lt;/p&gt;
&lt;p&gt;对于序列或者图片数据，如果想获得一个long-range的依赖，通常的做法是循环神经网络（对于序列）或者深层的卷积神经网络（对于图片数据）&lt;/p&gt;</description></item><item><title>non-local means algorithm 学习笔记</title><link>https://111qqz.com/2018/01/non-local-means-algorithm-notes/</link><pubDate>Thu, 25 Jan 2018 02:53:52 +0000</pubDate><guid>https://111qqz.com/2018/01/non-local-means-algorithm-notes/</guid><description>
&lt;p&gt;终于忙完学校的事情可以干正事了orz&lt;/p&gt;
&lt;p&gt;这里会记录一些第一遍看paper的过程中遇到的一些影响理解的概念，不过大多不会深究，只算做粗浅的理解。&lt;/p&gt;
&lt;p&gt;1、高斯金字塔：&lt;/p&gt;</description></item></channel></rss>
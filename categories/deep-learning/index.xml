<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>deep-learning on 111qqz的小窝</title>
    <link>https://111qqz.github.io/categories/deep-learning/</link>
    <description>Recent content in deep-learning on 111qqz的小窝</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 26 Nov 2019 20:59:04 +0800</lastBuildDate>
    
	<atom:link href="https://111qqz.github.io/categories/deep-learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>rankboost 算法学习笔记</title>
      <link>https://111qqz.github.io/2019/boosting-algorithm/</link>
      <pubDate>Tue, 26 Nov 2019 20:59:04 +0800</pubDate>
      
      <guid>https://111qqz.github.io/2019/boosting-algorithm/</guid>
      <description>boosting 算法是什么． 机缘使然，接触到了 Boosting 算法．Boosting是一种通过组合弱学习器来产生强学习器的通用且有效的方法. 动机是基于如下观察:尽管委员</description>
    </item>
    
    <item>
      <title>Kubernetes(k8s)在深度学习模型转换方面的探索</title>
      <link>https://111qqz.github.io/2019/k8s-for-model-conversion/</link>
      <pubDate>Fri, 22 Nov 2019 11:14:19 +0800</pubDate>
      
      <guid>https://111qqz.github.io/2019/k8s-for-model-conversion/</guid>
      <description>年中的时候接了离职的同事模型转换的锅，在不断地更新迭代的过程中，发现了一些痛点。 发现k8s能够解决一部分痛点，因此来分享一下在这方面的探索。</description>
    </item>
    
    <item>
      <title>faster rcnn 模型 tensorrt4与tensorrt5 结果不一致 踩坑记录</title>
      <link>https://111qqz.github.io/2018/02/debug-frcnn-model-when-upgrading-from-tensorrt4-to-tensorrt5/</link>
      <pubDate>Thu, 07 Nov 2019 23:40:39 +0800</pubDate>
      
      <guid>https://111qqz.github.io/2018/02/debug-frcnn-model-when-upgrading-from-tensorrt4-to-tensorrt5/</guid>
      <description>最近有同事report给我们,用同一个模型转换工具,转同一个faster rcnn 模型, 同样的sdk代码,在有些显卡上结果正常,但是再比较新的显卡上</description>
    </item>
    
    <item>
      <title>Anchor Box Algorithm</title>
      <link>https://111qqz.github.io/2019/07/anchor-box-algorithm/</link>
      <pubDate>Mon, 01 Jul 2019 19:53:24 +0800</pubDate>
      
      <guid>https://111qqz.github.io/2019/07/anchor-box-algorithm/</guid>
      <description>动机 将一张图分成多个grid cell进行检测之后,每个cell只能检测到一个object. 如果这个grid cell中不止有一个物体要怎么办呢</description>
    </item>
    
    <item>
      <title>目标检测领域的滑动窗口算法</title>
      <link>https://111qqz.github.io/2019/06/sliding-windows/</link>
      <pubDate>Sun, 30 Jun 2019 16:55:40 +0800</pubDate>
      
      <guid>https://111qqz.github.io/2019/06/sliding-windows/</guid>
      <description>对象检测（Object Detection）的目的是”识别对象并给出其在图中的确切位置”，其内容可解构为三部分： 识别某个对象（Classifi</description>
    </item>
    
    <item>
      <title>caffe2 添加自定义operater</title>
      <link>https://111qqz.github.io/2018/04/add-custom-operation-in-caffe2/</link>
      <pubDate>Fri, 13 Apr 2018 03:08:19 +0000</pubDate>
      
      <guid>https://111qqz.github.io/2018/04/add-custom-operation-in-caffe2/</guid>
      <description>记录一些一个没有之前没有接触过caffe/caffe2的人为了添加自定义的op 到caffe2需要做的工作. 首先参考caffe2 tutoria</description>
    </item>
    
    <item>
      <title>非极大值抑制（Non-Maximum Suppression，NMS）</title>
      <link>https://111qqz.github.io/2018/03/non-maximum-suppression/</link>
      <pubDate>Fri, 16 Mar 2018 02:56:14 +0000</pubDate>
      
      <guid>https://111qqz.github.io/2018/03/non-maximum-suppression/</guid>
      <description>NMS是为了在诸多CV任务如边缘检测，目标检测等，找到局部最大值 其主要思想是先设定一个阈值，然后计算检测框的IOU(所谓IOU，也就是int</description>
    </item>
    
    <item>
      <title>reid 相关任务记录</title>
      <link>https://111qqz.github.io/2018/02/reid-task-notes/</link>
      <pubDate>Sat, 24 Feb 2018 04:34:02 +0000</pubDate>
      
      <guid>https://111qqz.github.io/2018/02/reid-task-notes/</guid>
      <description>被师兄（同事？）普及了一番实验规范orz&amp;hellip; 我还是太年轻了 所谓的一个fc的版本是右边的．一个放着不动，另一个在sequence_</description>
    </item>
    
    <item>
      <title>分类评价指标之Cumulative Match Characteristi (CMC)曲线</title>
      <link>https://111qqz.github.io/2018/02/cumulative-match-characteristi/</link>
      <pubDate>Fri, 23 Feb 2018 08:20:55 +0000</pubDate>
      
      <guid>https://111qqz.github.io/2018/02/cumulative-match-characteristi/</guid>
      <description>CMC曲线全称是Cumulative Match Characteristic (CMC) curve，也就是累积匹配曲线，同ROC曲线Receiver Operating Characteristic (ROC) curve一样，是模式识别系统，</description>
    </item>
    
    <item>
      <title>pytorch 函数笔记</title>
      <link>https://111qqz.github.io/2018/02/pytorch-function-notes/</link>
      <pubDate>Fri, 23 Feb 2018 02:55:25 +0000</pubDate>
      
      <guid>https://111qqz.github.io/2018/02/pytorch-function-notes/</guid>
      <description>记录一些常用的&amp;hellip;总去查文档也是有点麻烦 * tensor.view 的作用是reshape 比如 a = torch.range(1, 16) 得到一个tensor that has 16 elements from 1 to 16. 在a=a.vi</description>
    </item>
    
    <item>
      <title>光流法初探</title>
      <link>https://111qqz.github.io/2018/02/optical-flow-notes/</link>
      <pubDate>Thu, 22 Feb 2018 09:03:48 +0000</pubDate>
      
      <guid>https://111qqz.github.io/2018/02/optical-flow-notes/</guid>
      <description>算是CV领域的传统算法了 只写两句话就够了。 **它是空间运动物体在观察成像平面上的像素运动的瞬时速度，是利用图像序列中像素在时间域上的变化以及</description>
    </item>
    
    <item>
      <title>end-to-end 神经网络</title>
      <link>https://111qqz.github.io/2018/02/end-to-end-neural-network/</link>
      <pubDate>Thu, 22 Feb 2018 02:53:01 +0000</pubDate>
      
      <guid>https://111qqz.github.io/2018/02/end-to-end-neural-network/</guid>
      <description>所谓end-to-end 神经网络，更多是一种思想。 这种思想的核心是，比如对于图像处理，输入原始图像数据，输出的是直接有用的结果（有用取决于具</description>
    </item>
    
    <item>
      <title>Pose-driven Deep Convolutional Model for Person Re-identification 阅读笔记</title>
      <link>https://111qqz.github.io/2018/02/pose-driven-deep-convolutional-model-for-person-re-identification/</link>
      <pubDate>Thu, 22 Feb 2018 02:25:00 +0000</pubDate>
      
      <guid>https://111qqz.github.io/2018/02/pose-driven-deep-convolutional-model-for-person-re-identification/</guid>
      <description>1709.08325 Reid问题指的是判断一个probe person 是否在被不同的camera捕获的gallery person 中出现。 通常是如下情景：给出一个特定camera下某</description>
    </item>
    
    <item>
      <title>Deep Mutual Learning（相互学习） 阅读笔记</title>
      <link>https://111qqz.github.io/2018/02/deep-mutual-learning-notes/</link>
      <pubDate>Sun, 18 Feb 2018 10:46:35 +0000</pubDate>
      
      <guid>https://111qqz.github.io/2018/02/deep-mutual-learning-notes/</guid>
      <description>原始论文 DNN在很多问题上效果很不错，但是由于深度和宽度过大，导致需要的执行时间和内存过大。我们需要讨论一些能快速执行并且对内存的需要不大的</description>
    </item>
    
    <item>
      <title>Similarity learning 和Metric learning</title>
      <link>https://111qqz.github.io/2018/02/similarity-learning-metric-learning/</link>
      <pubDate>Sun, 18 Feb 2018 08:14:10 +0000</pubDate>
      
      <guid>https://111qqz.github.io/2018/02/similarity-learning-metric-learning/</guid>
      <description>Similarity_learning 相似性学习（Similarity learning ）有监督机器学习，它与回归和分类密切相关，但目标是从实例中学习一个相似函数，以衡量两个对象的相似程度或相</description>
    </item>
    
    <item>
      <title>persion reid 论文列表</title>
      <link>https://111qqz.github.io/2018/02/persion-reid-paper-list/</link>
      <pubDate>Sat, 17 Feb 2018 07:17:49 +0000</pubDate>
      
      <guid>https://111qqz.github.io/2018/02/persion-reid-paper-list/</guid>
      <description>Key: (1). Pose-driven, body part alignment, combine whole feature and body part feature, focus on alignment of part model, (2). Combine image label and human attributes classes, do classification with attributes and identity learning (3). Based on triplet loss, improve metric learning for an end to end learning (4). Post-process, re-ranking AlignedReID: Surpassing Human-Level Performance in Person Re-Identification Hydraplus-net: Attentive deep features for pedestrian analysis. Darkrank: Accelerating deep metric learning</description>
    </item>
    
    <item>
      <title>多标签图像分类任务的评价方法-mean average precision(mAP) 以及top x的评价方法</title>
      <link>https://111qqz.github.io/2018/02/mean-average-precision-for-multi-label-classification-task/</link>
      <pubDate>Fri, 09 Feb 2018 03:53:09 +0000</pubDate>
      
      <guid>https://111qqz.github.io/2018/02/mean-average-precision-for-multi-label-classification-task/</guid>
      <description>参考资料: 多标签图像分类任务的评价方法-mAP wiki_Sensitivity and specificity False Positives和False Negative等含义 mean average precision（MAP）在</description>
    </item>
    
    <item>
      <title>Non-local Neural Networks 阅读笔记</title>
      <link>https://111qqz.github.io/2018/02/non-local-neural-networks-notes/</link>
      <pubDate>Mon, 05 Feb 2018 02:24:34 +0000</pubDate>
      
      <guid>https://111qqz.github.io/2018/02/non-local-neural-networks-notes/</guid>
      <description>先粗略读了2遍orz.可能不够严谨，先写一些high-level的理解。 对于序列或者图片数据，如果想获得一个long-range的依赖，通常</description>
    </item>
    
    <item>
      <title>non-local means algorithm 学习笔记</title>
      <link>https://111qqz.github.io/2018/01/non-local-means-algorithm-notes/</link>
      <pubDate>Thu, 25 Jan 2018 02:53:52 +0000</pubDate>
      
      <guid>https://111qqz.github.io/2018/01/non-local-means-algorithm-notes/</guid>
      <description>终于忙完学校的事情可以干正事了orz 这里会记录一些第一遍看paper的过程中遇到的一些影响理解的概念，不过大多不会深究，只算做粗浅的理解。 1</description>
    </item>
    
    <item>
      <title>PCA &#43; kmeans</title>
      <link>https://111qqz.github.io/2017/11/pca-kmeans/</link>
      <pubDate>Sun, 26 Nov 2017 11:05:50 +0000</pubDate>
      
      <guid>https://111qqz.github.io/2017/11/pca-kmeans/</guid>
      <description>先记录一下PCA实战需要用到的安装包(arch下,python2环境) python2-scikit-learn python2-numpy python2-pandas python2-matplotlib python2-seaborn pandas.DataFrame pandas 数据结构介绍 几个和科学计算数据分析有关的重要的pytho</description>
    </item>
    
    <item>
      <title>反向传播学习笔记</title>
      <link>https://111qqz.github.io/2017/09/back-propagation-notes/</link>
      <pubDate>Tue, 05 Sep 2017 12:30:17 +0000</pubDate>
      
      <guid>https://111qqz.github.io/2017/09/back-propagation-notes/</guid>
      <description>先说下自己目前很笼统的理解： 反向传播是用来快速计算梯度的一种方法； 过程大概是把计算过程用计算图表示，这样每一个中间步骤都有一个节点，每一个l</description>
    </item>
    
    <item>
      <title>tensorflow input pipline  学习笔记</title>
      <link>https://111qqz.github.io/2017/08/tensorflow-input-pipline-notes/</link>
      <pubDate>Thu, 24 Aug 2017 09:12:58 +0000</pubDate>
      
      <guid>https://111qqz.github.io/2017/08/tensorflow-input-pipline-notes/</guid>
      <description>参考资料： tf_doc_Reading data TENSORFLOW INPUT PIPELINE EXAMPLE tensorflow：理解tensorflow中的输入管道 第二个参考资料是第一个的翻译版本，翻译的水平一般，建议看原文</description>
    </item>
    
    <item>
      <title>tensorflow 合并模型</title>
      <link>https://111qqz.github.io/2017/08/tensorflow-model-merging/</link>
      <pubDate>Mon, 21 Aug 2017 06:56:22 +0000</pubDate>
      
      <guid>https://111qqz.github.io/2017/08/tensorflow-model-merging/</guid>
      <description>在这里存个备份，还有些问题没有解决。 raise ValueError(&amp;ldquo;GraphDef cannot be larger than 2GB.&amp;rdquo;) 记录一些思路好了。现在是没有生成.meta文件，爆掉应该是因为所有的变量都加载到了默认图里</description>
    </item>
    
    <item>
      <title>tensorflow checkpoint 学习笔记</title>
      <link>https://111qqz.github.io/2017/08/tensorflow-checkpoint-notes/</link>
      <pubDate>Mon, 21 Aug 2017 02:03:45 +0000</pubDate>
      
      <guid>https://111qqz.github.io/2017/08/tensorflow-checkpoint-notes/</guid>
      <description>参考资料： What is the TensorFlow checkpoint meta file? TensorFlow: Restoring variables from from multiple checkpoints 合并模型的时候发现.meta一直在累加，而其他数据文件没有改变。因此来探究一下checkpoint的几</description>
    </item>
    
    <item>
      <title>tensorflow variable 学习笔记</title>
      <link>https://111qqz.github.io/2017/08/tensorflow-variable-notes/</link>
      <pubDate>Sun, 20 Aug 2017 09:36:00 +0000</pubDate>
      
      <guid>https://111qqz.github.io/2017/08/tensorflow-variable-notes/</guid>
      <description>参考资料： programmers_guide/variables tf/Variable 之前感觉对tensorflow 的variable的理解不是很深刻&amp;hellip;跑个模型啥的倒不会有什么问题，但是涉及分布式，</description>
    </item>
    
    <item>
      <title>tensorflow Session 学习笔记</title>
      <link>https://111qqz.github.io/2017/08/tensorflow-session-notes/</link>
      <pubDate>Sun, 20 Aug 2017 08:21:57 +0000</pubDate>
      
      <guid>https://111qqz.github.io/2017/08/tensorflow-session-notes/</guid>
      <description>tensorflow-session官方文档 说下我自己的理解： session中文一般叫会话，可以理解成op执行时候需要的一层虚拟化的封装。 o</description>
    </item>
    
    <item>
      <title>Distributed Tensorflow : Cannot assign a device for operation save</title>
      <link>https://111qqz.github.io/2017/08/distributed-tensorflow-cannot-assign-a-device-for-operation-save/</link>
      <pubDate>Mon, 14 Aug 2017 01:55:15 +0000</pubDate>
      
      <guid>https://111qqz.github.io/2017/08/distributed-tensorflow-cannot-assign-a-device-for-operation-save/</guid>
      <description>是在使用分布式tensorflow遇到的一个错误 报错如下： InvalidArgumentError (see above for traceback): Cannot assign a device for operation &amp;lsquo;save/Rest│| 2 GeForce GTX 1080 On | 0000:08:00.0 Off | N/A | oreV2_888&amp;rsquo;:</description>
    </item>
    
    <item>
      <title>分布式 tensorflow 学习笔记(非最终版)</title>
      <link>https://111qqz.github.io/2017/08/tensorflow-notes/</link>
      <pubDate>Mon, 07 Aug 2017 12:54:23 +0000</pubDate>
      
      <guid>https://111qqz.github.io/2017/08/tensorflow-notes/</guid>
      <description>感觉资料不是很多，先收集资料好了。 tf-distributed官网文档 SO-between-graph和in-graph的区别 inception.README.md SyncReplicasOptimizer SO_How does ps work in</description>
    </item>
    
    <item>
      <title>tensorflow Supervisor 学习笔记</title>
      <link>https://111qqz.github.io/2017/08/tensorflow-supervisor-notes/</link>
      <pubDate>Fri, 04 Aug 2017 09:22:44 +0000</pubDate>
      
      <guid>https://111qqz.github.io/2017/08/tensorflow-supervisor-notes/</guid>
      <description>update:supervisor的缺点是遇到问题只会抛异常，所以现在有一个better的管理工具,MonitoredSession master,chief worker,Supervisor 这几</description>
    </item>
    
    <item>
      <title>k-means clustering 学习笔记</title>
      <link>https://111qqz.github.io/2017/08/k-means-clustering-notes/</link>
      <pubDate>Thu, 03 Aug 2017 13:09:17 +0000</pubDate>
      
      <guid>https://111qqz.github.io/2017/08/k-means-clustering-notes/</guid>
      <description>其实这算法巨简单。。。。让我想到了均分纸牌（noip200? 还是大致说一下： 对于有 features 但是 没有 labels 的数据，没办法用监督学习，但是可以使用非监督学</description>
    </item>
    
    <item>
      <title>TensorFlow Architecture 学习笔记（二）Adding a New Op</title>
      <link>https://111qqz.github.io/2017/08/tensorflow-architecture-notes-2/</link>
      <pubDate>Wed, 02 Aug 2017 03:07:37 +0000</pubDate>
      
      <guid>https://111qqz.github.io/2017/08/tensorflow-architecture-notes-2/</guid>
      <description>Adding a New Op * [目录](https://www.tensorflow.org/extend/adding_an_op#top_of_page) *</description>
    </item>
    
    <item>
      <title>TensorFlow Architecture 学习笔记（一）</title>
      <link>https://111qqz.github.io/2017/08/tensorflow-architecture-notes-1/</link>
      <pubDate>Tue, 01 Aug 2017 03:01:12 +0000</pubDate>
      
      <guid>https://111qqz.github.io/2017/08/tensorflow-architecture-notes-1/</guid>
      <description>这篇文章不会涉及tensorflow的具体使用，而是专注于介绍tensorflow的架构，目的是让开发者能够对tensorflow现有框架进</description>
    </item>
    
    <item>
      <title>Long Short-Term Memory （LSTM） 网络 学习笔记</title>
      <link>https://111qqz.github.io/2017/07/lstm-notes/</link>
      <pubDate>Mon, 31 Jul 2017 10:05:01 +0000</pubDate>
      
      <guid>https://111qqz.github.io/2017/07/lstm-notes/</guid>
      <description>参考资料： 维基百科_长短期记忆(LSTM) Understanding LSTM Networks [译] 理解 LSTM 网络 LSTM笔记 翻译的比较一般，建议看原文&amp;hellip;.比如cell还是不要</description>
    </item>
    
    <item>
      <title>stanford cs 231n:常用激活函数</title>
      <link>https://111qqz.github.io/2017/07/common-activation-functions/</link>
      <pubDate>Sat, 22 Jul 2017 08:56:08 +0000</pubDate>
      
      <guid>https://111qqz.github.io/2017/07/common-activation-functions/</guid>
      <description>其实我觉得这部分可以直接黑箱。。。直接无脑上Leaky ReLU或者Maxou？不过对这些激活函数的特点有个high-level的了解应该总是</description>
    </item>
    
    <item>
      <title>how to copy &amp; modify nets model on tensorflow slim</title>
      <link>https://111qqz.github.io/2017/07/how-to-copy-modify-nets-model-on-tensorflow-slim/</link>
      <pubDate>Wed, 19 Jul 2017 06:21:40 +0000</pubDate>
      
      <guid>https://111qqz.github.io/2017/07/how-to-copy-modify-nets-model-on-tensorflow-slim/</guid>
      <description>想要修改tensorflow-slim 中 nets中的某个model,例如明明为kk_v2.py 观察到train_image_classifi</description>
    </item>
    
    <item>
      <title>Inception-v4,Inception-ResNet 和残差连接对学习的影响</title>
      <link>https://111qqz.github.io/2017/07/inception-resnet-notes/</link>
      <pubDate>Tue, 18 Jul 2017 02:42:50 +0000</pubDate>
      
      <guid>https://111qqz.github.io/2017/07/inception-resnet-notes/</guid>
      <description>原始论文 翻译链接 **——前言：**作者认为残差连接在训练深度卷积模型是很有必要的。至少在图像识别上，我们的研究似乎并不支持这一观点。 **摘要</description>
    </item>
    
    <item>
      <title>stanford CS231n notes：Linear classification</title>
      <link>https://111qqz.github.io/2017/07/cs231n-linear-classification/</link>
      <pubDate>Mon, 17 Jul 2017 02:02:43 +0000</pubDate>
      
      <guid>https://111qqz.github.io/2017/07/cs231n-linear-classification/</guid>
      <description>课程链接 知乎翻译链接 之前看的原版，后来发现知乎上有翻译，正好想到之前看完没有整理总结，干脆就写一下自己的理解，顺便贴一下课程翻译（感觉翻译的</description>
    </item>
    
    <item>
      <title>tensorflow slim 源码分析</title>
      <link>https://111qqz.github.io/2017/07/tensorflow-slim-code-notes/</link>
      <pubDate>Sun, 16 Jul 2017 13:10:04 +0000</pubDate>
      
      <guid>https://111qqz.github.io/2017/07/tensorflow-slim-code-notes/</guid>
      <description>py的源码看起来还是很愉快的。。。（虽然熟练成程度完全不如cpp。。。。 datasets里是数据集相关 deployment是部署相关 nets</description>
    </item>
    
    <item>
      <title>几种梯度下降(GD)法的比较（转载）</title>
      <link>https://111qqz.github.io/2017/07/gradient-descent-methods/</link>
      <pubDate>Mon, 10 Jul 2017 01:49:04 +0000</pubDate>
      
      <guid>https://111qqz.github.io/2017/07/gradient-descent-methods/</guid>
      <description>参考资料 机器学习中梯度下降（Gradient Descent， GD）算法只需要计算损失函数的一阶导数，计算代价小，非常适合训练数据非常大的应用</description>
    </item>
    
    <item>
      <title>Deep Learning Tutorial - PCA and Whitening</title>
      <link>https://111qqz.github.io/2017/07/deep-learning-tutorial-pca-and-whitening/</link>
      <pubDate>Thu, 06 Jul 2017 08:35:51 +0000</pubDate>
      
      <guid>https://111qqz.github.io/2017/07/deep-learning-tutorial-pca-and-whitening/</guid>
      <description>说下我自己的理解 PCA：主成分分析，是一种预处理手段。对于n维的数据，通过一些手段，把变化显著的k个维度保留，舍弃另外n-k个维度。对于一些</description>
    </item>
    
  </channel>
</rss>
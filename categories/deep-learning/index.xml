<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Deep-Learning on 111qqz的小窝</title><link>https://111qqz.com/categories/deep-learning/</link><description>Recent content in Deep-Learning on 111qqz的小窝</description><generator>Hugo -- gohugo.io</generator><language>zh</language><copyright>Copyright © 2012-2022 all rights reserved.</copyright><lastBuildDate>Sun, 17 Dec 2023 18:22:24 +0800</lastBuildDate><atom:link href="https://111qqz.com/categories/deep-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>caffe 源码阅读笔记</title><link>https://111qqz.com/2020/06/caffe-notes/</link><pubDate>Tue, 30 Jun 2020 19:47:02 +0800</pubDate><guid>https://111qqz.com/2020/06/caffe-notes/</guid><description>
&lt;p&gt;caffe做部署是YYDS!&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://111qqz.github.io/2020/01/caffe-source-code-analysis-part1/"&gt;blob&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://111qqz.github.io/2020/01/caffe-source-code-analysis-part2/"&gt;layer&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://111qqz.github.io/2020/01/caffe-source-code-analysis-part3/"&gt;net&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://111qqz.github.io/2020/04/caffe-source-code-analysis-part4/"&gt;激活函数&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://111qqz.github.io/2020/04/caffe-source-code-analysis-part5/"&gt;卷积&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://111qqz.github.io/2020/04/caffe-source-code-analysis-part6/"&gt;reshape&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://111qqz.github.io/2020/04/caffe-source-code-analysis-part7/"&gt;slice&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://111qqz.github.io/2020/04/caffe-source-code-analysis-part8/"&gt;loss function&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://111qqz.github.io/2020/05/caffe-source-code-analysis-part9/"&gt;reduce&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://111qqz.github.io/2020/05/caffe-source-code-analysis-part10/"&gt;eltwise&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://111qqz.github.io/2020/05/caffe-source-code-analysis-part11/"&gt;argmax&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;</description></item><item><title>[施工中] cupy与torch的导入顺序不同对计算结果的影响</title><link>https://111qqz.com/2023/12/cupy-torch-import-order-impact/</link><pubDate>Sun, 17 Dec 2023 18:22:24 +0800</pubDate><guid>https://111qqz.com/2023/12/cupy-torch-import-order-impact/</guid><description>
&lt;h2 id="背景"&gt;背景&lt;/h2&gt;
&lt;p&gt;公司内部的基于torch的toolbox发现某个版本之后,结果发生了偏移. 通过一系列排查,发现当导入cupy和torch的顺序不同时，计算结果会有所差异。
也就是说,如下两段代码会导致模型训练等环节的计算得到不同的结果.&lt;/p&gt;</description></item><item><title>Build Onnxruntime With Bazel</title><link>https://111qqz.com/2023/01/build-onnxruntime-with-bazel/</link><pubDate>Mon, 16 Jan 2023 16:28:22 +0800</pubDate><guid>https://111qqz.com/2023/01/build-onnxruntime-with-bazel/</guid><description>
&lt;h1 id="背景"&gt;背景&lt;/h1&gt;
&lt;p&gt;需要使用bazel build &lt;a href="https://github.com/microsoft/onnxruntime"&gt;onnxruntime&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;但是onnxruntime本身没有提供bazel相关的配置&lt;/p&gt;
&lt;h1 id="作为单独的repo"&gt;作为单独的repo&lt;/h1&gt;
&lt;p&gt;将onnxruntime的包&lt;a href="https://github.com/microsoft/onnxruntime/releases/download/v1.13.1/onnxruntime-linux-x64-1.13.1.tgz"&gt;下载&lt;/a&gt;下来解压&lt;/p&gt;
&lt;p&gt;主要的坑点在于动态库必须写全版本号，不然无法成功导入
完整的BUILD.bazel文件为&lt;/p&gt;</description></item><item><title>[施工中]caffe 源码学习笔记(11) softmax</title><link>https://111qqz.com/2022/08/caffe-source-code-analysis-part12/</link><pubDate>Sat, 06 Aug 2022 12:26:03 +0800</pubDate><guid>https://111qqz.com/2022/08/caffe-source-code-analysis-part12/</guid><description>
&lt;h2 id="背景"&gt;背景&lt;/h2&gt;
&lt;p&gt;2022年惊讶的发现，当时竟然没有写关于softmax的笔记，因此来补充一下。&lt;/p&gt;
&lt;h2 id="proto"&gt;proto&lt;/h2&gt;
&lt;p&gt;还是先看proto&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-protobuf" data-lang="protobuf"&gt;&lt;span class="line"&gt;&lt;span class="ln"&gt; 1&lt;/span&gt;&lt;span class="cl"&gt;&lt;span class="err"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="ln"&gt; 2&lt;/span&gt;&lt;span class="cl"&gt;&lt;span class="err"&gt;&lt;/span&gt;&lt;span class="c1"&gt;// Message that stores parameters used by SoftmaxLayer, SoftmaxWithLossLayer
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="ln"&gt; 3&lt;/span&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="kd"&gt;message&lt;/span&gt; &lt;span class="nc"&gt;SoftmaxParameter&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="err"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="ln"&gt; 4&lt;/span&gt;&lt;span class="cl"&gt;&lt;span class="err"&gt;&lt;/span&gt; &lt;span class="kd"&gt;enum&lt;/span&gt; &lt;span class="n"&gt;Engine&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="err"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="ln"&gt; 5&lt;/span&gt;&lt;span class="cl"&gt;&lt;span class="err"&gt;&lt;/span&gt; &lt;span class="n"&gt;DEFAULT&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="err"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="ln"&gt; 6&lt;/span&gt;&lt;span class="cl"&gt;&lt;span class="err"&gt;&lt;/span&gt; &lt;span class="n"&gt;CAFFE&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="err"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="ln"&gt; 7&lt;/span&gt;&lt;span class="cl"&gt;&lt;span class="err"&gt;&lt;/span&gt; &lt;span class="n"&gt;CUDNN&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="err"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="ln"&gt; 8&lt;/span&gt;&lt;span class="cl"&gt;&lt;span class="err"&gt;&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="err"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="ln"&gt; 9&lt;/span&gt;&lt;span class="cl"&gt;&lt;span class="err"&gt;&lt;/span&gt; &lt;span class="k"&gt;optional&lt;/span&gt; &lt;span class="n"&gt;Engine&lt;/span&gt; &lt;span class="n"&gt;engine&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="k"&gt;default&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;DEFAULT&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;&lt;span class="err"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="ln"&gt;10&lt;/span&gt;&lt;span class="cl"&gt;&lt;span class="err"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="ln"&gt;11&lt;/span&gt;&lt;span class="cl"&gt;&lt;span class="err"&gt;&lt;/span&gt; &lt;span class="c1"&gt;// The axis along which to perform the softmax -- may be negative to index
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="ln"&gt;12&lt;/span&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="c1"&gt;// from the end (e.g., -1 for the last axis).
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="ln"&gt;13&lt;/span&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="c1"&gt;// Any other axes will be evaluated as independent softmaxes.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="ln"&gt;14&lt;/span&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="k"&gt;optional&lt;/span&gt; &lt;span class="kt"&gt;int32&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="k"&gt;default&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;&lt;span class="err"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="ln"&gt;15&lt;/span&gt;&lt;span class="cl"&gt;&lt;span class="err"&gt;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="err"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;axis表示在哪个维护进行softmax&lt;/p&gt;</description></item><item><title>(CSE 599W)Reverse Mode Autodiff</title><link>https://111qqz.com/2021/04/reverse-mode-autodiff/</link><pubDate>Mon, 05 Apr 2021 14:44:25 +0800</pubDate><guid>https://111qqz.com/2021/04/reverse-mode-autodiff/</guid><description>
&lt;h2 id="背景"&gt;背景&lt;/h2&gt;
&lt;p&gt;怎么算微分。。通常有三种方法。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Symbolic Differentiation&lt;/li&gt;
&lt;li&gt;Numerical Differentiation&lt;/li&gt;
&lt;li&gt;Automatic Differentiation (auto diff)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="https://img.so/image/gqMwii"&gt;
&lt;img class="image_figure image_external" loading="lazy" src="https://111qqz.com/images/migrated/myximage/c8589036cb6d845eb07a05441e2d32f8.md.png" alt="c8589036cb6d845eb07a05441e2d32f8.md.png" /&gt;
&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://img.so/image/gqMENj"&gt;
&lt;img class="image_figure image_external" loading="lazy" src="https://111qqz.com/images/migrated/myximage/7f409550ef544562ea67816c7a884fcb.md.png" alt="7f409550ef544562ea67816c7a884fcb.md.png" /&gt;
&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;auto diff中两种主流的方式分别是forward-mode和reverse-mode
由于forward-mode的方法中，计算的时间复杂度是O(n),n是输入的参数个数。而reverse-mode中，计算的时间复杂度是O(m),m是输出节点的个数。在dnn中，n往往很大，远大于m，因此这里主要介绍reverse-mode auto diff方法。&lt;/p&gt;</description></item><item><title>【推荐系统】Toward the Next Generation of Recommender Systems: A Survey of the State-of-the-Art and Possible Extensions</title><link>https://111qqz.com/2020/01/toward-the-next-gen-of-recom-sys/</link><pubDate>Sat, 23 Jan 2021 17:42:15 +0800</pubDate><guid>https://111qqz.com/2020/01/toward-the-next-gen-of-recom-sys/</guid><description>
&lt;p&gt;迫于生计，从今天开始学习推荐系统相关的内容，今天先来读一篇推荐系统领域的综述 &lt;a href="https://ieeexplore.ieee.org/document/1423975"&gt;Toward the next generation of recommender systems: a survey of the state-of-the-art and possible extensions&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;由于目前的工作其实是偏向推荐系统的serving,训练的开发，因此这些paper可能都是粗读，也不会把paper中的内容逐句翻译，而是找出我认为最为重要的一些概念加以记录。&lt;/p&gt;</description></item><item><title>【施工中】torch2trt　学习笔记</title><link>https://111qqz.com/2020/09/torch2trt/</link><pubDate>Fri, 18 Sep 2020 11:02:50 +0800</pubDate><guid>https://111qqz.com/2020/09/torch2trt/</guid><description>
&lt;h2 id="前言"&gt;前言&lt;/h2&gt;
&lt;p&gt;偶然发现了 &lt;a href="https://github.com/NVIDIA-AI-IOT/torch2trt"&gt;torch2trt&lt;/a&gt; 的模型转换方案，思路是直接将pytorch op映射到TensorRT的python api. 在pytorch进行每个op　forward的时候，tensorrt也相应往network上添加op.
这里会先涉及torch2trt的使用，后面会补充这个转换工具的代码学习&lt;/p&gt;</description></item><item><title>Jetson Nano踩坑记录</title><link>https://111qqz.com/2020/09/jetson-nano/</link><pubDate>Tue, 08 Sep 2020 14:41:34 +0800</pubDate><guid>https://111qqz.com/2020/09/jetson-nano/</guid><description>
&lt;h2 id="写在前面"&gt;写在前面&lt;/h2&gt;
&lt;p&gt;主要是需要在jetson nano做模型转换，来记录下踩的坑
目前有两条路径，一条是我们现有的转换路径，也就是pytorch-&amp;gt;onnx(-&amp;gt;caffe)-&amp;gt;trt的路径
在这条路径上踩了比较多的坑，最终暂时放弃，最直接的原因是&lt;strong&gt;cudnn8.0升级接口发生改动，编译caffe遇到较多问题&lt;/strong&gt;
这里其实仍然采用了两条平行的路径，一条是直接在nano上构建环境，另外一种是基于docker(包括构建交叉编译环境用于加快编译速度)&lt;/p&gt;</description></item><item><title>caffe 源码学习笔记(11) argmax layer</title><link>https://111qqz.com/2020/05/caffe-source-code-analysis-part11/</link><pubDate>Wed, 06 May 2020 21:26:03 +0800</pubDate><guid>https://111qqz.com/2020/05/caffe-source-code-analysis-part11/</guid><description>
&lt;h2 id="背景"&gt;背景&lt;/h2&gt;
&lt;p&gt;似乎没什么背景,继续看caffe代码&lt;/p&gt;
&lt;p&gt;argmax的作用是返回一个blob某个维度或者batch_size之后的维度的top_k的index(或者pair(index,value))&lt;/p&gt;</description></item><item><title>caffe 源码学习笔记(10) eltwise layer</title><link>https://111qqz.com/2020/05/caffe-source-code-analysis-part10/</link><pubDate>Sun, 03 May 2020 17:53:22 +0800</pubDate><guid>https://111qqz.com/2020/05/caffe-source-code-analysis-part10/</guid><description>
&lt;h2 id="背景"&gt;背景&lt;/h2&gt;
&lt;p&gt;这个layer和reduce layer有一些相似,就干脆一起看了.
作用是输入至少两个blob,然后对每个blob中的元素所一些运算,最后得到一个blob.&lt;/p&gt;</description></item><item><title>caffe 源码学习笔记(9) reduce layer</title><link>https://111qqz.com/2020/05/caffe-source-code-analysis-part9/</link><pubDate>Sun, 03 May 2020 15:16:53 +0800</pubDate><guid>https://111qqz.com/2020/05/caffe-source-code-analysis-part9/</guid><description>
&lt;h2 id="背景"&gt;背景&lt;/h2&gt;
&lt;p&gt;其实没什么背景,继续啃caffe代码而已2333&lt;/p&gt;
&lt;p&gt;reduce layer其实就是做reduce操作,把一个任意shape的blob通过某种运算变成一个scalar.&lt;/p&gt;</description></item><item><title>Focal Loss for Dense Object Detection(RetinaNet) 学习笔记</title><link>https://111qqz.com/2020/05/retinanet-notes/</link><pubDate>Sat, 02 May 2020 18:50:06 +0800</pubDate><guid>https://111qqz.com/2020/05/retinanet-notes/</guid><description>
&lt;p&gt;先写个简略版的笔记..看之后的情况要不要读得更精细一点..&lt;/p&gt;
&lt;h2 id="背景"&gt;背景&lt;/h2&gt;
&lt;p&gt;two stage的检测比one stage的检测效果好,原因是啥?&lt;/p&gt;
&lt;p&gt;作者认为是正负样本不平衡导致的. two stage的方法在proposal 的时候干掉了大部分负样本,所以效果好.&lt;/p&gt;</description></item><item><title>caffe 源码学习笔记(8) loss function</title><link>https://111qqz.com/2020/04/caffe-source-code-analysis-part8/</link><pubDate>Sat, 18 Apr 2020 18:33:29 +0800</pubDate><guid>https://111qqz.com/2020/04/caffe-source-code-analysis-part8/</guid><description>
&lt;h2 id="背景"&gt;背景&lt;/h2&gt;
&lt;p&gt;虽然不太care 训练的过程，&lt;del&gt;但是由于容易看懂的layer都看得差不多了&lt;/del&gt; 所以打算看一下这些loss function.&lt;/p&gt;
&lt;h2 id="euclidean-loss-l2-loss"&gt;Euclidean Loss (L2 loss)&lt;/h2&gt;
&lt;p&gt;
&lt;img class="image_figure image_external" loading="lazy" src="https://111qqz.com/images/migrated/loli/voT7jGEF1BabmpL.png" alt="L2 loss.png" /&gt;
&lt;/p&gt;
&lt;p&gt;一般用于“real-valued regression tasks” 。　比如之前的项目上用的人脸年龄模型，就是用了这个Loss&lt;/p&gt;</description></item><item><title>caffe 源码学习笔记(7) slice layer</title><link>https://111qqz.com/2020/04/caffe-source-code-analysis-part7/</link><pubDate>Mon, 13 Apr 2020 21:22:54 +0800</pubDate><guid>https://111qqz.com/2020/04/caffe-source-code-analysis-part7/</guid><description>
&lt;h2 id="背景"&gt;背景　&lt;/h2&gt;
&lt;p&gt;ocr组那边有个shuffle net 的网络,里面有个pytorch op叫chunk,转成的onnx对应的op是 &lt;a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Split"&gt;split&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;作用是:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Split a tensor into a list of tensors, along the specified 'axis'. Lengths of the parts can be specified using argument 'split'. Otherwise, the tensor is split to equal sized parts.&lt;/p&gt;</description></item><item><title>caffe 源码学习笔记(6) reshape layer</title><link>https://111qqz.com/2020/04/caffe-source-code-analysis-part6/</link><pubDate>Thu, 09 Apr 2020 21:03:06 +0800</pubDate><guid>https://111qqz.com/2020/04/caffe-source-code-analysis-part6/</guid><description>
&lt;h2 id="背景"&gt;背景　&lt;/h2&gt;
&lt;p&gt;最近在魔改 tensorRT 的caffe parser
之前caffe模型转到trt模型时，有一个修改是需要将reshape　layer的param末尾补1,比较繁琐，于是看了下caffe的reshape layer的实现．&lt;/p&gt;</description></item><item><title>caffe 源码学习笔记(5) 卷积</title><link>https://111qqz.com/2020/04/caffe-source-code-analysis-part5/</link><pubDate>Wed, 08 Apr 2020 20:29:37 +0800</pubDate><guid>https://111qqz.com/2020/04/caffe-source-code-analysis-part5/</guid><description>
&lt;h2 id="caffe中卷积运算的实现"&gt;caffe中卷积运算的实现&lt;/h2&gt;
&lt;p&gt;暴力实现的卷积大概是这样子的&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span class="line"&gt;&lt;span class="ln"&gt; 1&lt;/span&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="ln"&gt; 2&lt;/span&gt;&lt;span class="cl"&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;W&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="ln"&gt; 3&lt;/span&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;h&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;H&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="ln"&gt; 4&lt;/span&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;K&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="ln"&gt; 5&lt;/span&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;K&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="ln"&gt; 6&lt;/span&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;M&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="ln"&gt; 7&lt;/span&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="ln"&gt; 8&lt;/span&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;h&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="nb"&gt;input&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;h&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="nb"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="ln"&gt; 9&lt;/span&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;end&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="ln"&gt;10&lt;/span&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;end&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="ln"&gt;11&lt;/span&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;end&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="ln"&gt;12&lt;/span&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;end&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="ln"&gt;13&lt;/span&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;end&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="ln"&gt;14&lt;/span&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;end&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这种方式的效率显然很低，不意外地,caffe中并不是这样实现的．&lt;/p&gt;
&lt;p&gt;注释里面说:&lt;/p&gt;</description></item><item><title>tensorrt INT8 量化debug记录（cuda error 700）</title><link>https://111qqz.com/2020/04/cuda-error-700-when-using-tensorrt-calibration/</link><pubDate>Wed, 08 Apr 2020 14:58:16 +0800</pubDate><guid>https://111qqz.com/2020/04/cuda-error-700-when-using-tensorrt-calibration/</guid><description>
&lt;p&gt;背景是要把某个caffe model,转换成tensorrt的INT8 模型。 然后遇到如下报错:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-bash" data-lang="bash"&gt;&lt;span class="line"&gt;&lt;span class="ln"&gt; 1&lt;/span&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="ln"&gt; 2&lt;/span&gt;&lt;span class="cl"&gt;E0403 08:54:35.951987  &lt;span class="m"&gt;5704&lt;/span&gt; engine.h:62&lt;span class="o"&gt;]&lt;/span&gt; engine.cpp &lt;span class="o"&gt;(&lt;/span&gt;572&lt;span class="o"&gt;)&lt;/span&gt; - Cuda Error in commonEmitTensor: &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;invalid argument&lt;span class="o"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="ln"&gt; 3&lt;/span&gt;&lt;span class="cl"&gt;E0403 08:54:35.952157  &lt;span class="m"&gt;5704&lt;/span&gt; engine.h:62&lt;span class="o"&gt;]&lt;/span&gt; Failure &lt;span class="k"&gt;while&lt;/span&gt; trying to emit debug blob.
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="ln"&gt; 4&lt;/span&gt;&lt;span class="cl"&gt;engine.cpp &lt;span class="o"&gt;(&lt;/span&gt;572&lt;span class="o"&gt;)&lt;/span&gt; - Cuda Error in commonEmitTensor: &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;invalid argument&lt;span class="o"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="ln"&gt; 5&lt;/span&gt;&lt;span class="cl"&gt;E0403 08:54:35.952235  &lt;span class="m"&gt;5704&lt;/span&gt; engine.h:62&lt;span class="o"&gt;]&lt;/span&gt; cuda/caskConvolutionLayer.cpp &lt;span class="o"&gt;(&lt;/span&gt;355&lt;span class="o"&gt;)&lt;/span&gt; - Cuda Error in execute: &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;invalid argument&lt;span class="o"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="ln"&gt; 6&lt;/span&gt;&lt;span class="cl"&gt;E0403 08:54:35.952291  &lt;span class="m"&gt;5704&lt;/span&gt; engine.h:62&lt;span class="o"&gt;]&lt;/span&gt; cuda/caskConvolutionLayer.cpp &lt;span class="o"&gt;(&lt;/span&gt;355&lt;span class="o"&gt;)&lt;/span&gt; - Cuda Error in execute: &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;invalid argument&lt;span class="o"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="ln"&gt; 7&lt;/span&gt;&lt;span class="cl"&gt;W0403 08:54:35.952324  &lt;span class="m"&gt;5704&lt;/span&gt; calibrator.cpp:45&lt;span class="o"&gt;]&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt;4, 3, 224, 224&lt;span class="o"&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="ln"&gt; 8&lt;/span&gt;&lt;span class="cl"&gt;F0403 08:54:35.992761  &lt;span class="m"&gt;5704&lt;/span&gt; tensor.h:149&lt;span class="o"&gt;]&lt;/span&gt; Check failed: cudaMemcpy&lt;span class="o"&gt;(&lt;/span&gt;raw_mutable_data&lt;span class="o"&gt;()&lt;/span&gt;, b.raw_data&lt;span class="o"&gt;()&lt;/span&gt;, size_in_bytes, cudaMemcpyDefault&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; cudaSuccess &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;700&lt;/span&gt; vs. 0&lt;span class="o"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="ln"&gt; 9&lt;/span&gt;&lt;span class="cl"&gt;*** Check failure stack trace: ***
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="ln"&gt;10&lt;/span&gt;&lt;span class="cl"&gt;Aborted &lt;span class="o"&gt;(&lt;/span&gt;core dumped&lt;span class="o"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;cuda error 700. 原来cuda error的错误号可以这么大。。&lt;/p&gt;</description></item><item><title>caffe 源码学习笔记(4) 激活函数</title><link>https://111qqz.com/2020/04/caffe-source-code-analysis-part4/</link><pubDate>Tue, 07 Apr 2020 23:21:40 +0800</pubDate><guid>https://111qqz.com/2020/04/caffe-source-code-analysis-part4/</guid><description>
&lt;p&gt;在看过caffe代码的三个核心部分,blob,layer,net之后，陷入了不知道以什么顺序继续看的困境。&lt;/p&gt;
&lt;p&gt;blob,layer,net只是三个最基本的概念，关键还是在于各个layer. 但是layer这么多，要怎么看呢？ 想了一下决定把相同作用的layer放在一起分析。 今天打算先分析一下激活函数。&lt;/p&gt;</description></item><item><title>Faster Rcnn 目标检测算法</title><link>https://111qqz.com/2020/04/faster-rcnn/</link><pubDate>Sun, 05 Apr 2020 20:38:28 +0800</pubDate><guid>https://111qqz.com/2020/04/faster-rcnn/</guid><description>
&lt;h2 id="背景"&gt;背景&lt;/h2&gt;
&lt;p&gt;2019年对了好几次faster rcnn，第一次是赛事之窗项目和北京的同事，对齐sdk和训练的实现。
第二次是被tensorRT4和tensorRT5之间默认参数不一致的问题坑了一下。
第三次是被caffe proto中roi align 的默认参数坑了。&lt;/p&gt;</description></item><item><title>resnet 学习笔记</title><link>https://111qqz.com/2020/04/resnet-learning-notes/</link><pubDate>Sun, 05 Apr 2020 16:49:44 +0800</pubDate><guid>https://111qqz.com/2020/04/resnet-learning-notes/</guid><description>
&lt;h2 id="背景"&gt;背景&lt;/h2&gt;
&lt;p&gt;基于Conv的方法在某年的ImageNet比赛上又重新被人想起之后，大家发现网络堆叠得越深，似乎在cv的各个任务上表现的越好。&lt;/p&gt;
&lt;p&gt;然而事情当然没有无脑退跌深度那么简单，人们发现，当网络深到一定程度时，结果还不如浅一些的网络结构。&lt;/p&gt;</description></item><item><title>caffe 源码学习笔记(3) Net</title><link>https://111qqz.com/2020/01/caffe-source-code-analysis-part3/</link><pubDate>Sun, 12 Jan 2020 19:18:15 +0800</pubDate><guid>https://111qqz.com/2020/01/caffe-source-code-analysis-part3/</guid><description>
&lt;h2 id="net-基本介绍"&gt;Net 基本介绍&lt;/h2&gt;
&lt;p&gt;网络通过组成和自微分共同定义一个函数及其梯度。&lt;/p&gt;
&lt;p&gt;网络是一些Layer组成的DAG,也就是有向无环图，在caffe中通常由prototxt定义．&lt;/p&gt;</description></item><item><title>caffe 源码学习笔记(2) Layer</title><link>https://111qqz.com/2020/01/caffe-source-code-analysis-part2/</link><pubDate>Sat, 11 Jan 2020 17:47:05 +0800</pubDate><guid>https://111qqz.com/2020/01/caffe-source-code-analysis-part2/</guid><description>
&lt;h2 id="layer-整体介绍"&gt;layer 整体介绍&lt;/h2&gt;
&lt;p&gt;layer是模型计算的基本单元
类似于pytorch或者其他深度学习框架的op
layer中的数据流向为,输入若干个blob，称之为&amp;quot;bottom blob&amp;quot;,然后经过layer的计算，输出若干个blob,称之为&amp;quot;top blob&amp;quot;&lt;/p&gt;</description></item><item><title>caffe 源码学习笔记(1) Blob</title><link>https://111qqz.com/2020/01/caffe-source-code-analysis-part1/</link><pubDate>Fri, 10 Jan 2020 11:24:23 +0800</pubDate><guid>https://111qqz.com/2020/01/caffe-source-code-analysis-part1/</guid><description>
&lt;p&gt;迫于生计，开始看caffe代码。
会侧重于分析inference部分。&lt;/p&gt;
&lt;h2 id="blob-整体介绍"&gt;blob 整体介绍&lt;/h2&gt;
&lt;h3 id="blob的含义及目的"&gt;blob的含义及目的&lt;/h3&gt;
&lt;p&gt;blob在逻辑上表示的就是所谓的tensor,blob是tensor在caffe中的叫法。
在框架层面上，blob的意义在于对数据进行封装，提供统一的接口。
这里的数据包含训练/inference时用的数据，也包含模型参数，导数等数据。
深度学习离不开在GPU上的计算。 blob对数据的封装使得用户不必关心和cuda有关的数据传输细节。&lt;/p&gt;</description></item><item><title>记一次faster-rcnn debug记录</title><link>https://111qqz.com/2019/12/debug-faster-rcnn-once-again/</link><pubDate>Fri, 13 Dec 2019 16:32:14 +0800</pubDate><guid>https://111qqz.com/2019/12/debug-faster-rcnn-once-again/</guid><description>
&lt;h2 id="问题描述"&gt;问题描述&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;一年debug 三次faster rcnn,每次都有新感觉（不&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;接到一个bug report,现象为某人脸模型，转换成trt模型，当batch size为1时结果完全正确，但是batch size大于1时结果不正确。
具体的现象是，如果跑多张不同的图，只有第一张图有结果，后面的图都没有结果。
如果跑的图中有相同的，那么和第一张相同的图都会有结果，其余的图没有结果。&lt;/p&gt;</description></item><item><title>FPN:Feature Pyramid Networks 学习笔记</title><link>https://111qqz.com/2019/12/feature-pyramid-networks/</link><pubDate>Sun, 08 Dec 2019 17:30:50 +0800</pubDate><guid>https://111qqz.com/2019/12/feature-pyramid-networks/</guid><description>
&lt;p&gt;检测不同尺度的物体一直是计算机视觉领域中比较有挑战性的事情．我们先从之前的工作出发，并对比FPN比起之前的工作有哪些改进．&lt;/p&gt;
&lt;h2 id="之前的工作"&gt;之前的工作&lt;/h2&gt;
&lt;h3 id="featurized-image-pyramid"&gt;Featurized image pyramid&lt;/h3&gt;
&lt;p&gt;
&lt;img class="image_figure image_external" loading="lazy" src="https://111qqz.com/images/migrated/loli/vhsEbJoYNBcMKdk.png" alt="Featurized image pyramid.png" /&gt;
&lt;/p&gt;
&lt;p&gt;思路是对于同一张图，生成不同的scale，然后每个scale的image单独去做检测．
这个方法是手工设计feautre时代的常用办法．
这个办法是比较显然的，也的确可以解决检测不同尺度物体的问题．
缺点非常明显...inference的速度几乎和scale的个数线性相关．
以及由于显存的开销，没办法做end-to-end 的training.&lt;/p&gt;</description></item><item><title>SSD: Single Shot MultiBox Detector 学习笔记</title><link>https://111qqz.com/2019/12/single-short-detector/</link><pubDate>Sun, 08 Dec 2019 15:00:15 +0800</pubDate><guid>https://111qqz.com/2019/12/single-short-detector/</guid><description>
&lt;h2 id="概述"&gt;概述&lt;/h2&gt;
&lt;p&gt;SSD是一种单阶段目标检测算法．所谓单阶段，是指只使用了一个deep neural network,而不是像faster-rcnn这种两阶段网络．
为什么有了faster-rcnn还要使用SSD? 最主要是慢...
两阶段网络虽然准确率高，但是在嵌入式等算力不足的设备上做inference速度非常感人，很难达到real time的要求．
（实际业务上也是这样，公有云上的检测模型几乎都是faster-rcnn,而到了一些盒子之类的硬件设备，检测模型就全是SSD等single stage 模型了)&lt;/p&gt;</description></item><item><title>rankboost 算法学习笔记</title><link>https://111qqz.com/2019/11/rankboost-Algorithm/</link><pubDate>Tue, 26 Nov 2019 20:59:04 +0800</pubDate><guid>https://111qqz.com/2019/11/rankboost-Algorithm/</guid><description>
&lt;h2 id="boosting-算法是什么"&gt;boosting 算法是什么．&lt;/h2&gt;
&lt;p&gt;机缘使然，接触到了 Boosting 算法．Boosting是一种通过组合弱学习器来产生强学习器的通用且有效的方法.&lt;/p&gt;
&lt;p&gt;动机是基于如下观察:尽管委员会中每个成员只提供一些不成熟的判断,但整个委员会却产生较为准确的决策。通过组合多个弱学习器来解决学习问题。给定训练数据,弱学习算法(如决策树)可以训练产生弱学习器,这些弱学习器只需要比随机猜测的准确率好一些。用不同的训练数据训练可以得到不同的弱学习器。这些弱学习器作为委员会成员,共同决策。&lt;/p&gt;</description></item><item><title>Kubernetes(k8s)在深度学习模型转换方面的探索</title><link>https://111qqz.com/2019/11/K8s-for-Model-Conversion/</link><pubDate>Fri, 22 Nov 2019 11:14:19 +0800</pubDate><guid>https://111qqz.com/2019/11/K8s-for-Model-Conversion/</guid><description>
&lt;p&gt;年中的时候接了离职的同事模型转换的锅，在不断地更新迭代的过程中，发现了一些痛点。
发现k8s能够解决一部分痛点，因此来分享一下在这方面的探索。&lt;/p&gt;
&lt;h2 id="什么是模型转换"&gt;什么是模型转换&lt;/h2&gt;
&lt;p&gt;简单来说，深度学习模型的流程分为training和inference两部分。训练时用的一般是pytorch等框架，这些框架训练出的model是没办法直接部署在各个硬件平台上做inference的。因此需要将使用训练框架得到的模型，转换为能够部署到各个硬件平台上的模型。这个过程就是模型转换。&lt;/p&gt;</description></item><item><title>faster rcnn 模型 tensorrt4与tensorrt5 结果不一致 踩坑记录</title><link>https://111qqz.com/2019/11/debug-Frcnn-Model-When-Upgrading-From-Tensorrt4-to-Tensorrt5/</link><pubDate>Thu, 07 Nov 2019 23:40:39 +0800</pubDate><guid>https://111qqz.com/2019/11/debug-Frcnn-Model-When-Upgrading-From-Tensorrt4-to-Tensorrt5/</guid><description>
&lt;p&gt;最近有同事report给我们,用同一个模型转换工具,转同一个faster rcnn 模型, 同样的sdk代码,在有些显卡上结果正常,但是再比较新的显卡上(比如Titan V)上 结果完全不正确.&lt;/p&gt;</description></item><item><title>Anchor Box Algorithm</title><link>https://111qqz.com/2019/07/Anchor-Box-Algorithm/</link><pubDate>Mon, 01 Jul 2019 19:53:24 +0800</pubDate><guid>https://111qqz.com/2019/07/Anchor-Box-Algorithm/</guid><description>
&lt;h2 id="动机"&gt;动机&lt;/h2&gt;
&lt;p&gt;将一张图分成多个grid cell进行检测之后,每个cell只能检测到一个object.
如果这个grid cell中不止有一个物体要怎么办呢? 因此提出了anchor box algorithm来解决这个问题.&lt;/p&gt;</description></item><item><title>目标检测领域的滑动窗口算法</title><link>https://111qqz.com/2019/06/sliding-windows/</link><pubDate>Sun, 30 Jun 2019 16:55:40 +0800</pubDate><guid>https://111qqz.com/2019/06/sliding-windows/</guid><description>
&lt;p&gt;对象检测（Object Detection）的目的是”识别对象并给出其在图中的确切位置”，其内容可解构为三部分：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;识别某个对象（Classification）；&lt;/li&gt;
&lt;li&gt;给出对象在图中的位置（Localization）；&lt;/li&gt;
&lt;li&gt;识别图中所有的目标及其位置（Detection）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;本文将介绍&lt;strong&gt;滑动窗口&lt;/strong&gt;这一方法.&lt;/p&gt;</description></item><item><title>caffe2 添加自定义operater</title><link>https://111qqz.com/2018/04/add-custom-operation-in-caffe2/</link><pubDate>Fri, 13 Apr 2018 03:08:19 +0000</pubDate><guid>https://111qqz.com/2018/04/add-custom-operation-in-caffe2/</guid><description>
&lt;p&gt;记录一些一个没有之前没有接触过caffe/caffe2的人为了添加自定义的op 到caffe2需要做的工作.&lt;/p&gt;
&lt;p&gt;首先参考caffe2 tutorial,随便跑个op来试试,不妨以比较简单的  &lt;a href="https://caffe2.ai/docs/operators-catalogue.html#accumulate"&gt;Accumulate_op&lt;/a&gt; 为例子.&lt;/p&gt;</description></item><item><title>非极大值抑制（Non-Maximum Suppression，NMS）</title><link>https://111qqz.com/2018/03/non-maximum-suppression/</link><pubDate>Fri, 16 Mar 2018 02:56:14 +0000</pubDate><guid>https://111qqz.com/2018/03/non-maximum-suppression/</guid><description>
&lt;p&gt;NMS是为了在诸多CV任务如边缘检测，目标检测等，找到&lt;strong&gt;局部最大值&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;其主要思想是先设定一个阈值，然后计算检测框的IOU(所谓IOU，也就是intersection-over-union，指的是相交面积除以相并面积，是来衡量overlap程度的指数）。如果IOU大于阈值，说明overlap过大，我们要通过某种算法来将其剔除。&lt;/strong&gt;&lt;/p&gt;</description></item><item><title>reid 相关任务记录</title><link>https://111qqz.com/2018/02/reid-task-notes/</link><pubDate>Sat, 24 Feb 2018 04:34:02 +0000</pubDate><guid>https://111qqz.com/2018/02/reid-task-notes/</guid><description>
&lt;p&gt;被师兄（同事？）普及了一番实验规范orz...&lt;/p&gt;
&lt;p&gt;我还是太年轻了&lt;/p&gt;
&lt;p&gt;所谓的一个fc的版本是右边的．一个放着不动，另一个在sequence_len（１０）的维度上做ave,然后再expand成原来的维度．如下图．&lt;/p&gt;</description></item><item><title>分类评价指标之Cumulative Match Characteristi (CMC)曲线</title><link>https://111qqz.com/2018/02/cumulative-Match-characteristi/</link><pubDate>Fri, 23 Feb 2018 08:20:55 +0000</pubDate><guid>https://111qqz.com/2018/02/cumulative-Match-characteristi/</guid><description>
&lt;p&gt;CMC曲线全称是Cumulative Match Characteristic (CMC) curve，也就是累积匹配曲线，同ROC曲线Receiver Operating Characteristic (ROC) curve一样，是模式识别系统，如人脸，指纹，虹膜等的重要评价指标，尤其是在生物特征识别系统中，一般同ROC曲线（ &lt;a href="https://111qqz.com/2021/08/ska_flat_hash_map_notes/"&gt;多标签图像分类任务的评价方法-mean average precision(mAP) 以及top x的评价方法&lt;/a&gt;）一起给出，能够综合评价出算法的好坏。&lt;/p&gt;</description></item><item><title>pytorch 函数笔记</title><link>https://111qqz.com/2018/02/pytorch-function-notes/</link><pubDate>Fri, 23 Feb 2018 02:55:25 +0000</pubDate><guid>https://111qqz.com/2018/02/pytorch-function-notes/</guid><description>
&lt;p&gt;记录一些常用的...总去查文档也是有点麻烦&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; *
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id="tensorview-的作用是reshape-比如a--torchrange1-16-得到一个tensor-that-has-16-elements-from-1-to-16-在aaview44就得到了一个44的tensor-需要注意reshape之后元素的个数不能改变1644-参数-1的作用是我懒得算这一维度应该是多少由于元素个数不能改变所以希望自动被计算需要注意的是只有一个维度可以写-1不过view和reshape有些区别reshape-always-copies-memory-view-never-copies-memory"&gt;tensor.view 的作用是reshape 比如 a = torch.range(1, 16) 得到一个tensor  that has 16 elements from 1 to 16. 在a=a.view(4,4)就得到了一个4&lt;em&gt;4的tensor。 需要注意reshape之后元素的个数不能改变(16==4&lt;/em&gt;4)  参数-1的作用是，我懒得算这一维度应该是多少,（由于元素个数不能改变）所以希望自动被计算。**需要注意的是，只有一个维度可以写-1。 **不过view和reshape有些区别：&lt;em&gt;reshape always copies memory. view never copies memory&lt;/em&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt; *
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id="torchsqueeze将输入张量形状中的1去除并返回-如果输入是形如a1b1c1d那么输出形状就为abcd当给定dim时那么挤压操作只在给定维度上例如输入形状为a1bsqueezeinput-0将会保持张量不变只有用squeezeinput-1形状会变成ab注意-返回张量与输入张量共享内存所以改变其中一个的内容会改变另一个"&gt;torch.squeeze  将输入张量形状中的&lt;code&gt;1&lt;/code&gt; 去除并返回。 如果输入是形如(A×1×B×1×C×1×D)，那么输出形状就为： (A×B×C×D)当给定&lt;code&gt;dim&lt;/code&gt;时，那么挤压操作只在给定维度上。例如，输入形状为: (A×1×B), &lt;code&gt;squeeze(input, 0)&lt;/code&gt; 将会保持张量不变，只有用 &lt;code&gt;squeeze(input, 1)&lt;/code&gt;，形状会变成 (A×B)。注意： 返回张量与输入张量共享内存，所以改变其中一个的内容会改变另一个。&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt; *
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id="torchunsqueeze返回一个新的张量对输入的制定位置插入维度-1-注意-返回张量与输入张量共享内存所以改变其中一个的内容会改变另一个如果dim为负则将会被转化diminputdim1"&gt;torch.unsqueeze  返回一个新的张量，对输入的制定位置插入维度 1 注意： 返回张量与输入张量共享内存，所以改变其中一个的内容会改变另一个。如果&lt;code&gt;dim&lt;/code&gt;为负，则将会被转化dim+input.dim()+1&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; x = torch.Tensor([1, 2, 3, 4])
&amp;gt;&amp;gt;&amp;gt; torch.unsqueeze(x, 0)
1 2 3 4
[torch.FloatTensor of size 1x4]
&amp;gt;&amp;gt;&amp;gt; torch.unsqueeze(x, 1)
1
2
3
4
[torch.FloatTensor of size 4x1]
*
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id="tensorexpandsize-扩展tensor可以保持维度数目不变每一维度的size增加比如ab变到cd其中cadb-1参数表示某一个维度的size不发生改变--有可以扩展tensor到更多的维度新增加的维度会默认放在最前面并且不能以-1作为参数"&gt;tensor.expand(&lt;em&gt;size)   扩展tensor.可以保持维度数目不变，每一维度的size增加(比如A&lt;/em&gt;B变到C*D,其中C&amp;gt;=A,D&amp;gt;=B).-1参数表示某一个维度的size不发生改变  . 有可以扩展tensor到更多的维度，新增加的维度会默认放在最前面，并且不能以-1作为参数。&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt; *
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id="tensorcontiguous-将一个tensor变成连续的一些ops如expandexpand_"&gt;&lt;strong&gt;tensor.contiguous  将一个tensor变成连续的。（一些ops如expand/expand_as会让tensor 不连续）&lt;/strong&gt;&lt;/h3&gt;</description></item><item><title>光流法初探</title><link>https://111qqz.com/2018/02/Optical-flow-notes/</link><pubDate>Thu, 22 Feb 2018 09:03:48 +0000</pubDate><guid>https://111qqz.com/2018/02/Optical-flow-notes/</guid><description>
&lt;p&gt;算是CV领域的传统算法了&lt;/p&gt;
&lt;p&gt;只写两句话就够了。&lt;/p&gt;
&lt;blockquote&gt;**它是空间运动物体在观察成像平面上的像素运动的瞬时速度，是利用图像序列中像素在时间域上的变化以及相邻帧之间的相关性来找到上一帧跟当前帧之间存在的对应关系，从而计算出相邻帧之间物体的运动信息的一种方法。**
&lt;p&gt;&lt;strong&gt;研究光流场的目的就是为了从图片序列中近似得到不能直接得到的运动场。运动场，其实就是物体在三维真实世界中的运动；光流场，是运动场在二维图像平面上（人的眼睛或者摄像头）的投影。&lt;/strong&gt;&lt;/blockquote&gt;&lt;/p&gt;</description></item><item><title>end-to-end 神经网络</title><link>https://111qqz.com/2018/02/end-to-end-neural-network/</link><pubDate>Thu, 22 Feb 2018 02:53:01 +0000</pubDate><guid>https://111qqz.com/2018/02/end-to-end-neural-network/</guid><description>
&lt;p&gt;所谓end-to-end 神经网络，更多是一种思想。&lt;/p&gt;
&lt;p&gt;这种思想的核心是，比如对于图像处理，输入原始图像数据，输出的是直接有用的结果（有用取决于具体的任务，比如自动驾驶)&lt;/p&gt;</description></item><item><title>Pose-driven Deep Convolutional Model for Person Re-identification 阅读笔记</title><link>https://111qqz.com/2018/02/pose-driven-deep-convolutional-model-for-person-re-identification/</link><pubDate>Thu, 22 Feb 2018 02:25:00 +0000</pubDate><guid>https://111qqz.com/2018/02/pose-driven-deep-convolutional-model-for-person-re-identification/</guid><description>
&lt;p&gt;&lt;a href="https://arxiv.org/abs/1709.08325"&gt;1709.08325&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Reid问题指的是判断一个probe person 是否在被不同的camera捕获的gallery person 中出现。&lt;/p&gt;
&lt;p&gt;通常是如下情景：给出一个特定camera下某个特定人的probe image 或者 video sequence，从其他camera处询问这个人的图像，地点，时间戳。&lt;/p&gt;</description></item><item><title>Deep Mutual Learning（相互学习） 阅读笔记</title><link>https://111qqz.com/2018/02/deep-mutual-learning-notes/</link><pubDate>Sun, 18 Feb 2018 10:46:35 +0000</pubDate><guid>https://111qqz.com/2018/02/deep-mutual-learning-notes/</guid><description>
&lt;p&gt;&lt;a href="https://arxiv.org/abs/1706.00384"&gt;原始论文&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;DNN在很多问题上效果很不错，但是由于深度和宽度过大，导致需要的执行时间和内存过大。我们需要讨论一些能快速执行并且对内存的需要不大的模型。&lt;/p&gt;
&lt;p&gt;已经有很多方法来做这件事，比较重要的是Model distillation（模型蒸馏）&lt;/p&gt;</description></item><item><title>Similarity learning 和Metric learning</title><link>https://111qqz.com/2018/02/similarity-learning-metric-learning/</link><pubDate>Sun, 18 Feb 2018 08:14:10 +0000</pubDate><guid>https://111qqz.com/2018/02/similarity-learning-metric-learning/</guid><description>
&lt;h2 id="similarity_"&gt;&lt;a href="https://en.wikipedia.org/wiki/Similarity_learning"&gt;Similarity_learning&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;相似性学习（Similarity learning ）有监督机器学习，它与回归和分类密切相关，但目标是从实例中学习一个相似函数，&lt;strong&gt;以衡量两个对象的相似程度或相关程度。&lt;/strong&gt;&lt;/p&gt;</description></item><item><title>persion reid 论文列表</title><link>https://111qqz.com/2018/02/persion-reid-paper-list/</link><pubDate>Sat, 17 Feb 2018 07:17:49 +0000</pubDate><guid>https://111qqz.com/2018/02/persion-reid-paper-list/</guid><description>
&lt;p&gt;Key:&lt;/p&gt;
&lt;p&gt;(1). Pose-driven, body part alignment, combine whole feature and body part feature, focus on alignment of part model,&lt;/p&gt;
&lt;p&gt;(2). Combine image label and human attributes classes, do classification with attributes and identity learning&lt;/p&gt;
&lt;p&gt;(3). Based on triplet loss, improve metric learning for an end to end learning&lt;/p&gt;
&lt;p&gt;(4). Post-process, re-ranking&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;AlignedReID: Surpassing Human-Level Performance in Person Re-Identification&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Hydraplus-net: Attentive deep features for pedestrian analysis.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Darkrank: Accelerating deep metric learning via cross sample similarities transfer.&lt;/p&gt;</description></item><item><title>推荐系统之 LFM (Latent Factor Model) 隐因子模型 学习笔记</title><link>https://111qqz.com/2018/02/Latent-Factor-Model-notes/</link><pubDate>Fri, 09 Feb 2018 13:02:06 +0000</pubDate><guid>https://111qqz.com/2018/02/Latent-Factor-Model-notes/</guid><description>
&lt;p&gt;起因是被assgin了一个新的任务.....要死.&lt;/p&gt;
&lt;p&gt;参考资料:&lt;/p&gt;
&lt;p&gt;&lt;a href="http://blog.csdn.net/asd136912/article/details/78290679"&gt;推荐系统学习笔记之三 LFM (Latent Factor Model) 隐因子模型 + SVD (singular value decomposition) 奇异值分解&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://blog.csdn.net/ice110956/article/details/21955461"&gt;基于矩阵分解的隐因子模型&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.jianshu.com/p/356656ce2901"&gt;实时推荐系统的三种方式&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;先说下我的理解...&lt;/p&gt;
&lt;p&gt;隐因子模型(LFM)是一种推荐算法,&amp;quot;隐&amp;quot;可以理解成用户喜欢某个item的间接原因.&lt;/p&gt;</description></item><item><title>多标签图像分类任务的评价方法-mean average precision(mAP) 以及top x的评价方法</title><link>https://111qqz.com/2018/02/mean-average-precision-for-multi-label-classification-task/</link><pubDate>Fri, 09 Feb 2018 03:53:09 +0000</pubDate><guid>https://111qqz.com/2018/02/mean-average-precision-for-multi-label-classification-task/</guid><description>
&lt;p&gt;参考资料:&lt;/p&gt;
&lt;p&gt;&lt;a href="http://blog.sina.com.cn/s/blog_9db078090102whzw.html"&gt;多标签图像分类任务的评价方法-mAP&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity"&gt;wiki_Sensitivity and specificity&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://blog.sciencenet.cn/blog-605185-617068.html"&gt;False Positives和False Negative等含义&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.zhihu.com/question/41540197/answer/91698989"&gt;mean average precision（MAP）在计算机视觉中是如何计算和应用的？&lt;/a&gt;&lt;/p&gt;</description></item><item><title>Non-local Neural Networks 阅读笔记</title><link>https://111qqz.com/2018/02/non-local-neural-networks-notes/</link><pubDate>Mon, 05 Feb 2018 02:24:34 +0000</pubDate><guid>https://111qqz.com/2018/02/non-local-neural-networks-notes/</guid><description>
&lt;p&gt;先粗略读了2遍orz.可能不够严谨，先写一些high-level的理解。&lt;/p&gt;
&lt;p&gt;对于序列或者图片数据，如果想获得一个long-range的依赖，通常的做法是循环神经网络（对于序列）或者深层的卷积神经网络（对于图片数据）&lt;/p&gt;</description></item><item><title>non-local means algorithm 学习笔记</title><link>https://111qqz.com/2018/01/non-local-means-algorithm-notes/</link><pubDate>Thu, 25 Jan 2018 02:53:52 +0000</pubDate><guid>https://111qqz.com/2018/01/non-local-means-algorithm-notes/</guid><description>
&lt;p&gt;终于忙完学校的事情可以干正事了orz&lt;/p&gt;
&lt;p&gt;这里会记录一些第一遍看paper的过程中遇到的一些影响理解的概念，不过大多不会深究，只算做粗浅的理解。&lt;/p&gt;
&lt;p&gt;1、高斯金字塔：&lt;/p&gt;</description></item><item><title>PCA + kmeans</title><link>https://111qqz.com/2017/11/pca-kmeans/</link><pubDate>Sun, 26 Nov 2017 11:05:50 +0000</pubDate><guid>https://111qqz.com/2017/11/pca-kmeans/</guid><description>
&lt;h3 id="先记录一下pca实战需要用到的安装包arch下python2环境"&gt;先记录一下PCA实战需要用到的安装包(arch下,python2环境)&lt;/h3&gt;
&lt;h3 id="python2-scikit-learn"&gt;&lt;a href="https://www.archlinux.org/packages/community/x86_64/python-scikit-learn/"&gt;python2-scikit-learn&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;python2-numpy&lt;/p&gt;
&lt;p&gt;python2-pandas&lt;/p&gt;
&lt;p&gt;python2-matplotlib&lt;/p&gt;
&lt;p&gt;python2-seaborn&lt;/p&gt;
&lt;p&gt;&lt;a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html"&gt;pandas.DataFrame&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://pda.readthedocs.io/en/latest/chp5.html"&gt;pandas 数据结构介绍&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;几个和科学计算数据分析有关的重要的python库:&lt;code&gt;Numpy&lt;/code&gt;、&lt;code&gt;Matplotlib&lt;/code&gt; ,pandas&lt;/p&gt;
&lt;p&gt;(之前数字图像处理课程都接触过了orz)&lt;/p&gt;</description></item><item><title>反向传播学习笔记</title><link>https://111qqz.com/2017/09/back-propagation-notes/</link><pubDate>Tue, 05 Sep 2017 12:30:17 +0000</pubDate><guid>https://111qqz.com/2017/09/back-propagation-notes/</guid><description>
&lt;p&gt;先说下自己目前很笼统的理解：&lt;/p&gt;
&lt;p&gt;反向传播是用来快速计算梯度的一种方法；&lt;/p&gt;
&lt;p&gt;过程大概是把计算过程用计算图表示，这样每一个中间步骤都有一个节点，每一个local gradient都会比较容易计算；&lt;/p&gt;</description></item><item><title>tensorflow input pipline 学习笔记</title><link>https://111qqz.com/2017/08/tensorflow-input-pipline-notes/</link><pubDate>Thu, 24 Aug 2017 09:12:58 +0000</pubDate><guid>https://111qqz.com/2017/08/tensorflow-input-pipline-notes/</guid><description>
&lt;p&gt;参考资料：&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.tensorflow.org/api_guides/python/reading_data"&gt;tf_doc_Reading data&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://ischlag.github.io/2016/06/19/tensorflow-input-pipeline-example/"&gt;TENSORFLOW INPUT PIPELINE EXAMPLE&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://shartoo.github.io/tensorflow-inputpipeline/"&gt;tensorflow：理解tensorflow中的输入管道&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;第二个参考资料是第一个的翻译版本，翻译的水平一般，建议看原文，不是很长。&lt;/p&gt;
&lt;p&gt;下面是我挑了文章中重点的部分+自己的理解。&lt;/p&gt;
&lt;h1 id="tldr"&gt;TL;DR;&lt;/h1&gt;
&lt;p&gt;一个适用于不是很大的数据集的pipline input 的例子。&lt;/p&gt;</description></item><item><title>tensorflow 合并模型</title><link>https://111qqz.com/2017/08/tensorflow-model-merging/</link><pubDate>Mon, 21 Aug 2017 06:56:22 +0000</pubDate><guid>https://111qqz.com/2017/08/tensorflow-model-merging/</guid><description>
&lt;p&gt;在这里存个备份，还有些问题没有解决。&lt;/p&gt;
&lt;p&gt;raise ValueError(&amp;quot;GraphDef cannot be larger than 2GB.&amp;quot;)&lt;/p&gt;
&lt;p&gt;记录一些思路好了。现在是没有生成.meta文件，爆掉应该是因为所有的变量都加载到了默认图里。&lt;/p&gt;
&lt;p&gt;也就是说我处理完checkpoint 0 之后开始处理checkpoint1,但是checkpoint0的那些变量还是存在的...所以越来越多？&lt;/p&gt;</description></item><item><title>tensorflow checkpoint 学习笔记</title><link>https://111qqz.com/2017/08/tensorflow-checkpoint-notes/</link><pubDate>Mon, 21 Aug 2017 02:03:45 +0000</pubDate><guid>https://111qqz.com/2017/08/tensorflow-checkpoint-notes/</guid><description>
&lt;p&gt;参考资料：&lt;/p&gt;
&lt;p&gt;&lt;a href="https://stackoverflow.com/questions/36195454/what-is-the-tensorflow-checkpoint-meta-file"&gt;What is the TensorFlow checkpoint meta file?&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://stackoverflow.com/questions/35733917/tensorflow-restoring-variables-from-from-multiple-checkpoints"&gt;TensorFlow: Restoring variables from from multiple checkpoints&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;合并模型的时候发现.meta一直在累加，而其他数据文件没有改变。因此来探究一下checkpoint的几个文件的含义。&lt;/p&gt;</description></item><item><title>tensorflow variable 学习笔记</title><link>https://111qqz.com/2017/08/tensorflow-variable-notes/</link><pubDate>Sun, 20 Aug 2017 09:36:00 +0000</pubDate><guid>https://111qqz.com/2017/08/tensorflow-variable-notes/</guid><description>
&lt;p&gt;参考资料：&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.tensorflow.org/programmers_guide/variables"&gt;programmers_guide/variables&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.tensorflow.org/api_docs/python/tf/Variable"&gt;tf/Variable&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;之前感觉对tensorflow 的variable的理解不是很深刻...跑个模型啥的倒不会有什么问题，但是涉及分布式，模型并行之类的，感觉有些地方还是要理解得仔细一点比较好。&lt;/p&gt;</description></item><item><title>tensorflow Session 学习笔记</title><link>https://111qqz.com/2017/08/tensorflow-session-notes/</link><pubDate>Sun, 20 Aug 2017 08:21:57 +0000</pubDate><guid>https://111qqz.com/2017/08/tensorflow-session-notes/</guid><description>
&lt;p&gt;&lt;a href="https://www.tensorflow.org/api_docs/python/tf/Session"&gt;tensorflow-session官方文档&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;说下我自己的理解：&lt;/p&gt;
&lt;p&gt;session中文一般叫会话，可以理解成op执行时候需要的一层虚拟化的封装。&lt;/p&gt;
&lt;p&gt;op必须在session中才能执行。&lt;/p&gt;
&lt;p&gt;tensor也是在tensor中才可以存在（tf.variable和tensor几乎是一回事，只是tf.variable的会话不要求session，也可以理解成tf.variable在session中就成了tensor.&lt;/p&gt;</description></item><item><title>Distributed Tensorflow : Cannot assign a device for operation save</title><link>https://111qqz.com/2017/08/distributed-tensorflow-cannot-assign-a-device-for-operation-save/</link><pubDate>Mon, 14 Aug 2017 01:55:15 +0000</pubDate><guid>https://111qqz.com/2017/08/distributed-tensorflow-cannot-assign-a-device-for-operation-save/</guid><description>
&lt;p&gt;是在使用分布式tensorflow遇到的一个错误&lt;/p&gt;
&lt;p&gt;报错如下：&lt;/p&gt;
&lt;p&gt;InvalidArgumentError (see above for traceback): Cannot assign a device for operation 'save/Rest│| 2 GeForce GTX 1080 On | 0000:08:00.0 Off | N/A |
oreV2_888': Operation was explicitly assigned to /job:worker/task:0/device:CPU:0 but available │| 24% 39C P8 12W / 180W | 0MiB / 8114MiB | 0% Default |
devices are [ /job:localhost/replica:0/task:0/cpu:0, /job:localhost/replica:0/task:0/gpu:0 ]. Make sure the device specification refers to a valid device.&lt;/p&gt;</description></item><item><title>分布式 tensorflow 学习笔记(非最终版)</title><link>https://111qqz.com/2017/08/tensorflow-notes/</link><pubDate>Mon, 07 Aug 2017 12:54:23 +0000</pubDate><guid>https://111qqz.com/2017/08/tensorflow-notes/</guid><description>
&lt;p&gt;感觉资料不是很多，先收集资料好了。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.tensorflow.org/deploy/distributed"&gt;tf-distributed官网文档&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://stackoverflow.com/questions/41600321/distributed-tensorflow-the-difference-between-in-graph-replication-and-between"&gt;SO-between-graph和in-graph的区别&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/tensorflow/models/blob/master/inception/README.md"&gt;inception.README.md&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.tensorflow.org/versions/r0.12/api_docs/python/train/other_functions_and_classes"&gt;SyncReplicasOptimizer&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://stackoverflow.com/questions/41480149/how-does-ps-work-in-distribute-tensorflow"&gt;SO_How does ps work in distribute Tensorflow?&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;update:在多个nodes（机）上跑。。。tf默认是异步更新的。。。同步的话。。大概需要syncreplicasoptimizer?&lt;/p&gt;</description></item><item><title>tensorflow Supervisor 学习笔记</title><link>https://111qqz.com/2017/08/tensorflow-supervisor-notes/</link><pubDate>Fri, 04 Aug 2017 09:22:44 +0000</pubDate><guid>https://111qqz.com/2017/08/tensorflow-supervisor-notes/</guid><description>
&lt;p&gt;update:supervisor的缺点是遇到问题只会抛异常，所以现在有一个better的管理工具,&lt;a href="https://www.tensorflow.org/api_docs/python/tf/train/MonitoredSession"&gt;MonitoredSession&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;master,chief worker,Supervisor 这几个概念有点搞不清（我最菜.jpg  因此来学习一下。&lt;/p&gt;</description></item><item><title>k-means clustering 学习笔记</title><link>https://111qqz.com/2017/08/k-means-clustering-notes/</link><pubDate>Thu, 03 Aug 2017 13:09:17 +0000</pubDate><guid>https://111qqz.com/2017/08/k-means-clustering-notes/</guid><description>
&lt;p&gt;其实这算法巨简单。。。。让我想到了均分纸牌（noip200?&lt;/p&gt;
&lt;p&gt;还是大致说一下：&lt;/p&gt;
&lt;p&gt;对于有 features 但是 **没有 **labels 的数据，没办法用监督学习，但是可以使用非监督学习的聚类算法。&lt;/p&gt;</description></item><item><title>TensorFlow Architecture 学习笔记（二）Adding a New Op</title><link>https://111qqz.com/2017/08/tensorflow-architecture-notes-2/</link><pubDate>Wed, 02 Aug 2017 03:07:37 +0000</pubDate><guid>https://111qqz.com/2017/08/tensorflow-architecture-notes-2/</guid><description>
&lt;h1 id="adding-a-new-op"&gt;Adding a New Op&lt;/h1&gt;
&lt;pre&gt;&lt;code&gt; * [目录](https://www.tensorflow.org/extend/adding_an_op#top_of_page)
* [定义运算的接口](https://www.tensorflow.org/extend/adding_an_op#define_the_ops_interface)
* [实现运算的核心部分(kernels)](https://www.tensorflow.org/extend/adding_an_op#implement_the_kernel_for_the_op)
* [多线程cpu kernels](https://www.tensorflow.org/extend/adding_an_op#multi-threaded_cpu_kernels)
* [GPU kernels](https://www.tensorflow.org/extend/adding_an_op#gpu_kernels)
* [构建运算库](https://www.tensorflow.org/extend/adding_an_op#build_the_op_library)
* [用系统编译器编译你的运算（TensorFlow binary installation）](https://www.tensorflow.org/extend/adding_an_op#compile_the_op_using_your_system_compiler_tensorflow_binary_installation)
* [使用bazel编译你的运算(TensorFlow source installation)](https://www.tensorflow.org/extend/adding_an_op#compile_the_op_using_bazel_tensorflow_source_installation)
* [在 Python 中使用你的运算](https://www.tensorflow.org/extend/adding_an_op#use_the_op_in_python)
* [验证你添加的运算可以工作](https://www.tensorflow.org/extend/adding_an_op#verify_that_the_op_works)
* [在你的运算中添加高级特性](https://www.tensorflow.org/extend/adding_an_op#building_advanced_features_into_your_op)
* [条件检查和验证](https://www.tensorflow.org/extend/adding_an_op#conditional_checks_and_validation)
* [Op registration](https://www.tensorflow.org/extend/adding_an_op#op_registration)
* [GPU Support](https://www.tensorflow.org/extend/adding_an_op#gpu_support)
* [用python 实现梯度](https://www.tensorflow.org/extend/adding_an_op#implement_the_gradient_in_python)
* [Shape functions in C++](https://www.tensorflow.org/extend/adding_an_op#shape_functions_in_c)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;对于要添加原生tensorflow中没有定义的运算的需求，首先建议在python层面，能不能将需要的op用其他原生的op拼凑起来。&lt;/p&gt;</description></item><item><title>TensorFlow Architecture 学习笔记（一）</title><link>https://111qqz.com/2017/08/tensorflow-architecture-notes-1/</link><pubDate>Tue, 01 Aug 2017 03:01:12 +0000</pubDate><guid>https://111qqz.com/2017/08/tensorflow-architecture-notes-1/</guid><description>
&lt;p&gt;&lt;strong&gt;这篇文章不会涉及tensorflow的具体使用，而是专注于介绍tensorflow的架构，目的是让开发者能够对tensorflow现有框架进行自定义的扩展。&lt;/strong&gt;&lt;/p&gt;</description></item><item><title>Long Short-Term Memory （LSTM） 网络 学习笔记</title><link>https://111qqz.com/2017/07/lstm-notes/</link><pubDate>Mon, 31 Jul 2017 10:05:01 +0000</pubDate><guid>https://111qqz.com/2017/07/lstm-notes/</guid><description>
&lt;h3 id="参考资料"&gt;参考资料：&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://zh.wikipedia.org/wiki/"&gt;维基百科_长短期记忆(LSTM)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/"&gt;Understanding LSTM Networks&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.jianshu.com/p/9dc9f41f0b29"&gt;[译] 理解 LSTM 网络&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://blog.leanote.com/post/petra_yu/LSTM"&gt;LSTM笔记&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;翻译的比较一般，建议看原文....比如cell还是不要翻译成【细胞】比较好吧...让人以为和生物学的【细胞】有什么关系呢orz&lt;/p&gt;</description></item><item><title>stanford cs 231n:常用激活函数</title><link>https://111qqz.com/2017/07/common-activation-functions/</link><pubDate>Sat, 22 Jul 2017 08:56:08 +0000</pubDate><guid>https://111qqz.com/2017/07/common-activation-functions/</guid><description>
&lt;h4 id="其实我觉得这部分可以直接黑箱直接无脑上leaky-relu或者maxou不过对这些激活函数的特点有个high-level的了解应该总是没坏处的只要别太纠结细节就好了把"&gt;其实我觉得这部分可以直接黑箱。。。直接无脑上Leaky ReLU或者Maxou？不过对这些激活函数的特点有个high-level的了解应该总是没坏处的，只要别太纠结细节就好了把。。&lt;/h4&gt;
&lt;blockquote&gt;每个激活函数（或非线性函数）的输入都是一个数字，然后对其进行某种固定的数学操作。下面是在实践中可能遇到的几种激活函数：
&lt;p&gt;————————————————————————————————————————&lt;/p&gt;</description></item><item><title>how to copy &amp; modify nets model on tensorflow slim</title><link>https://111qqz.com/2017/07/how-to-copy-modify-nets-model-on-tensorflow-slim/</link><pubDate>Wed, 19 Jul 2017 06:21:40 +0000</pubDate><guid>https://111qqz.com/2017/07/how-to-copy-modify-nets-model-on-tensorflow-slim/</guid><description>
&lt;p&gt;想要修改tensorflow-slim 中 nets中的某个model,例如明明为kk_v2.py&lt;/p&gt;
&lt;p&gt;观察到train_image_classifier.py中调用模型的部分&lt;/p&gt;</description></item><item><title>Inception-v4,Inception-ResNet 和残差连接对学习的影响</title><link>https://111qqz.com/2017/07/inception-resnet-notes/</link><pubDate>Tue, 18 Jul 2017 02:42:50 +0000</pubDate><guid>https://111qqz.com/2017/07/inception-resnet-notes/</guid><description>
&lt;p&gt;&lt;a href="https://arxiv.org/abs/1602.07261"&gt;原始论文&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://ask.julyedu.com/question/7711"&gt;翻译链接&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;**——前言：**作者认为残差连接在训练深度卷积模型是很有必要的。至少在图像识别上，我们的研究似乎并不支持这一观点。
&lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt;
近年来，深度卷积神经网络对图像识别性能的巨大提升发挥着关键作用。以Inception网络为例，其以相对较低的计算代价取得出色的表现。最近，与传统结构相结合的残差连接网络在2015ILSVRC挑战赛上取得非常优异的成绩；它的性能跟最新的Inception-v3 网络非常接近。因此也就引出了结合残差连接的Inception结构能否对性能进行提高的问题。本文给出实验证明，残差连接可以明显加速Inception网络的训练。同时实验也证明，相比没有残差连接的消耗相似的Inception网络，残差Inception网络在性能上具有微弱的优势。针对是否包含残差连接的Inception网络，本文同时提出了一些新的简化网络。这些网络的变体在ILSVRC2012分类任务上很明显的改善了单一框架的识别性能。本文进一步展示了适当的激活缩放如何使得很宽的残差Inception网络的训练更加稳定。本文通过对三个残差和一个Inception-v4进行组合，在top-5错误率上达到了 3.08%。&lt;/p&gt;</description></item><item><title>stanford CS231n notes：Linear classification</title><link>https://111qqz.com/2017/07/cs231n-linear-classification/</link><pubDate>Mon, 17 Jul 2017 02:02:43 +0000</pubDate><guid>https://111qqz.com/2017/07/cs231n-linear-classification/</guid><description>
&lt;h4 id="课程链接"&gt;&lt;a href="http://cs231n.github.io/"&gt;课程链接&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21930884"&gt;知乎翻译链接&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;之前看的原版，后来发现知乎上有翻译，正好想到之前看完没有整理总结，干脆就写一下自己的理解，顺便贴一下课程翻译（感觉翻译的质量好像还可以？&lt;/p&gt;
&lt;!-- more --&gt;
&lt;p&gt;分类器就是一个函数,自变量是图像信息，因变量是类别信息。&lt;/p&gt;</description></item><item><title>tensorflow slim 源码分析</title><link>https://111qqz.com/2017/07/tensorflow-slim-code-notes/</link><pubDate>Sun, 16 Jul 2017 13:10:04 +0000</pubDate><guid>https://111qqz.com/2017/07/tensorflow-slim-code-notes/</guid><description>
&lt;p&gt;py的源码看起来还是很愉快的。。。（虽然熟练成程度完全不如cpp。。。。&lt;/p&gt;
&lt;!-- more --&gt;
&lt;p&gt;&lt;a href="https://111qqz.com/wordpress/wp-content/uploads/2017/07/Selection_004.png"&gt;
&lt;img class="image_figure image_external" loading="lazy" src="https://111qqz.com/wordpress/wp-content/uploads/2017/07/Selection_004.png" alt="" /&gt;
&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;datasets里是数据集相关&lt;/p&gt;
&lt;p&gt;deployment是部署相关&lt;/p&gt;
&lt;p&gt;nets里给了很多网络结构&lt;/p&gt;</description></item><item><title>几种梯度下降(GD)法的比较（转载）</title><link>https://111qqz.com/2017/07/Gradient-descent-methods/</link><pubDate>Mon, 10 Jul 2017 01:49:04 +0000</pubDate><guid>https://111qqz.com/2017/07/Gradient-descent-methods/</guid><description>
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Gradient_descent"&gt;参考资料&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;机器学习中梯度下降（Gradient Descent， GD）算法只需要计算损失函数的一阶导数，计算代价小，非常适合训练数据非常大的应用。&lt;/p&gt;
&lt;p&gt;梯度下降法的物理意义很好理解，就是沿着当前点的梯度方向进行线搜索，找到下一个迭代点。但是，为什么有会派生出 batch、mini-batch、online这些GD算法呢？&lt;/p&gt;</description></item><item><title>Deep Learning Tutorial - PCA and Whitening</title><link>https://111qqz.com/2017/07/deep-learning-tutorial-pca-and-whitening/</link><pubDate>Thu, 06 Jul 2017 08:35:51 +0000</pubDate><guid>https://111qqz.com/2017/07/deep-learning-tutorial-pca-and-whitening/</guid><description>
&lt;p&gt;说下我自己的理解&lt;/p&gt;
&lt;p&gt;PCA：主成分分析，是一种预处理手段。对于n维的数据，通过一些手段，把变化显著的k个维度保留，舍弃另外n-k个维度。对于一些非监督学习算法，降低维度可以有效加快运算速度。而n-k个最次要方向的丢失带来的误差不会很大。&lt;/p&gt;</description></item><item><title>文本相似度判断-simhash算法学习笔记</title><link>https://111qqz.com/2017/03/simhash/</link><pubDate>Fri, 10 Mar 2017 03:33:08 +0000</pubDate><guid>https://111qqz.com/2017/03/simhash/</guid><description>
&lt;p&gt;先放原始论文。。。以此表达对这个算法的敬意orz&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.australianscience.com.au/research/google/33026.pdf"&gt;论文链接&lt;/a&gt;&lt;/p&gt;
&lt;h2 id="问题引出"&gt;问题引出：&lt;/h2&gt;
&lt;p&gt;那天百度一面，frog学姐问了我如何判断两篇新闻稿的相似度的问题....我满篇口胡...也只是回答了一些诸如从图片上考虑。。或者去掉stop word之后得到特征向量然后计算余弦值之类得到传统想法。。。&lt;/p&gt;</description></item></channel></rss>
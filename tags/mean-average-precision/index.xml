<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>mean average precision on 111qqz的小窝</title><link>https://111qqz.com/tags/mean-average-precision/</link><description>Recent content in mean average precision on 111qqz的小窝</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><copyright>Copyright © 2012-2022 all rights reserved.</copyright><lastBuildDate>Fri, 09 Feb 2018 03:53:09 +0000</lastBuildDate><atom:link href="https://111qqz.com/tags/mean-average-precision/index.xml" rel="self" type="application/rss+xml"/><item><title>多标签图像分类任务的评价方法-mean average precision(mAP) 以及top x的评价方法</title><link>https://111qqz.com/2018/02/mean-average-precision-for-multi-label-classification-task/</link><pubDate>Fri, 09 Feb 2018 03:53:09 +0000</pubDate><guid>https://111qqz.com/2018/02/mean-average-precision-for-multi-label-classification-task/</guid><description>
参考资料:
多标签图像分类任务的评价方法-mAP
wiki_Sensitivity and specificity
False Positives和False Negative等含义
mean average precision（MAP）在计算机视觉中是如何计算和应用的？
首先需要了解True(False) Positives (Negatives)的含义
True Positive （真正, TP）被模型预测为正的正样本；可以称作判断为真的正确率
True Negative（真负 , TN）被模型预测为负的负样本 ；可以称作判断为假的正确率
False Positive （假正, FP）被模型预测为正的负样本；可以称作误报率
False Negative（假负 , FN）被模型预测为负的正样本；可以称作漏报率
在图像中，尤其是分类问题中应用AP，是一种评价ranking方式好不好的指标：
举例来说，我有一个两类分类问题，分别5个样本，如果这个分类器性能达到完美的话，ranking结果应该是+1，+1，+1，+1，+1，-1，-1，-1，-1，-1.
但是分类器预测的label，和实际的score肯定不会这么完美。按照从大到小来打分，我们可以计算两个指标：precision和recall。比如分类器认为打分由高到低选择了前四个，实际上这里面只有两个是正样本。此时的recall就是2（你能包住的正样本数）/5（总共的正样本数）=0.4，precision是2（你选对了的）/4（总共选的）=0.5.
图像分类中，这个打分score可以由SVM得到：s=w^Tx+b就是每一个样本的分数。
从上面的例子可以看出，其实precision，recall都是选多少个样本k的函数，很容易想到，如果我总共有1000个样本，那么我就可以像这样计算1000对P-R，并且把他们画出来，这就是PR曲线：
Image not found a.warning-link { color: inherit !important; font-weight: inherit !important; text-decoration: underline !important; border-bottom: none !important; } 网站链接: /2018/02/mean-average-precision-for-multi-label-classification-task/https://111qqz.com/wordpress/wp-content/uploads/2018/02/1.png
链接到文件: /content/post/深度学习/https://111qqz.com/wordpress/wp-content/uploads/2018/02/1.png
使用 Page Bundles: true
这里有一个趋势，recall越高，precision越低。这是很合理的，因为假如说我把1000个全拿进来，那肯定正样本都包住了，recall=1，但是此时precision就很小了，因为我全部认为他们是正样本。recall=1时的precision的数值，等于正样本所占的比例。</description></item></channel></rss>
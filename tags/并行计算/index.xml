<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>并行计算 on 111qqz的小窝</title><link>http://example.org/tags/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97/</link><description>Recent content in 并行计算 on 111qqz的小窝</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Mon, 12 Feb 2018 04:58:31 +0000</lastBuildDate><atom:link href="http://example.org/tags/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97/index.xml" rel="self" type="application/rss+xml"/><item><title>CUDA C Best Practices Guide 阅读笔记（1） 并行计算方法论(APOD)</title><link>http://example.org/2018/02/cuda-c-best-practices-parallel-computing-methodology/</link><pubDate>Mon, 12 Feb 2018 04:58:31 +0000</pubDate><guid>http://example.org/2018/02/cuda-c-best-practices-parallel-computing-methodology/</guid><description>APOD指的是Assess, Parallelize, Optimize, Deploy
如图所示，APOD过程是一个循环的过程，每次只进行一部分，从A到P到O到D,然后再进行下一轮的APOD
Assess 对于一个项目，第一步要做的是接触(Assess)项目，得到项目代码中每部分的执行时间。有了这部分内容，开发者就可以找到并行优化的瓶颈所在，并开始尝试用GPU加速。
根据Amdahl&amp;rsquo;s and Gustafson&amp;rsquo;s laws，开发者可以确定并行优化的性能上界。
Parallelize 找到瓶颈所在并确定了优化的目标和期望，开发者就可以优化代码了。调用一些如cuBLAS, cuFFT, or Thrust 的 GPU-optimized library 可能会很有效。
另一方面，有些应用需要开发者重构代码，以此让可以被并行优化得部分被暴露出来。
Optimize 确定了需要被并行优化的部分之后，就要考虑具体得实现方式了。
具体得实现方式通常不过只有一种，所以充分理解应用的需求是很有必要的。
要记得，APOD是一个反复迭代的过程（找到可以优化的点，实现并测试优化，验证优化效果，然后再重复）
因为对于开发者来说，没有必要最初就找到解决所有性能瓶颈的策略。
优化可以在不同的level上进行，配合性能分析工具是很有帮助的。
Deploy 大的原则是当优化完一处之后，立刻将这一部分部署到生产环境，而不是再去寻找其他可以优化的地方。
这样做有很多重要的原因，比如这会使得用户尽早从这个优化中收益（尽管提速只是部分的，但是仍然有价值）
此外，每次有改动就重新部署，也使得变化是平稳而不是激进的，这有助于减少风险。
Recommendations and Best Practice 优化根据对性能影响程度的不同有不同的优先级。
在先要处理低优先级的优化之前，一定要确保其他所有的高优先级优化都做完了。
这种方法将倾向于为所投入的时间提供最佳结果，并且将避免过早优化的陷阱。
需要说明的一点是，教程中的代码为了方便简洁没有关于任何 check error的部分。
在实际上这是不可取的（这不同于编写C++代码!）</description></item><item><title>MPI 学习笔记</title><link>http://example.org/2017/08/mpi-notes/</link><pubDate>Thu, 31 Aug 2017 03:04:27 +0000</pubDate><guid>http://example.org/2017/08/mpi-notes/</guid><description>参考资料：
消息传递接口（MPI）维基百科
MPI_TUTORIAL
MPI 在大规模机器学习领域的前景如何？
因为要和平台组对接工作以及写我们自己的BN同步&amp;hellip;所以来了解一下MPI相关&amp;hellip;感谢平台组@gyz 菊苣提供指导。
下面写一些自己的理解 ^_^
OVERVIEW MPI是一个跨语言的通讯协议，用于并行相关
MPI不是一种具体的语言实现，而是一种标准或者说接口，类比sql在关系型数据库中的地位，具体用的时候我们是用某个特定的实现，例如openmpi或者mpich2
对于机器学习问题，MPI很适合用在超算上&amp;hellip;
下面随便补一些我认为需要了解的：
** **_communicator _是一个进程的group,该group里的所有进程可以相互通信。
在这组进程中，每个进程有一个唯一的rank,通信按照rank进行（做身份标识的作用？
MPI支持的通信方式有point-to-point 和 collective 两种，也就是点对点和广播
下面分别介绍这两种方式。
Blocking point-to-point communication Blocking communication 就是阻塞通信
对于非阻塞通信，不必等到通信操作完全完成便可以返回，该通信操作可以交给特定的通信硬件去完成，在该通信硬件完成该通信操作的同时，处理机可以同时进行计算操作，这样便实现了计算与通信的重叠。通过计算与通信的重叠，可以大大提高程序执行的效率。这一方法和通过异步I/O实现I/O与计算的重叠思路是完全一样的。MPI Send and Receive</description></item></channel></rss>
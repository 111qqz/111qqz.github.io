<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>模型转换 on 111qqz的小窝</title><link>https://111qqz.com/tags/%E6%A8%A1%E5%9E%8B%E8%BD%AC%E6%8D%A2/</link><description>Recent content in 模型转换 on 111qqz的小窝</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><copyright>Copyright © 2012-2022 all rights reserved.</copyright><lastBuildDate>Fri, 18 Sep 2020 11:02:50 +0800</lastBuildDate><atom:link href="https://111qqz.com/tags/%E6%A8%A1%E5%9E%8B%E8%BD%AC%E6%8D%A2/index.xml" rel="self" type="application/rss+xml"/><item><title>【施工中】torch2trt　学习笔记</title><link>https://111qqz.com/2020/09/torch2trt/</link><pubDate>Fri, 18 Sep 2020 11:02:50 +0800</pubDate><guid>https://111qqz.com/2020/09/torch2trt/</guid><description>
前言 偶然发现了 torch2trt 的模型转换方案，思路是直接将pytorch op映射到TensorRT的python api. 在pytorch进行每个op　forward的时候，tensorrt也相应往network上添加op. 这里会先涉及torch2trt的使用，后面会补充这个转换工具的代码学习
使用torch2trt torch2trt pytorch可以直接安装，但是torchvision根据 pytorch-for-jetson-version-1-6-0-now-available 中的说法，需要编译安装
1git clone https://github.com/pytorch/vision 然后切换到tag v0.7.0 执行
1sudo python3 setup.py install 可以正常安装
然后报错: ModuleNotFoundError: No module named 'termcolor'
尝试 sudo apt install python3-termcolor 后解决
接下来尝试trt samples中的　/python/network_api_pytorch_mnist 发现安装pycuda报错找不到cuda.h的头文件 参考　pycuda installation failure on jetson nano 执行了如下命令后成功:
1export LIBRARY_PATH=/usr/local/cuda/targets/aarch64-linux/lib/:$LIBRARY_PATH 2export CPATH=/usr/local/cuda/include:$CPATH 3 然后尝试使用TensorRT python api对一个engine file 做inference的时候，报错: pycuda._driver.LogicError: explicit_context_dependent failed: invalid device context - no currently active context? 在　import pycuda.</description></item></channel></rss>
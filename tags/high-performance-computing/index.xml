<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>High performance computing on 111qqz的小窝</title><link>https://111qqz.com/tags/high-performance-computing/</link><description>Recent content in High performance computing on 111qqz的小窝</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Copyright © 2012-2022 all rights reserved.</copyright><lastBuildDate>Thu, 31 Aug 2017 03:04:27 +0000</lastBuildDate><atom:link href="https://111qqz.com/tags/high-performance-computing/index.xml" rel="self" type="application/rss+xml"/><item><title>MPI 学习笔记</title><link>https://111qqz.com/2017/08/mpi-notes/</link><pubDate>Thu, 31 Aug 2017 03:04:27 +0000</pubDate><guid>https://111qqz.com/2017/08/mpi-notes/</guid><description>
参考资料：
消息传递接口（MPI）维基百科
MPI_TUTORIAL
MPI 在大规模机器学习领域的前景如何？
因为要和平台组对接工作以及写我们自己的BN同步...所以来了解一下MPI相关...感谢平台组@gyz 菊苣提供指导。
下面写一些自己的理解 ^_^
OVERVIEW MPI是一个跨语言的通讯协议，用于并行相关
MPI不是一种具体的语言实现，而是一种标准或者说接口，类比sql在关系型数据库中的地位，具体用的时候我们是用某个特定的实现，例如openmpi或者mpich2
对于机器学习问题，MPI很适合用在超算上...
下面随便补一些我认为需要了解的：
** **_communicator _是一个进程的group,该group里的所有进程可以相互通信。
在这组进程中，每个进程有一个唯一的rank,通信按照rank进行（做身份标识的作用？
MPI支持的通信方式有point-to-point 和 collective 两种，也就是点对点和广播
下面分别介绍这两种方式。
Blocking point-to-point communication Blocking communication 就是阻塞通信
**阻塞通信**是指消息发送方的send调用需要接受方的recv调用的配合才可完成 对于非阻塞通信，不必等到通信操作完全完成便可以返回，该通信操作可以交给特定的通信硬件去完成，在该通信硬件完成该通信操作的同时，处理机可以同时进行计算操作，这样便实现了计算与通信的重叠。通过计算与通信的重叠，可以大大提高程序执行的效率。这一方法和通过异步I/O实现I/O与计算的重叠思路是完全一样的。
MPI Send and Receive</description></item></channel></rss>
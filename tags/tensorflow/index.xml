<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>tensorflow on 111qqz的小窝</title><link>http://example.org/tags/tensorflow/</link><description>Recent content in tensorflow on 111qqz的小窝</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Thu, 24 Aug 2017 09:12:58 +0000</lastBuildDate><atom:link href="http://example.org/tags/tensorflow/index.xml" rel="self" type="application/rss+xml"/><item><title>tensorflow input pipline 学习笔记</title><link>http://example.org/2017/08/tensorflow-input-pipline-notes/</link><pubDate>Thu, 24 Aug 2017 09:12:58 +0000</pubDate><guid>http://example.org/2017/08/tensorflow-input-pipline-notes/</guid><description>参考资料：
tf_doc_Reading data
TENSORFLOW INPUT PIPELINE EXAMPLE
tensorflow：理解tensorflow中的输入管道
第二个参考资料是第一个的翻译版本，翻译的水平一般，建议看原文，不是很长。
下面是我挑了文章中重点的部分+自己的理解。
TL;DR; 一个适用于不是很大的数据集的pipline input 的例子。
Load Data in Tensorflow input pipline 可以理解称一种load data的方式。 一般有两种方式load data,一种是比较传统的，使用feed 的方式。如果数据集比较大，这种方式就不适用了，因为这种方式需要将数据全部导入到memory中。因此tf提供了pipline input的读入数据的方式。
input pipline 会处理 csv file,解码文件格式，重构数据结构，打乱数据顺序，做数据扩充或者其他预处理，然后使用线程(threads)将数据导进batch.
Load the Label Data 确保使用正确的dataset,csv文件路径。
然后处理 得到train和test 的label
由于我们只是读数据而没有真的打算训练，所以没有使用one-hot的编码方式，而是直接将（本来也是由数字字符组成的）字符串，转化成int.
def encode_label(label): return int(label) def read_label_file(file): f = open(file, &amp;quot;r&amp;quot;) filepaths = [] labels = [] for line in f: filepath, label = line.split(&amp;quot;,&amp;quot;) filepaths.append(filepath) labels.append(encode_label(label)) return filepaths, labels # reading labels and file path train_filepaths, train_labels = read_label_file(dataset_path + train_labels_file) test_filepaths, test_labels = read_label_file(dataset_path + test_labels_file) Do Some Optional Processing on Our String Lists # transform relative path into full path train_filepaths = [ dataset_path + fp for fp in train_filepaths] test_filepaths = [ dataset_path + fp for fp in test_filepaths] # for this example we will create or own test partition all_filepaths = train_filepaths + test_filepaths all_labels = train_labels + test_labels # we limit the number of files to 20 to make the output more clear!</description></item><item><title>tensorflow 合并模型</title><link>http://example.org/2017/08/tensorflow-model-merging/</link><pubDate>Mon, 21 Aug 2017 06:56:22 +0000</pubDate><guid>http://example.org/2017/08/tensorflow-model-merging/</guid><description>在这里存个备份，还有些问题没有解决。
raise ValueError(&amp;ldquo;GraphDef cannot be larger than 2GB.&amp;quot;)
记录一些思路好了。现在是没有生成.meta文件，爆掉应该是因为所有的变量都加载到了默认图里。
也就是说我处理完checkpoint 0 之后开始处理checkpoint1,但是checkpoint0的那些变量还是存在的&amp;hellip;所以越来越多？
目前有两个想法，第一个想法是是受TensorFlow极简教程：创建、保存和恢复机器学习模型 中启发，用多个saver，每个saver指定要搞的图（但是这样好像要每个checkpoint都是不同的saver才有意义？）
第二个想法是，每次save完变量之后，将图恢复成默认状态（可以把图中所有变量清空。。
想法二大失败：
会遇到if self.stack[-1] is not default: │ IndexError: list index out of range 的问题。。
根据 reset_default_graph awkwardly breaks graph nesting
中提到了。。。reset_default_graph本身就不舍被设计成放在graph中清空变量用的。。。然后tf的代码也写得很不友好。。。没有 指明这个错误的原因。。。
import sys, getopt import argparse import tensorflow as tf import os import shutil import numpy as np # fix out ,not log_ def fix_var_name(id,var_name): prefix = var_name[0:3] if id&amp;lt;10: suffix = var_name[4:] if id&amp;gt;=10 and id&amp;lt;100: suffix = var_name[5:] if id&amp;gt;=100 and id&amp;lt;1000: suffix = var_name[6:] if id&amp;gt;=1000 and id&amp;lt;10000: suffix = var_name[7:] ret = prefix + str(id+1) + suffix print('id=%d var_name=%s prefix=%s suffix=%s ret=%s' %(id,var_name,prefix,suffix,ret)) return ret # only concat full_link_layer def merge_full_link_layer(checkpoint_list,dry_run=False): with tf.</description></item><item><title>tensorflow checkpoint 学习笔记</title><link>http://example.org/2017/08/tensorflow-checkpoint-notes/</link><pubDate>Mon, 21 Aug 2017 02:03:45 +0000</pubDate><guid>http://example.org/2017/08/tensorflow-checkpoint-notes/</guid><description>参考资料：
What is the TensorFlow checkpoint meta file?
TensorFlow: Restoring variables from from multiple checkpoints
合并模型的时候发现.meta一直在累加，而其他数据文件没有改变。因此来探究一下checkpoint的几个文件的含义。
Assuming that you still have the Python code for your model, you do not need the MetaGraphDefto restore the model, because you can reconstruct all of the information in the MetaGraphDef by re-executing the Python code that builds the model. To restore from a checkpoint, you only need the checkpoint files that contain the trained weights, which are written periodically to the same directory.</description></item><item><title>tensorflow variable 学习笔记</title><link>http://example.org/2017/08/tensorflow-variable-notes/</link><pubDate>Sun, 20 Aug 2017 09:36:00 +0000</pubDate><guid>http://example.org/2017/08/tensorflow-variable-notes/</guid><description>参考资料：
programmers_guide/variables
tf/Variable
之前感觉对tensorflow 的variable的理解不是很深刻&amp;hellip;跑个模型啥的倒不会有什么问题，但是涉及分布式，模型并行之类的，感觉有些地方还是要理解得仔细一点比较好。
OVERVIEW variable的目的是将状态可持久化。
Unlike tf.Tensor objects, a tf.Variable exists outside the context of a singlesession.run call.
通俗地说就是，variable可以用来存储一个可持久化的tensor
一些op允许读取或者修改tensor的值，这些修改是跨session可见的，也就是说，对于用variable可持久化过的tensor,多个worker（多卡之间）之间可以看到相同的值。
Creating a Variable 创建变量可以通过调用tf.get_variable function的方法实现。这个函数要求指明变量名称，这个名称会被作为标识该变量的key。
tf.get_variable也允许变量复用，意思是用之前创建过的有相同名字的变量，创建当前的变量。
my_int_variable = tf.get_variable(&amp;quot;my_int_variable&amp;quot;, [1, 2, 3], dtype=tf.int32, initializer=tf.zeros_initializer) #分别是变量名，shape，变量类型，初始化方法。 #默认类型为tf.float32，默认初始化方法是随机数。 #tf提供很多其他的初始化方法，以及也可以用一个tensor作为初始化。 #注意用tensor作为初始化时，shape就不用提供了，因为会用tensor的shape作为variable的shape Variable collections 由于在不同的部分创建了的变量可能有是够想一起访问，所以我们需要一个简单的能访问一个集合的变量的方法。tensorflow提供了collecetions,可以理解成python list,
是一个存储tensor，variable或者其他实例的容器。
默认情况下，tf.variable被收集到如下两个collcetions:
* tf.GraphKeys.GLOBAL_VARIABLES：放置可以被多个设备共享的variable(从名字中的GLOBAL也可以看出来...) * tf.GraphKeys.TRAINABLE_VARIABLES:用来放置用来计算梯度的variable 如果不想训练某个variable,那么将它加入名字叫tf.GraphKeys.LOCAL_VARIABLES 的默认collection&amp;hellip;
下面是一个将名字叫my_local的variable加入tf.GraphKeys.LOCAL_VARIABLES的例子
my_local = tf.get_variable(&amp;quot;my_local&amp;quot;, shape=(), collections=[tf.GraphKeys.LOCAL_VARIABLES]) 一个等价写法是，将trainable属性设置为False
my_non_trainable = tf.get_variable(&amp;quot;my_non_trainable&amp;quot;, shape=(), trainable=False) 当然自定义collcetion也是可以的，名字可以是任何字符串。</description></item><item><title>tensorflow Session 学习笔记</title><link>http://example.org/2017/08/tensorflow-session-notes/</link><pubDate>Sun, 20 Aug 2017 08:21:57 +0000</pubDate><guid>http://example.org/2017/08/tensorflow-session-notes/</guid><description>tensorflow-session官方文档
说下我自己的理解：
session中文一般叫会话，可以理解成op执行时候需要的一层虚拟化的封装。
op必须在session中才能执行。
tensor也是在tensor中才可以存在（tf.variable和tensor几乎是一回事，只是tf.variable的会话不要求session，也可以理解成tf.variable在session中就成了tensor.
需要注意的是session一般会占据资源，所以在使用完记得释放，或者写成with的形式（看到with总想叫成开域语句&amp;hellip;感觉暴露年龄orz
下面这两种形式是等价的：
# Using the `close()` method. sess = tf.Session() sess.run(...) sess.close() # Using the context manager. with tf.Session() as sess: sess.run(...) session本身有一些配置，我们使用configproto：
# Launch the graph in a session that allows soft device placement and # logs the placement decisions. sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)) allow_soft_placement的作用是自动选择可用的设备（如果指定的设备不可用（？）），防止指定的设备不可用而挂掉的情况。
log_device_placement :To find out which devices your operations and tensors are assigned to.</description></item><item><title>Distributed Tensorflow : Cannot assign a device for operation save</title><link>http://example.org/2017/08/distributed-tensorflow-cannot-assign-a-device-for-operation-save/</link><pubDate>Mon, 14 Aug 2017 01:55:15 +0000</pubDate><guid>http://example.org/2017/08/distributed-tensorflow-cannot-assign-a-device-for-operation-save/</guid><description>是在使用分布式tensorflow遇到的一个错误
报错如下：
InvalidArgumentError (see above for traceback): Cannot assign a device for operation &amp;lsquo;save/Rest│| 2 GeForce GTX 1080 On | 0000:08:00.0 Off | N/A | oreV2_888&amp;rsquo;: Operation was explicitly assigned to /job:worker/task:0/device:CPU:0 but available │| 24% 39C P8 12W / 180W | 0MiB / 8114MiB | 0% Default | devices are [ /job:localhost/replica:0/task:0/cpu:0, /job:localhost/replica:0/task:0/gpu:0 ]. Make sure the device specification refers to a valid device.
其中看到Distributed Tensorflow : Cannot assign a device for operation.</description></item><item><title>分布式 tensorflow 学习笔记(非最终版)</title><link>http://example.org/2017/08/tensorflow-notes/</link><pubDate>Mon, 07 Aug 2017 12:54:23 +0000</pubDate><guid>http://example.org/2017/08/tensorflow-notes/</guid><description>感觉资料不是很多，先收集资料好了。
tf-distributed官网文档
SO-between-graph和in-graph的区别
inception.README.md
SyncReplicasOptimizer
SO_How does ps work in distribute Tensorflow?
update:在多个nodes（机）上跑。。。tf默认是异步更新的。。。同步的话。。大概需要syncreplicasoptimizer?
来直观感受下，不同task的之间并不同步
创建一个cluster 每一个task唯一对应一个server,server中有一个master，还有若干个worker
cluster是task的集合
cluster是在处理分布式问题时抽象出的概念，类似缩点。
cluster也可以划分成一个或者多个job，每个job包含一个或者多个task.
所以task,job,cluster的关系，从集合的角度考虑：
task的集合中的元素，job是task的（不相交？）子集，cluster是task的全集。
（似乎要求所有job的交为空，所有job的补为全集，也就是似乎不能越过job直接到taks(?)）
如下图：
通常不同的task运行在不同的machine上，不过也可以运行在同一个machine的不同device上（比如一个机器的多个gpu)
为了创建一个cluster，要做如下步骤：
创建 一个 tf.train.ClusterSpec 来描述cluster中的全部tasks cluster通过一个dictionary将job(task) map到网络地址，我们将这个地址传递给 tf.train.ClusterSpec 构造器，看如下例子：
我们观察到，task的id是0-base，按照dictionary中的key的顺序自动递增编号的。
在每一个task中创建一个tf.train.Server的实例 tf.train.server包含一些local devices,以及他们和tf.train.clusterspec中描述的其他tasks的connections，还有一个tf.session来实现分布式计算（的交互）
cluster的每个server可以和该cluster中的任意其他server通信
# In task 0: cluster = tf.train.ClusterSpec({&amp;quot;local&amp;quot;: [&amp;quot;localhost:2222&amp;quot;, &amp;quot;localhost:2223&amp;quot;]}) server = tf.train.Server(cluster, job_name=&amp;quot;local&amp;quot;, task_index=0) # In task 1: cluster = tf.train.ClusterSpec({&amp;quot;local&amp;quot;: [&amp;quot;localhost:2222&amp;quot;, &amp;quot;localhost:2223&amp;quot;]}) server = tf.train.Server(cluster, job_name=&amp;quot;local&amp;quot;, task_index=1) 在你的模型中指定分布式设备 还是用tf.</description></item><item><title>tensorflow Supervisor 学习笔记</title><link>http://example.org/2017/08/tensorflow-supervisor-notes/</link><pubDate>Fri, 04 Aug 2017 09:22:44 +0000</pubDate><guid>http://example.org/2017/08/tensorflow-supervisor-notes/</guid><description>update:supervisor的缺点是遇到问题只会抛异常，所以现在有一个better的管理工具,MonitoredSession
master,chief worker,Supervisor 这几个概念有点搞不清（我最菜.jpg 因此来学习一下。
概述 原生的tensorflow 是各种东西都需要自己手动，如果是小规模的训练问题倒是不大，但是如果是训练的数据量比较大，可能需要训练几天或者几个月。。。
那原生的tensorflow的健壮性可能就比较堪忧。。。
万一断电了之类。。。
这时候我们就可以使用supervisor
其主要提供下面三个功能，以增强训练的健壮性：
* Handles shutdowns and crashes cleanly. * Can be resumed after a shutdown or a crash. * Can be monitored through TensorBoard. supervisor可以看做一个工具，或者说是对原生tensorflow的一层封装，目的主要是通过定期save的方法增强训练健壮性，
就算程序挂掉了也可以从上一次save的checkpoint恢复，而不是从头再来（虽然这些也可以手动实现（？）
同时也可以简化代码量
除了supervisor,还有tf.learn库，里面提供对原生tensorflow更高层的封装，也提供更丰富的功能。
实例 来举个具体的例子好了：
在不使用supervisor的时候，我们的训练代码如下：
variables ... ops ... summary_op ... merge_all_summarie saver init_op with tf.Session() as sess: writer = tf.tf.train.SummaryWriter() sess.run(init) saver.restore() for ...: train merged_summary = sess.run(merge_all_summarie) writer.add_summary(merged_summary,i) saver.save 如果使用supervisor，代码如下：</description></item><item><title>TensorFlow Architecture 学习笔记（二）Adding a New Op</title><link>http://example.org/2017/08/tensorflow-architecture-notes-2/</link><pubDate>Wed, 02 Aug 2017 03:07:37 +0000</pubDate><guid>http://example.org/2017/08/tensorflow-architecture-notes-2/</guid><description>Adding a New Op * [目录](https://www.tensorflow.org/extend/adding_an_op#top_of_page) * [定义运算的接口](https://www.tensorflow.org/extend/adding_an_op#define_the_ops_interface) * [实现运算的核心部分(kernels)](https://www.tensorflow.org/extend/adding_an_op#implement_the_kernel_for_the_op) * [多线程cpu kernels](https://www.tensorflow.org/extend/adding_an_op#multi-threaded_cpu_kernels) * [GPU kernels](https://www.tensorflow.org/extend/adding_an_op#gpu_kernels) * [构建运算库](https://www.tensorflow.org/extend/adding_an_op#build_the_op_library) * [用系统编译器编译你的运算（TensorFlow binary installation）](https://www.tensorflow.org/extend/adding_an_op#compile_the_op_using_your_system_compiler_tensorflow_binary_installation) * [使用bazel编译你的运算(TensorFlow source installation)](https://www.tensorflow.org/extend/adding_an_op#compile_the_op_using_bazel_tensorflow_source_installation) * [在 Python 中使用你的运算](https://www.tensorflow.org/extend/adding_an_op#use_the_op_in_python) * [验证你添加的运算可以工作](https://www.tensorflow.org/extend/adding_an_op#verify_that_the_op_works) * [在你的运算中添加高级特性](https://www.tensorflow.org/extend/adding_an_op#building_advanced_features_into_your_op) * [条件检查和验证](https://www.tensorflow.org/extend/adding_an_op#conditional_checks_and_validation) * [Op registration](https://www.tensorflow.org/extend/adding_an_op#op_registration) * [GPU Support](https://www.tensorflow.org/extend/adding_an_op#gpu_support) * [用python 实现梯度](https://www.tensorflow.org/extend/adding_an_op#implement_the_gradient_in_python) * [Shape functions in C++](https://www.tensorflow.org/extend/adding_an_op#shape_functions_in_c) 对于要添加原生tensorflow中没有定义的运算的需求，首先建议在python层面，能不能将需要的op用其他原生的op拼凑起来。
如果不能这样做，或者这样做逻辑很复杂，或者这样做效率比较低的时候，我们才考虑在cpp层面添加一个新的op
去实现你自定义的运算需要如下步骤：
1. 在C++文件中注册该运算。包含参数个数，类型，返回值类型，运算名称等。大概就是C++头文件中函数的定义吧.同时在此处也要定义shape function 2. 用C++实现该运算，运算的实现被称之为kernel，该实现与第一步中的注册对应，相同功能的op对于不同的输入输出类型，或者是架构（GPU,CPU)可能 有不同的实现. 3. 创建一个python包装器（**可选**），该包装器使得可以在python层面用API对该运算进行调用。在运算注册阶段会生成默认的包装器 4. 编写计算该运算梯度 的函数**（可选）** 5. 测试你新添加的运算。为了方便一般在python层面进行测试，不过你想在C++层面测试也没什么问题。 Define the op's interface 直接看代码好了&amp;hellip;</description></item><item><title>TensorFlow Architecture 学习笔记（一）</title><link>http://example.org/2017/08/tensorflow-architecture-notes-1/</link><pubDate>Tue, 01 Aug 2017 03:01:12 +0000</pubDate><guid>http://example.org/2017/08/tensorflow-architecture-notes-1/</guid><description>这篇文章不会涉及tensorflow的具体使用，而是专注于介绍tensorflow的架构，目的是让开发者能够对tensorflow现有框架进行自定义的扩展。
tensorflow被设计用来处理大规模分布式训练，但是也足够灵活去处理新的machine learning模型或是系统层面的优化。
Overview tensorflow的结构图如下：
从下往上大致上抽象程度越来越高。
其中C API那一层将tensorflow底层的runtime core 封装成不同语言（python,cpp,etc)的用户层代码，并提供相应的接口
这篇文章主要侧重如下layer:
* **Client**: * 将计算定义为数据流图. * 使用 **[session](https://www.github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/python/client/session.py)(**会话)启动图 的执行 * **Distributed Master** * 通过Session.run()中参数的定义，修改图中特定的子图 * 将子图分成多个pieces,使之运行在不同的进程和设备中） * 将得到的pieces分发到 worker services上 * 由worker services 启动graph pieces * **Worker Services** (one for each task) * Schedule the execution of graph operations using kernel implementations appropriate to the available hardware (CPUs, GPUs, etc). * 使用kernel中对于特定硬件设备(cpu,gpu,etc)合适的实现去安全图中操作的执行。 * 从其他worker service 处发送或接收运算结果 * **Kernel Implementations** * 完成各个操作的计算 client,master,worker的关系如下</description></item><item><title>how to copy &amp; modify nets model on tensorflow slim</title><link>http://example.org/2017/07/how-to-copy-modify-nets-model-on-tensorflow-slim/</link><pubDate>Wed, 19 Jul 2017 06:21:40 +0000</pubDate><guid>http://example.org/2017/07/how-to-copy-modify-nets-model-on-tensorflow-slim/</guid><description>想要修改tensorflow-slim 中 nets中的某个model,例如明明为kk_v2.py
观察到train_image_classifier.py中调用模型的部分
network_fn = nets_factory.get_network_fn( FLAGS.model_name, num_classes=(dataset.num_classes - FLAGS.labels_offset), weight_decay=FLAGS.weight_decay, is_training=True) 调用了nets_factory.get_network_fn，get_network如下：
def get_network_fn(name, num_classes, weight_decay=0.0, is_training=False): &amp;quot;&amp;quot;&amp;quot;Returns a network_fn such as `logits, end_points = network_fn(images)`. Args: name: The name of the network. num_classes: The number of classes to use for classification. weight_decay: The l2 coefficient for the model weights. is_training: `True` if the model is being used for training and `False` otherwise. Returns: network_fn: A function that applies the model to a batch of images.</description></item><item><title>tensorflow slim 源码分析</title><link>http://example.org/2017/07/tensorflow-slim-code-notes/</link><pubDate>Sun, 16 Jul 2017 13:10:04 +0000</pubDate><guid>http://example.org/2017/07/tensorflow-slim-code-notes/</guid><description>py的源码看起来还是很愉快的。。。（虽然熟练成程度完全不如cpp。。。。
datasets里是数据集相关
deployment是部署相关
nets里给了很多网络结构
preprocessing给了几种预处理的方式
这些都和slim没有太大关系，就不多废话了。
分析的部分见代码注释&amp;hellip;
由于刚刚入门machine learning 一周&amp;hellip;还有很多内容还没有从理论层面接触&amp;hellip;所以源码的理解也十分有限&amp;hellip;希望能以后有机会补充一波
# Copyright 2016 The TensorFlow Authors. All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the &amp;quot;License&amp;quot;); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an &amp;quot;AS IS&amp;quot; BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</description></item></channel></rss>
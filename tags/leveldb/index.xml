<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>levelDB on 111qqz的小窝</title><link>http://example.org/tags/leveldb/</link><description>Recent content in levelDB on 111qqz的小窝</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Sat, 26 Feb 2022 19:10:30 +0800</lastBuildDate><atom:link href="http://example.org/tags/leveldb/index.xml" rel="self" type="application/rss+xml"/><item><title>levelDB 代码阅读笔记 01</title><link>http://example.org/2022/02/leveldb-notes-01/</link><pubDate>Sat, 26 Feb 2022 19:10:30 +0800</pubDate><guid>http://example.org/2022/02/leveldb-notes-01/</guid><description>背景 最近在做一个智能算力相关的项目，类似美团外卖广告智能算力的探索与实践 其中实现控制系统需要与数据库交互。 虽然最后技术选型并没有使用到levelDB,但是想趁机把代码读了吧。
很惊讶的发现我大三的时候声称自己度过部分levelDB代码，甚至还写了几篇相关的博客，比如
murmurhash源码分析 Lock-free vs wait-free concurrency 内存屏障（Memory Barriers） levelDB 学习笔记 但是我却一点都没印象了&amp;hellip;. 仔细看来很多概念在当时可能都是没有充分理解的，而且从数目上来看，应该并没有完整看完levelDB代码。
所以重新开个坑，看看自己比起毕业前有没有长进【没有
先从入口 include/leveldb/db.h 开始
LEVELDB_EXPORT 看到LEVELDB_EXPORT这个macro
class LEVELDB_EXPORT Snapshot { protected: virtual ~Snapshot(); }; 是在 include/leveldb/export.h 中定义的
// 符号可见性问题，使用macro来控制在编译成动态库时暴露，在Link时不暴露符号是一种common 的做法 // #if !defined(LEVELDB_EXPORT) #if defined(LEVELDB_SHARED_LIBRARY)#if defined(_WIN32) #if defined(LEVELDB_COMPILE_LIBRARY)#define LEVELDB_EXPORT __declspec(dllexport)#else#define LEVELDB_EXPORT __declspec(dllimport)#endif // defined(LEVELDB_COMPILE_LIBRARY) #else // defined(_WIN32) #if defined(LEVELDB_COMPILE_LIBRARY)#define LEVELDB_EXPORT __attribute__((visibility(&amp;#34;default&amp;#34;)))#else#define LEVELDB_EXPORT#endif#endif // defined(_WIN32) #else // defined(LEVELDB_SHARED_LIBRARY) #define LEVELDB_EXPORT#endif #endif // !</description></item><item><title>levelDB 使用笔记</title><link>http://example.org/2018/04/leveldb-notes/</link><pubDate>Thu, 19 Apr 2018 15:58:40 +0000</pubDate><guid>http://example.org/2018/04/leveldb-notes/</guid><description>2022-02-26 update:
说学习笔记听起来像在分析代码。。。但是实际上什么都没干，还是写&amp;quot;使用笔记&amp;quot;好了
大三的时候看过一点levelDB的源码，不过没有怎么用过。
最近有个需求是存人脸的feature到硬盘，似乎使用levelDB比较合适，因此来学习一下使用。
先放参考资料。
关于levelDB的语法，看这里就好了。
以及由于caffe中使用了levelDB，因此也可以参考下caffe源码。不过caffe中对levelDB的使用是又封装了一层。
具体可以参考：
#ifdef USE_LEVELDB #ifndef CAFFE_UTIL_DB_LEVELDB_HPP #define CAFFE_UTIL_DB_LEVELDB_HPP #include &amp;lt;string&amp;gt; #include &amp;quot;leveldb/db.h&amp;quot; #include &amp;quot;leveldb/write_batch.h&amp;quot; #include &amp;quot;caffe/util/db.hpp&amp;quot; namespace caffe { namespace db { class LevelDBCursor : public Cursor { public: explicit LevelDBCursor(leveldb::Iterator* iter) : iter_(iter) { SeekToFirst(); CHECK(iter_-&amp;gt;status().ok()) &amp;lt;&amp;lt; iter_-&amp;gt;status().ToString(); } ~LevelDBCursor() { delete iter_; } virtual void SeekToFirst() { iter_-&amp;gt;SeekToFirst(); } virtual void Next() { iter_-&amp;gt;Next(); } virtual string key() { return iter_-&amp;gt;key().ToString(); } virtual string value() { return iter_-&amp;gt;value().</description></item><item><title>murmurhash源码分析</title><link>http://example.org/2017/03/reading-murmurhash-code/</link><pubDate>Wed, 22 Mar 2017 12:20:37 +0000</pubDate><guid>http://example.org/2017/03/reading-murmurhash-code/</guid><description>分析levelDB源码的时候遇到的&amp;hellip;发现是一个广泛应用的hash算法，而且是纯c写的，于是找来了源码看。
最初的实现是C++的，但是被移植到了其他的流行语言上，包括 Python,[11]C,[12]C#,[9][13]Perl,[14]Ruby,[15]PHP,[16]Haskell,[17]、Scala[18]、Java[19][20]和JavaScript[21][22]等。
这个算法已经被若干开源计划所采纳，最重要的有libstdc++ (4.6版)、Perl[23]、nginx (不早于1.0.1版)[24]、Rubinius[25]、 libmemcached (Memcached的C语言客户端驱动)[26]、maatkit[27]、Hadoop[1]、Kyoto Cabinet[28]以及RaptorDB[29]。虽然说破天就是一个hash函数。。似乎没什么好分析的？
不过由于是第一次分析有现实意义的代码，所以简单一点也不是罪过吧orz
以及这次分析代码的重点不在hash算法本身&amp;hellip;而是算法之外的其他东西&amp;hellip;
大概感受下有现实意义的工程代码的布局之类orz
hash函数本身没有分析&amp;hellip;这个没什么好分析的吧&amp;hellip;应该是类似一种构造，看懂每一步很容易，但是你还是想不出来啊？而且一堆&amp;quot;magic number&amp;rdquo;
代码很短，也就200行,分析见注释。
/** * `main.c' - murmurhash * * copyright (c) 2014 joseph werle &amp;lt;joseph.werle@gmail.com&amp;gt; */ #include &amp;lt;stdio.h&amp;gt; #include &amp;lt;stdlib.h&amp;gt; #include &amp;lt;string.h&amp;gt; #include &amp;lt;unistd.h&amp;gt; #include &amp;lt;inttypes.h&amp;gt; #include &amp;quot;murmurhash.h&amp;quot; static void usage () { fprintf(stderr, &amp;quot;usage: murmur [-hV] [options]\n&amp;quot;); } static void //函数类型和函数名不一行写是什么风格orz... help () { fprintf(stderr, &amp;quot;\noptions:\n&amp;quot;); fprintf(stderr, &amp;quot;\n --seed=[seed] hash seed (optional)&amp;quot;); fprintf(stderr, &amp;quot;\n&amp;quot;); } static char * read_stdin () { size_t bsize = 1024; size_t size = 1; char buf[bsize]; char *res = (char *) malloc(sizeof(char) * bsize); char *tmp = NULL; // memory issue if (NULL == res) { return NULL; } //申请内存失败了.</description></item><item><title>内存屏障（Memory Barriers）</title><link>http://example.org/2017/03/memory-barriers/</link><pubDate>Wed, 22 Mar 2017 05:16:53 +0000</pubDate><guid>http://example.org/2017/03/memory-barriers/</guid><description>起因是最近在看levelDB源码，其中port里的atomic_pointer.h文件用到了内存屏障。。
于是来学习一下。。
粗略得说下我自己的理解。
代码的顺序并不和执行的顺序完全对应，出于对效率的追求，cpu和编译器会对一些顺序指令重排，以期得到最大的执行效率。
比如下面这段代码：
// example 2 // void *ptr, v, _store; v = ptr; _store = v; somefunc(); v = _store; v的值是没有改变的，那么编译器可能会认为_store = v; v = _store; 是多余的，就直接把这一段给“优化”掉了。这段代码在单线程中确实是多余的，但是在多线程环境下，可能在somefunc()被调用的时候，另一个线程把v的值给改变了，而这种情况是编译器无法发现的。因此，为了避免这种情况。。。内存屏障登场！
摘自维基百科：
大多数现代计算机为了提高性能而采取乱序执行，这使得内存屏障成为必须。
语义上，内存屏障之前的所有写操作都要写入内存；内存屏障之后的读操作都可以获得同步屏障之前的写操作的结果。因此，对于敏感的程序块，写操作之后、读操作之前可以插入内存屏障。再看一个例子
// get start time for (int i = 0; i != 100000; i++) { MemoryBarrier() } // get end time 这段代码，是想知道for循环空转100000次的耗时，这里就需要加入一个MemoryBarrier，如果不加，那么编译器可能就会直接把这个无意义的for循环直接优化掉了。
除了编译器，cpu由于指令流水线或者超流水线等计数，也可能导致出现乱序执行的情况。
内存屏障提供了两个功能。首先，它们通过确保从另一个CPU来看屏障的两边的所有指令都是正确的程序顺序，而保持程序顺序的外部可见性；其次它们可以实现内存数据可见性，确保内存数据会同步到CPU缓存子系统。
不过内存平展由于阻碍了cpu和编译器的部分优化。。。因此对性能的影响是不忽略的。
内存屏障的实现不同平台差别很大。。。因为我们可以看到atomic_pointer.h文件中 一堆和平台相关的条件编译&amp;hellip;
// Copyright (c) 2011 The LevelDB Authors. All rights reserved.</description></item><item><title>Lock-free vs wait-free concurrency</title><link>http://example.org/2017/03/lock-free-vs-wait-free-concurrency/</link><pubDate>Tue, 21 Mar 2017 09:24:56 +0000</pubDate><guid>http://example.org/2017/03/lock-free-vs-wait-free-concurrency/</guid><description>参考资料
看leveldb源码中遇到的，关于lock-free 和 wait-free..感觉这个讲得不错，我试着翻译一下？
有两种 无阻塞线程同步算法，一种是lock-free，一种是wait-free，它们的含义经常被搞混。在一个lock-free系统中，尽管某个特定的计算会被阻碍一段时间，所有的cpu还是能够继续其他计算。换一种说法，尽管在一个lock-free的系统里，一个线程可能被其他线程阻碍，所有的cpu仍然可以继续做其他工作而不做停顿。lock-free算法通过偶然增加一个特定事物的延迟，增加了系统总体的吞吐率。大多数高端数据库系统都在某种程度上基于lock-free 算法。
与此相反，wait-free算法除了保证所有cpu继续做其他工作以外，还保证不会有任何计算被另一个计算阻止。wait-free算法比lock-free算法有更强的保证，确保了在不牺牲某一事物的延迟的基础上，拥有更高的吞吐率.wait-free算法因此也更加难以实现，测试，调试。linux内核的无锁页面缓存（？）就是一个wait-free系统的例子。
在一个系统处理几十个并发事务并且对延迟要求不高的情况下，lock-free系统是开发复杂性和高并发性要求之间的良好折衷。一个网站的数据库服务器是lock-free系统的很好的体现。尽管某个特定的事物可能被阻塞，但同时也有更多的事务要处理，所以CPU永远不会空闲。面临的挑战是建立一个好的事物调度表，以此来获得尽可能低的平均延迟和一个有界的标准偏差。
在一个场景中，系统与CPU内核大致相同数量的并发事务，或者有硬实时要求，开发人员需要花费额外的时间来构建wait-free系统。在这种情况下，阻塞单个事务是不可接受的，要么是因为CPU没有其他事务要处理从而减少了吞吐量，要么是给定的事务需要用一个定义良好的非概率时间段来完成（相对比较确定的时间的意思？）。核反应堆控制软件是wait-free系统的一个很好的体现。</description></item></channel></rss>
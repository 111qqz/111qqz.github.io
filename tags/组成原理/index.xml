<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>组成原理 on 111qqz的小窝</title><link>https://111qqz.com/tags/%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/</link><description>Recent content in 组成原理 on 111qqz的小窝</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><copyright>Copyright © 2012-2022 all rights reserved.</copyright><lastBuildDate>Wed, 15 Mar 2017 00:34:50 +0000</lastBuildDate><atom:link href="https://111qqz.com/tags/%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/index.xml" rel="self" type="application/rss+xml"/><item><title>缓存淘汰算法之LRU（转载）</title><link>https://111qqz.com/2017/03/lru/</link><pubDate>Wed, 15 Mar 2017 00:34:50 +0000</pubDate><guid>https://111qqz.com/2017/03/lru/</guid><description>
参考博客
计组块忘光了呜呜呜。。。来复习一波。。
1. LRU 1.1. 原理
LRU（Least recently used，最近最少使用）算法根据数据的历史访问记录来进行淘汰数据，其核心思想是“如果数据最近被访问过，那么将来被访问的几率也更高”。
1.2. 实现 最常见的实现是使用一个链表保存缓存数据，详细算法实现如下：
Image not found a.warning-link { color: inherit !important; font-weight: inherit !important; text-decoration: underline !important; border-bottom: none !important; } 网站链接: /2017/03/lru/http://my.csdn.net/uploads/201205/24/1337859321_3597.png
链接到文件: /content/post/ACM-ICPC/http://my.csdn.net/uploads/201205/24/1337859321_3597.png
使用 Page Bundles: true
1. 新数据插入到链表头部；
2. 每当缓存命中（即缓存数据被访问），则将数据移到链表头部；
3. 当链表满的时候，将链表尾部的数据丢弃。
1.3. 分析 【命中率】
当存在热点数据时，LRU的效率很好，但偶发性的、周期性的批量操作会导致LRU命中率急剧下降，缓存污染情况比较严重。
【复杂度】
实现简单。
【代价】
命中时需要遍历链表，找到命中的数据块索引，然后需要将数据移到头部。
2. LRU-K 2.1. 原理 LRU-K中的K代表最近使用的次数，因此LRU可以认为是LRU-1。LRU-K的主要目的是为了解决LRU算法“缓存污染”的问题，其核心思想是将“最近使用过1次”的判断标准扩展为“最近使用过K次”。
2.2. 实现 相比LRU，LRU-K需要多维护一个队列，用于记录所有缓存数据被访问的历史。只有当数据的访问次数达到K次的时候，才将数据放入缓存。当需要淘汰数据时，LRU-K会淘汰第K次访问时间距当前时间最大的数据。详细实现如下：
Image not found a.warning-link { color: inherit !</description></item></channel></rss>
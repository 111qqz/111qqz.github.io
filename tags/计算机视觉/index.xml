<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>计算机视觉 on 111qqz的小窝</title><link>https://111qqz.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/</link><description>Recent content in 计算机视觉 on 111qqz的小窝</description><generator>Hugo -- gohugo.io</generator><language>zh</language><copyright>Copyright © 2012-2022 all rights reserved.</copyright><lastBuildDate>Sun, 05 Apr 2020 20:38:28 +0800</lastBuildDate><atom:link href="https://111qqz.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/index.xml" rel="self" type="application/rss+xml"/><item><title>Faster Rcnn 目标检测算法</title><link>https://111qqz.com/2020/04faster-rcnn/</link><pubDate>Sun, 05 Apr 2020 20:38:28 +0800</pubDate><guid>https://111qqz.com/2020/04faster-rcnn/</guid><description>
&lt;h2 id="背景">背景&lt;/h2>
&lt;p>2019年对了好几次faster rcnn，第一次是赛事之窗项目和北京的同事，对齐sdk和训练的实现。
第二次是被tensorRT4和tensorRT5之间默认参数不一致的问题坑了一下。
第三次是被caffe proto中roi align 的默认参数坑了。&lt;/p></description></item><item><title>resnet 学习笔记</title><link>https://111qqz.com/2020/04resnet-learning-notes/</link><pubDate>Sun, 05 Apr 2020 16:49:44 +0800</pubDate><guid>https://111qqz.com/2020/04resnet-learning-notes/</guid><description>
&lt;h2 id="背景">背景&lt;/h2>
&lt;p>基于Conv的方法在某年的ImageNet比赛上又重新被人想起之后，大家发现网络堆叠得越深，似乎在cv的各个任务上表现的越好。&lt;/p>
&lt;p>然而事情当然没有无脑退跌深度那么简单，人们发现，当网络深到一定程度时，结果还不如浅一些的网络结构。&lt;/p></description></item></channel></rss>
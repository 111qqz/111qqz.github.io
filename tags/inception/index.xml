<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Inception on 111qqz的小窝</title><link>https://111qqz.com/tags/inception/</link><description>Recent content in Inception on 111qqz的小窝</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><copyright>Copyright © 2012-2022 all rights reserved.</copyright><lastBuildDate>Tue, 18 Jul 2017 02:42:50 +0000</lastBuildDate><atom:link href="https://111qqz.com/tags/inception/index.xml" rel="self" type="application/rss+xml"/><item><title>Inception-v4,Inception-ResNet 和残差连接对学习的影响</title><link>https://111qqz.com/2017/07/inception-resnet-notes/</link><pubDate>Tue, 18 Jul 2017 02:42:50 +0000</pubDate><guid>https://111qqz.com/2017/07/inception-resnet-notes/</guid><description>
原始论文
翻译链接
**——前言：**作者认为残差连接在训练深度卷积模型是很有必要的。至少在图像识别上，我们的研究似乎并不支持这一观点。 摘要： 近年来，深度卷积神经网络对图像识别性能的巨大提升发挥着关键作用。以Inception网络为例，其以相对较低的计算代价取得出色的表现。最近，与传统结构相结合的残差连接网络在2015ILSVRC挑战赛上取得非常优异的成绩；它的性能跟最新的Inception-v3 网络非常接近。因此也就引出了结合残差连接的Inception结构能否对性能进行提高的问题。本文给出实验证明，残差连接可以明显加速Inception网络的训练。同时实验也证明，相比没有残差连接的消耗相似的Inception网络，残差Inception网络在性能上具有微弱的优势。针对是否包含残差连接的Inception网络，本文同时提出了一些新的简化网络。这些网络的变体在ILSVRC2012分类任务上很明显的改善了单一框架的识别性能。本文进一步展示了适当的激活缩放如何使得很宽的残差Inception网络的训练更加稳定。本文通过对三个残差和一个Inception-v4进行组合，在top-5错误率上达到了 3.08%。
前言： 自从Krizhevsky等人于2012年赢得Image Net比赛，其网络“AlexNet”已在越来越多的机器视觉任务中得到成功应用，比如目标检测、分割、人体姿态估计、视频分类、目标跟踪、超分辨率等。这些都是使用深度卷积网络的成功案例。 本研究结合最近的两个想法：残差连接和最近的Inception网络结构除了直接的融合，我们也研究了Inception本身通过变得更深更宽能否能变得更加高效。为了实现这个目的，我们设计了一个新版本的Inception-v4，相比Inception-v3，它有更加统一简化的网络结构和更多的inception模块。从历史观点来看，Inception-v3继承了之前的很多方法。技术性局限主要在于使用DistBelief对分布式训练进行模型划分。 如今，将训练迁移到TensorFlow上以后，这些问题也就随之解决，这样就允许我们对结构进行简化。简化的网络结构详见第三节。 在本文中，我们将两个单一Inception变体——Inception-v3和v4与消耗相似的 InceptionResNet混合版本进行比较。这些模型的挑选主要满足以下约束条件，即和非残差模型具有相似的参数和计算复杂度。事实上我们对更深更宽的Inception-ResNet变体也进行测试，它们在ImageNet分类任务上表现性能相似。 最新的实验对组合模型的性能进行了评估。结果显示Inception-v4和Inception-ResNetv2的性能都很好，在ImageNet验证集上其性能已超过业界领先的单个框架模型，我们想看这种结合如何将业界领先水准继续推进，令人惊讶的是，我们发现单个框架性能的提升不会引起组合性能大幅的提高。尽管如此，我们仍然用四个模型组合在验证集上取得了top-5上3.1%的错误率。 在最后一部分，我们分析了分类任务失败的原因，并总结出组合模型在标注数据上的类标噪声上仍然没有达到很好的效果，同时对于预测还有很有大的提升空间。
近期工作： 卷积网络在大规模图像识别任务上的运用非常广泛。主要的模型有Network-in-network、VGGNet、GoogleLeNet(Inception-v1)。残差连接在引文5中提出，并指出附加残差网络对于图像识别尤其是目标检测具有很大的优势，并给出理论和实验验证。作者认为残差连接在训练深度卷积模型是很有必要的。至少在图像识别上，我们的研究似乎并不支持这一观点。然而，残差连接所带来的潜在优势可能需要在更深网络结构中来展现。在实验部分，我们展示了不使用残差连接时深度网络的训练并不难做到。然而，使用残差连接能够极大的提高训练速度，单单这一点就值的肯定。 Inception深度卷积网络被称为GoogleLeNet或Incention-v1。继而我们通过各种方法对 Inception结构进行优化，首先引入batch normalization(Inception-v2)。后来在第三代中增加factorization因子，即本文中提到的Inception-v3。
Image not found a.warning-link { color: inherit !important; font-weight: inherit !important; text-decoration: underline !important; border-bottom: none !important; } 网站链接: /2017/07/inception-resnet-notes/https://ask.julyedu.com/uploads/questions/20170322/25b2acffee48ae5438f54a26871be517.png
链接到文件: /content/post/ACM-ICPC/https://ask.julyedu.com/uploads/questions/20170322/25b2acffee48ae5438f54a26871be517.png
使用 Page Bundles: true
图1.残差连接
Image not found a.warning-link { color: inherit !important; font-weight: inherit !important; text-decoration: underline !important; border-bottom: none !</description></item></channel></rss>
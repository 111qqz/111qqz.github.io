<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Inception on 111qqz的小窝</title><link>http://example.org/tags/inception/</link><description>Recent content in Inception on 111qqz的小窝</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Tue, 18 Jul 2017 02:42:50 +0000</lastBuildDate><atom:link href="http://example.org/tags/inception/index.xml" rel="self" type="application/rss+xml"/><item><title>Inception-v4,Inception-ResNet 和残差连接对学习的影响</title><link>http://example.org/2017/07/inception-resnet-notes/</link><pubDate>Tue, 18 Jul 2017 02:42:50 +0000</pubDate><guid>http://example.org/2017/07/inception-resnet-notes/</guid><description>原始论文
翻译链接
摘要： 近年来，深度卷积神经网络对图像识别性能的巨大提升发挥着关键作用。以Inception网络为例，其以相对较低的计算代价取得出色的表现。最近，与传统结构相结合的残差连接网络在2015ILSVRC挑战赛上取得非常优异的成绩；它的性能跟最新的Inception-v3 网络非常接近。因此也就引出了结合残差连接的Inception结构能否对性能进行提高的问题。本文给出实验证明，残差连接可以明显加速Inception网络的训练。同时实验也证明，相比没有残差连接的消耗相似的Inception网络，残差Inception网络在性能上具有微弱的优势。针对是否包含残差连接的Inception网络，本文同时提出了一些新的简化网络。这些网络的变体在ILSVRC2012分类任务上很明显的改善了单一框架的识别性能。本文进一步展示了适当的激活缩放如何使得很宽的残差Inception网络的训练更加稳定。本文通过对三个残差和一个Inception-v4进行组合，在top-5错误率上达到了 3.08%。
前言： 自从Krizhevsky等人于2012年赢得Image Net比赛，其网络“AlexNet”已在越来越多的机器视觉任务中得到成功应用，比如目标检测、分割、人体姿态估计、视频分类、目标跟踪、超分辨率等。这些都是使用深度卷积网络的成功案例。 本研究结合最近的两个想法：残差连接和最近的Inception网络结构除了直接的融合，我们也研究了Inception本身通过变得更深更宽能否能变得更加高效。为了实现这个目的，我们设计了一个新版本的Inception-v4，相比Inception-v3，它有更加统一简化的网络结构和更多的inception模块。从历史观点来看，Inception-v3继承了之前的很多方法。技术性局限主要在于使用DistBelief对分布式训练进行模型划分。 如今，将训练迁移到TensorFlow上以后，这些问题也就随之解决，这样就允许我们对结构进行简化。简化的网络结构详见第三节。 在本文中，我们将两个单一Inception变体——Inception-v3和v4与消耗相似的 InceptionResNet混合版本进行比较。这些模型的挑选主要满足以下约束条件，即和非残差模型具有相似的参数和计算复杂度。事实上我们对更深更宽的Inception-ResNet变体也进行测试，它们在ImageNet分类任务上表现性能相似。 最新的实验对组合模型的性能进行了评估。结果显示Inception-v4和Inception-ResNetv2的性能都很好，在ImageNet验证集上其性能已超过业界领先的单个框架模型，我们想看这种结合如何将业界领先水准继续推进，令人惊讶的是，我们发现单个框架性能的提升不会引起组合性能大幅的提高。尽管如此，我们仍然用四个模型组合在验证集上取得了top-5上3.1%的错误率。 在最后一部分，我们分析了分类任务失败的原因，并总结出组合模型在标注数据上的类标噪声上仍然没有达到很好的效果，同时对于预测还有很有大的提升空间。
近期工作： 卷积网络在大规模图像识别任务上的运用非常广泛。主要的模型有Network-in-network、VGGNet、GoogleLeNet(Inception-v1)。残差连接在引文5中提出，并指出附加残差网络对于图像识别尤其是目标检测具有很大的优势，并给出理论和实验验证。作者认为残差连接在训练深度卷积模型是很有必要的。至少在图像识别上，我们的研究似乎并不支持这一观点。然而，残差连接所带来的潜在优势可能需要在更深网络结构中来展现。在实验部分，我们展示了不使用残差连接时深度网络的训练并不难做到。然而，使用残差连接能够极大的提高训练速度，单单这一点就值的肯定。 Inception深度卷积网络被称为GoogleLeNet或Incention-v1。继而我们通过各种方法对 Inception结构进行优化，首先引入batch normalization(Inception-v2)。后来在第三代中增加factorization因子，即本文中提到的Inception-v3。
图1.残差连接
图2.优化版本的ResNet连接 3.结构选择 3.1纯净的Inception模块 我们对以前的Inception模型通过分布式进行训练，将每个副本被划分成一个含多个子网络的模型，以达到在内存中对整个模型进行拟合的目的。然而，Inception结构是高度可调的，这就意味着各层滤波器（filter）的数量可以有多种变化，而整个训练网络的质量不会受到影响。为了优化训练速度，我们对层大小进行调整以平衡不同子网络的计算。 相反，随着TensorFlow的引入，大部分最新的模型无需分布式的对副本进行训练。它通过反向传播（back propagation）进行内存优化，并仔细考虑梯度计算需要的tensors，以及通过结构化计算减少这类tensors的数量。从历史观点来讲，我们对网络结构的更迭已经做得非常保守，并限制实验改变独立网络的组分，同时保持其余网络的稳定性。 由于之前没有对网络进行简化，导致网络看起来更加复杂。在最新的实验中，针对 Inception-v4网络，我们决定丢掉不必要的包袱，对于inception块的每个网格大小进行统一。如图9，展示了大尺寸的Inceptionv4网络结构。图3至8是每个部分的详细结构。所有图中没有标记“V”的卷积使用same的填充原则，意即其输出网格与输入的尺寸正好匹配。使用“V”标记的卷积使用valid的填充原则，意即每个单元输入块全部包含在前几层中，同时输出激活图（output activation map）的网格尺寸也相应会减少。
图3 Inception-v4网络和Inception-ResNet-v2网络的结构。这是网络的输入部分。
图 4 Inception-v4网络35×35网格的框架。对应图9中Inception-A块。
图 5 Incep-v4网络17×17网格块的框架。对应图9中Inception-B块。
图 6 Inception-v4网络的8×8网格模块的框架。对应图9中Inception-C块。
图7 35×35到17×17减少模块的框架。这个块不同的变化（不同滤波器）在图9和15中使用，同时在网络Inception(-v4,-ResNet-v1,-ResNet-v2).k,l,m,n数量表示滤波器尺寸大小，如表1所示。
图 8 17×17到8×8网格缩减框架。减少的模块在图9中Inception-v4网络。</description></item></channel></rss>
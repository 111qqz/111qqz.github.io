<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Jetson Nano on 111qqz的小窝</title><link>https://111qqz.com/tags/jetson-nano/</link><description>Recent content in Jetson Nano on 111qqz的小窝</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Copyright © 2012-2022 all rights reserved.</copyright><lastBuildDate>Fri, 18 Sep 2020 11:02:50 +0800</lastBuildDate><atom:link href="https://111qqz.com/tags/jetson-nano/index.xml" rel="self" type="application/rss+xml"/><item><title>【施工中】torch2trt　学习笔记</title><link>https://111qqz.com/2020/09/torch2trt/</link><pubDate>Fri, 18 Sep 2020 11:02:50 +0800</pubDate><guid>https://111qqz.com/2020/09/torch2trt/</guid><description>
前言 偶然发现了 torch2trt 的模型转换方案，思路是直接将pytorch op映射到TensorRT的python api. 在pytorch进行每个op　forward的时候，tensorrt也相应往network上添加op. 这里会先涉及torch2trt的使用，后面会补充这个转换工具的代码学习
使用torch2trt torch2trt pytorch可以直接安装，但是torchvision根据 pytorch-for-jetson-version-1-6-0-now-available 中的说法，需要编译安装
1git clone https://github.com/pytorch/vision 然后切换到tag v0.7.0 执行
1sudo python3 setup.py install 可以正常安装
然后报错: ModuleNotFoundError: No module named 'termcolor'
尝试 sudo apt install python3-termcolor 后解决
接下来尝试trt samples中的　/python/network_api_pytorch_mnist 发现安装pycuda报错找不到cuda.h的头文件 参考　pycuda installation failure on jetson nano 执行了如下命令后成功:
1export LIBRARY_PATH=/usr/local/cuda/targets/aarch64-linux/lib/:$LIBRARY_PATH 2export CPATH=/usr/local/cuda/include:$CPATH 3 然后尝试使用TensorRT python api对一个engine file 做inference的时候，报错: pycuda._driver.LogicError: explicit_context_dependent failed: invalid device context - no currently active context? 在　import pycuda.</description></item><item><title>Jetson Nano踩坑记录</title><link>https://111qqz.com/2020/09/jetson-nano/</link><pubDate>Tue, 08 Sep 2020 14:41:34 +0800</pubDate><guid>https://111qqz.com/2020/09/jetson-nano/</guid><description>
写在前面 主要是需要在jetson nano做模型转换，来记录下踩的坑 目前有两条路径，一条是我们现有的转换路径，也就是pytorch-&amp;gt;onnx(-&amp;gt;caffe)-&amp;gt;trt的路径 在这条路径上踩了比较多的坑，最终暂时放弃，最直接的原因是cudnn8.0升级接口发生改动，编译caffe遇到较多问题 这里其实仍然采用了两条平行的路径，一条是直接在nano上构建环境，另外一种是基于docker(包括构建交叉编译环境用于加快编译速度)
另一条路径是基于torch2trt,是一条直接pytorch-&amp;gt;trt的路径 这里主要记录在第一条路径上踩过的坑
环境准备 先过一遍开发者手册 主要是介绍了下nano的硬件和jetpack的组件 jetpack可以理解成一个nvidia用在嵌入式设备上的SDK工具包
镜像烧录 然后需要烧录镜像，参考Write Image to the microSD Card 最初使用 Etcher 来烧录，没有启动起来，原因未知。使用终端命令烧录就没问题了。
更换国内apt源 我拿到的jeston nano是基于ubuntu 18.04 lts的版本，默认源比较慢，换成国内源。需要注意要换arm版本的源
1wget -O /etc/apt/sources.list https://repo.huaweicloud.com/repository/conf/Ubuntu-Ports-bionic.list 2apt update 基于docker的模型转换 由于在x86上模型转换的工具是基于docker的，因此最初的想法是在nano上也基于docker进行转模型，这样或许可以复用一些x86上的工作。
确认了Jetson Nano上是可以跑docker和NVIDIA Container Runtime on Jetson (Beta)的 但是最初发现arm的cuda docker image最低支持cuda11.0的版本 cuda-arm64 docker image tag 然而目前(2020年9月)最新的jetpack4.4版本只支持到cuda10.2的版本 尝试了下使用cuda-arm64的docker image　发现驱动版本不够，而nano上似乎很难升级驱动版本，因此差点就放弃这条路径了。
然而发现，在nano上要用的cuda镜像并不应该是cuda-arm,而是NVIDIA L4T Base
结论 参考https://docs.nvidia.com/jetson/archives/，发现一个可能的问题是，jetpack中cuDNN,TensorRT等库的版本不是连续的。
jetpack4.4: CUDA10.2,TensorRT 7.1.3,cuDNN 8.0.0 jetpack4.3: CUDA 10.0.326, TensorRT 6.0.1.10, cuDNN 7.</description></item></channel></rss>
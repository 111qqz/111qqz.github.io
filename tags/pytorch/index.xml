<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>pytorch on 111qqz的小窝</title><link>https://111qqz.com/tags/pytorch/</link><description>Recent content in pytorch on 111qqz的小窝</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Copyright © 2012-2022 all rights reserved.</copyright><lastBuildDate>Sun, 17 Dec 2023 18:22:24 +0800</lastBuildDate><atom:link href="https://111qqz.com/tags/pytorch/index.xml" rel="self" type="application/rss+xml"/><item><title>[施工中] cupy与torch的导入顺序不同对计算结果的影响</title><link>https://111qqz.com/2023/12/cupy-torch-import-order-impact/</link><pubDate>Sun, 17 Dec 2023 18:22:24 +0800</pubDate><guid>https://111qqz.com/2023/12/cupy-torch-import-order-impact/</guid><description>
背景 公司内部的基于torch的toolbox发现某个版本之后,结果发生了偏移. 通过一系列排查,发现当导入cupy和torch的顺序不同时，计算结果会有所差异。 也就是说,如下两段代码会导致模型训练等环节的计算得到不同的结果.
1import cupy as cp 2import torch 1import torch 2import cupy as cp 3 最小复现代码 经过一番努力,把问题从内部框架中剥离了出来. 如下是得到的最小复现代码. 通过调整import cupy与import torch的相对顺序,会得到不同的结果.
1# import cupy as cp 2import torch 3import torch.nn as nn 4import cupy as cp 5import random 6import numpy as np 7 8# 设置随机种子 9def set_random_seed(seed: int): 10 random.seed(seed) 11 np.random.seed(seed) 12 torch.manual_seed(seed) 13 torch.cuda.manual_seed(seed) 14 torch.cuda.manual_seed_all(seed) 15 cp.random.seed(seed) 16 17# 定义一个简单的MLP模型 18class MLP(nn.Module): 19 def __init__(self): 20 super(MLP, self).</description></item><item><title>pytorch 函数笔记</title><link>https://111qqz.com/2018/02/pytorch-function-notes/</link><pubDate>Fri, 23 Feb 2018 02:55:25 +0000</pubDate><guid>https://111qqz.com/2018/02/pytorch-function-notes/</guid><description>
记录一些常用的...总去查文档也是有点麻烦
* tensor.view 的作用是reshape 比如 a = torch.range(1, 16) 得到一个tensor that has 16 elements from 1 to 16. 在a=a.view(4,4)就得到了一个44的tensor。 需要注意reshape之后元素的个数不能改变(16==44) 参数-1的作用是，我懒得算这一维度应该是多少,（由于元素个数不能改变）所以希望自动被计算。**需要注意的是，只有一个维度可以写-1。 **不过view和reshape有些区别：reshape always copies memory. view never copies memory * torch.squeeze 将输入张量形状中的1 去除并返回。 如果输入是形如(A×1×B×1×C×1×D)，那么输出形状就为： (A×B×C×D)当给定dim时，那么挤压操作只在给定维度上。例如，输入形状为: (A×1×B), squeeze(input, 0) 将会保持张量不变，只有用 squeeze(input, 1)，形状会变成 (A×B)。注意： 返回张量与输入张量共享内存，所以改变其中一个的内容会改变另一个。 * torch.unsqueeze 返回一个新的张量，对输入的制定位置插入维度 1 注意： 返回张量与输入张量共享内存，所以改变其中一个的内容会改变另一个。如果dim为负，则将会被转化dim+input.dim()+1 &amp;gt;&amp;gt;&amp;gt; x = torch.Tensor([1, 2, 3, 4]) &amp;gt;&amp;gt;&amp;gt; torch.unsqueeze(x, 0) 1 2 3 4 [torch.FloatTensor of size 1x4] &amp;gt;&amp;gt;&amp;gt; torch.</description></item></channel></rss>
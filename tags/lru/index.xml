<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>LRU on 111qqz的小窝</title><link>https://111qqz.com/tags/lru/</link><description>Recent content in LRU on 111qqz的小窝</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><copyright>Copyright © 2012-2022 all rights reserved.</copyright><lastBuildDate>Fri, 18 Aug 2017 19:18:25 +0000</lastBuildDate><atom:link href="https://111qqz.com/tags/lru/index.xml" rel="self" type="application/rss+xml"/><item><title>leetcode 146. LRU Cache(list+unordered_map)</title><link>https://111qqz.com/2017/08/leetcode-146-lru-cache/</link><pubDate>Fri, 18 Aug 2017 19:18:25 +0000</pubDate><guid>https://111qqz.com/2017/08/leetcode-146-lru-cache/</guid><description>
请实现最近最少使用缓存(Least Recently Used (LRU) cache)类,需要支持 get, set,操作。 get 操作,给出 key,获取到相应的 value (value 为非负数),如果不存在返回-1, 如果存在此 key 算作被访问过。 set 操作,设置 key,如果 key 存在则覆盖之前的 value (此时相当于访问过一次)。 如果 key 不存在,需要进行插入操作,如果此时已经 key 的数量已经到达 capacity, 这样需要淘汰掉最近最少使用(也就是上次被使用的时间距离现在最久的)的那 一项。
要求get和set的时间复杂度都是O(1)
/* *********************************************** Author :111qqz Created Time :2017年08月18日 星期五 00时00分22秒 File Name :LRU.cpp ************************************************ */ class LRUCache{ private: //map:&amp;lt;key,Value&amp;gt; //Value:pair&amp;lt;value,time&amp;gt; //time:vector? list? typedef unordered_map&amp;lt;int, pair&amp;lt;int , list&amp;lt;int&amp;gt;::iterator &amp;gt; &amp;gt;Cache; Cache cache; list&amp;lt;int&amp;gt;hit_seq; //头部最新元素，尾部最旧元素 int siz; #define fst first #define sec second #define MP make_pair void hit(Cache::iterator it) //access once { int key = it-&amp;gt;fst; hit_seq.</description></item><item><title>缓存淘汰算法之LRU（转载）</title><link>https://111qqz.com/2017/03/lru/</link><pubDate>Wed, 15 Mar 2017 00:34:50 +0000</pubDate><guid>https://111qqz.com/2017/03/lru/</guid><description>
参考博客
计组块忘光了呜呜呜。。。来复习一波。。
1. LRU 1.1. 原理
LRU（Least recently used，最近最少使用）算法根据数据的历史访问记录来进行淘汰数据，其核心思想是“如果数据最近被访问过，那么将来被访问的几率也更高”。
1.2. 实现 最常见的实现是使用一个链表保存缓存数据，详细算法实现如下：
Image not found a.warning-link { color: inherit !important; font-weight: inherit !important; text-decoration: underline !important; border-bottom: none !important; } 网站链接: /2017/03/lru/http://my.csdn.net/uploads/201205/24/1337859321_3597.png
链接到文件: /content/post/ACM-ICPC/http://my.csdn.net/uploads/201205/24/1337859321_3597.png
使用 Page Bundles: true
1. 新数据插入到链表头部；
2. 每当缓存命中（即缓存数据被访问），则将数据移到链表头部；
3. 当链表满的时候，将链表尾部的数据丢弃。
1.3. 分析 【命中率】
当存在热点数据时，LRU的效率很好，但偶发性的、周期性的批量操作会导致LRU命中率急剧下降，缓存污染情况比较严重。
【复杂度】
实现简单。
【代价】
命中时需要遍历链表，找到命中的数据块索引，然后需要将数据移到头部。
2. LRU-K 2.1. 原理 LRU-K中的K代表最近使用的次数，因此LRU可以认为是LRU-1。LRU-K的主要目的是为了解决LRU算法“缓存污染”的问题，其核心思想是将“最近使用过1次”的判断标准扩展为“最近使用过K次”。
2.2. 实现 相比LRU，LRU-K需要多维护一个队列，用于记录所有缓存数据被访问的历史。只有当数据的访问次数达到K次的时候，才将数据放入缓存。当需要淘汰数据时，LRU-K会淘汰第K次访问时间距当前时间最大的数据。详细实现如下：
Image not found a.warning-link { color: inherit !</description></item></channel></rss>
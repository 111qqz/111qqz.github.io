<!doctype html><html lang=zh-cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta property="og:site_name" content="111qqz的小窝"><meta property="og:type" content="article"><meta property="og:image" content="https://111qqz.github.io/img/2.png"><meta property="twitter:image" content="https://111qqz.github.io/img/2.png"><meta name=title content="缓存淘汰算法之LRU（转载）"><meta property="og:title" content="缓存淘汰算法之LRU（转载）"><meta property="twitter:title" content="缓存淘汰算法之LRU（转载）"><meta name=description content><meta property="og:description" content><meta property="twitter:description" content><meta property="twitter:card" content="summary"><meta name=keyword content="ACM,111qqz,商汤科技,hust,华中科技大学"><link rel="shortcut icon" href=/img/favicon.ico><title>缓存淘汰算法之LRU（转载）-111qqz的小窝</title><link rel=canonical href=/2017/03/lru/><link rel=stylesheet href=/css/iDisqus.min.css><link rel=stylesheet href=/css/bootstrap.min.css><link rel=stylesheet href=/css/hux-blog.min.css><link rel=stylesheet href=/css/syntax.css><link rel=stylesheet href=/css/zanshang.css><link href=//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css rel=stylesheet type=text/css><script src=/js/jquery.min.js></script><script src=/js/bootstrap.min.js></script><script src=/js/hux-blog.min.js></script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/styles/docco.min.css><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/highlight.min.js></script><script>hljs.initHighlightingOnLoad();</script><link rel=stylesheet href=/css/hux-blog.min.css><link rel=stylesheet href=/css/hux-blog.min-custom.css></head><nav class="navbar navbar-default navbar-custom navbar-fixed-top"><div class=container-fluid><div class="navbar-header page-scroll"><button type=button class=navbar-toggle>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span><span class=icon-bar></span><span class=icon-bar></span></button>
<a class=navbar-brand href=/>111qqz的小窝</a></div><div id=huxblog_navbar><div class=navbar-collapse><ul class="nav navbar-nav navbar-right"><li><a href=/>Home</a></li><li><a href=/categories/acm/>ACM-ICPC</a></li><li><a href=/categories/deep-learning/>深度学习</a></li><li><a href=/categories/mooc/>公开课</a></li><li><a href=/categories/%e5%85%b6%e4%bb%96/>其他</a></li><li><a href=/top/about/>ABOUT</a></li><li><a href=/search>SEARCH <img src=/img/search.png height=15 style=cursor:pointer alt=Search></a></li></ul></div></div></div></nav><script>var $body=document.body;var $toggle=document.querySelector('.navbar-toggle');var $navbar=document.querySelector('#huxblog_navbar');var $collapse=document.querySelector('.navbar-collapse');$toggle.addEventListener('click',handleMagic)
function handleMagic(e){if($navbar.className.indexOf('in')>0){$navbar.className=" ";setTimeout(function(){if($navbar.className.indexOf('in')<0){$collapse.style.height="0px"}},400)}else{$collapse.style.height="auto"
$navbar.className+=" in";}}</script><style type=text/css>header.intro-header{background-image:url(/img/2.png)}</style><header class=intro-header><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class=post-heading><div class=tags><a class=tag href=/tags/cache title=cache>cache</a>
<a class=tag href=/tags/lru title=LRU>LRU</a>
<a class=tag href=/tags/%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86 title=组成原理>组成原理</a></div><h1>缓存淘汰算法之LRU（转载）</h1><h2 class=subheading></h2><span class=meta>Posted by
111qqz
on
Wednesday, March 15, 2017
<span id=/2017/03/lru/ class="leancloud_visitors meta_data_item" data-flag-title><span class=post-meta-item-icon><span class="octicon octicon-eye"></span></span><i class="fa fa-eye"></i><span class=old-visitors-count style=display:none></span><span class=leancloud-visitors-count></span></span><script src=https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js></script><script>AV.initialize("UzhnsgbPvx1RFb2kNXUHpPtf-gzGzoHsz","OXOvoYGuwMv70Os5GOgaGEWT");</script><script type=text/javascript>function showTime(Counter){var query=new AV.Query(Counter);var entries=[];var $visitors=$(".leancloud_visitors");$visitors.each(function(){entries.push($(this).attr("id").trim());});query.containedIn('url',entries);query.find().done(function(results){var COUNT_CONTAINER_REF='.leancloud-visitors-count';var OLD_COUNT_CONTAINER_REF='.old-visitors-count';for(var i=0;i<results.length;i++){var item=results[i];var url=item.get('url');var time=item.get('time');var element=document.getElementById(url);$(element).find(COUNT_CONTAINER_REF).text(time);}
for(var i=0;i<entries.length;i++){var url=entries[i];var element=document.getElementById(url);var countSpan=$(element).find(COUNT_CONTAINER_REF);if(countSpan.text()==''){var oldCountSpan=$(element).find(OLD_COUNT_CONTAINER_REF).text();if(oldCountSpan!=''){countSpan.text(0+parseInt(oldCountSpan));}else{countSpan.text(0);}}}}).fail(function(object,error){console.log("Error: "+error.code+" "+error.message);});}
function addCount(Counter){var $visitors=$(".leancloud_visitors");var url=$visitors.attr('id').trim();var title=$visitors.attr('data-flag-title').trim();var query=new AV.Query(Counter);query.equalTo("url",url);query.find({success:function(results){if(results.length>0){var counter=results[0];counter.fetchWhenSave(true);counter.increment("time");counter.save(null,{success:function(counter){var $element=$(document.getElementById(url));$element.find('.leancloud-visitors-count').text(counter.get('time'));},error:function(counter,error){console.log('Failed to save Visitor num, with error message: '+error.message);}});}else{var newcounter=new Counter();var acl=new AV.ACL();acl.setPublicReadAccess(true);acl.setPublicWriteAccess(true);newcounter.setACL(acl);newcounter.set("title",title);newcounter.set("url",url);var OLD_COUNT_CONTAINER_REF='.old-visitors-count';var $element=$(document.getElementById(url));var oldCountSpan=$element.find(OLD_COUNT_CONTAINER_REF).text();if(oldCountSpan!=''){newcounter.set("time",parseInt(oldCountSpan)+1);}else{newcounter.set("time",1);}
newcounter.save(null,{success:function(newcounter){var $element=$(document.getElementById(url));$element.find('.leancloud-visitors-count').text(newcounter.get('time'));},error:function(newcounter,error){console.log('Failed to create');}});}},error:function(error){console.log('Error:'+error.code+" "+error.message);}});}
$(function(){var Counter=AV.Object.extend("Counter");if($('.leancloud_visitors').length==1){addCount(Counter);}else{showTime(Counter);}});</script></span></div></div></div></div></header><article><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2
col-md-10 col-md-offset-1
post-container"><header><h2>TOC</h2></header><nav id=TableOfContents><ol><li><ol><li></li></ol></li></ol></nav><p><a href=http://www.cnblogs.com/-OYK/archive/2012/12/05/2803317.html>参考博客</a></p><p>计组块忘光了呜呜呜。。。来复习一波。。</p><h4 id=1lru>1. LRU</h4><p>1.1. 原理</p><p>LRU（Least recently used，最近最少使用）算法根据数据的历史访问记录来进行淘汰数据，其核心思想是“如果数据最近被访问过，那么将来被访问的几率也更高”。</p><h5 id=12实现>1.2. 实现</h5><p>最常见的实现是使用一个链表保存缓存数据，详细算法实现如下：</p><p><img src=http://my.csdn.net/uploads/201205/24/1337859321_3597.png alt></p><p>1. 新数据插入到链表头部；</p><p>2. 每当缓存命中（即缓存数据被访问），则将数据移到链表头部；</p><p>3. 当链表满的时候，将链表尾部的数据丢弃。</p><h5 id=13分析>1.3. 分析</h5><p>【命中率】</p><p>当存在热点数据时，LRU的效率很好，但偶发性的、周期性的批量操作会导致LRU命中率急剧下降，缓存污染情况比较严重。</p><p>【复杂度】</p><p>实现简单。</p><p>【代价】</p><p>命中时需要遍历链表，找到命中的数据块索引，然后需要将数据移到头部。</p><h4 id=2lru-k>2. LRU-K</h4><h5 id=21原理>2.1. 原理</h5><p>LRU-K中的K代表最近使用的次数，因此LRU可以认为是LRU-1。LRU-K的主要目的是为了解决LRU算法“缓存污染”的问题，其核心思想是将“最近使用过1次”的判断标准扩展为“最近使用过K次”。</p><h5 id=22实现>2.2. 实现</h5><p>相比LRU，LRU-K需要多维护一个队列，用于记录所有缓存数据被访问的历史。只有当数据的访问次数达到K次的时候，才将数据放入缓存。当需要淘汰数据时，LRU-K会淘汰第K次访问时间距当前时间最大的数据。详细实现如下：</p><p><img src=http://my.csdn.net/uploads/201205/24/1337859332_7838.png alt></p><p>1. 数据第一次被访问，加入到访问历史列表；</p><p>2. 如果数据在访问历史列表里后没有达到K次访问，则按照一定规则（FIFO，LRU）淘汰；</p><p>3. 当访问历史队列中的数据访问次数达到K次后，将数据索引从历史队列删除，将数据移到缓存队列中，并缓存此数据，缓存队列重新按照时间排序；</p><p>4. 缓存数据队列中被再次访问后，重新排序；</p><p>5. 需要淘汰数据时，淘汰缓存队列中排在末尾的数据，即：淘汰“倒数第K次访问离现在最久”的数据。</p><p>LRU-K具有LRU的优点，同时能够避免LRU的缺点，实际应用中LRU-2是综合各种因素后最优的选择，LRU-3或者更大的K值命中率会高，但适应性差，需要大量的数据访问才能将历史访问记录清除掉。</p><h5 id=23分析>2.3. 分析</h5><p>【命中率】</p><p>LRU-K降低了“缓存污染”带来的问题，命中率比LRU要高。</p><p>【复杂度】</p><p>LRU-K队列是一个优先级队列，算法复杂度和代价比较高。</p><p>【代价】</p><p>由于LRU-K还需要记录那些被访问过、但还没有放入缓存的对象，因此内存消耗会比LRU要多；当数据量很大的时候，内存消耗会比较可观。</p><p>LRU-K需要基于时间进行排序（可以需要淘汰时再排序，也可以即时排序），CPU消耗比LRU要高。</p><h4 id=3twoqueues2q>3. Two queues（2Q）</h4><h5 id=31原理>3.1. 原理</h5><p>Two queues（以下使用2Q代替）算法类似于LRU-2，不同点在于2Q将LRU-2算法中的访问历史队列（注意这不是缓存数据的）改为一个FIFO缓存队列，即：2Q算法有两个缓存队列，一个是FIFO队列，一个是LRU队列。</p><h5 id=32实现>3.2. 实现</h5><p>当数据第一次访问时，2Q算法将数据缓存在FIFO队列里面，当数据第二次被访问时，则将数据从FIFO队列移到LRU队列里面，两个队列各自按照自己的方法淘汰数据。详细实现如下：</p><p><img src=http://my.csdn.net/uploads/201205/24/1337859339_6844.png alt></p><p>1. 新访问的数据插入到FIFO队列；</p><p>2. 如果数据在FIFO队列中一直没有被再次访问，则最终按照FIFO规则淘汰；</p><p>3. 如果数据在FIFO队列中被再次访问，则将数据移到LRU队列头部；</p><p>4. 如果数据在LRU队列再次被访问，则将数据移到LRU队列头部；</p><p>5. LRU队列淘汰末尾的数据。</p><p>注：上图中FIFO队列比LRU队列短，但并不代表这是算法要求，实际应用中两者比例没有硬性规定。</p><h5 id=33分析>3.3. 分析</h5><p>【命中率】</p><p>2Q算法的命中率要高于LRU。</p><p>【复杂度】</p><p>需要两个队列，但两个队列本身都比较简单。</p><p>【代价】</p><p>FIFO和LRU的代价之和。</p><p>2Q算法和LRU-2算法命中率类似，内存消耗也比较接近，但对于最后缓存的数据来说，2Q会减少一次从原始存储读取数据或者计算数据的操作。</p><h4 id=4multiqueuemq>4. Multi Queue（MQ）</h4><h5 id=41原理>4.1. 原理</h5><p>MQ算法根据访问频率将数据划分为多个队列，不同的队列具有不同的访问优先级，其核心思想是：优先缓存访问次数多的数据。</p><h5 id=42实现>4.2. 实现</h5><p>MQ算法将缓存划分为多个LRU队列，每个队列对应不同的访问优先级。访问优先级是根据访问次数计算出来的，例如</p><p>详细的算法结构图如下，Q0，Q1&mldr;.Qk代表不同的优先级队列，Q-history代表从缓存中淘汰数据，但记录了数据的索引和引用次数的队列：</p><p><img src=http://my.csdn.net/uploads/201205/24/1337859354_3696.png alt></p><p>如上图，算法详细描述如下：</p><p>1. 新插入的数据放入Q0；</p><p>2. 每个队列按照LRU管理数据；</p><p>3. 当数据的访问次数达到一定次数，需要提升优先级时，将数据从当前队列删除，加入到高一级队列的头部；</p><p>4. 为了防止高优先级数据永远不被淘汰，当数据在指定的时间里访问没有被访问时，需要降低优先级，将数据从当前队列删除，加入到低一级的队列头部；</p><p>5. 需要淘汰数据时，从最低一级队列开始按照LRU淘汰；每个队列淘汰数据时，将数据从缓存中删除，将数据索引加入Q-history头部；</p><p>6. 如果数据在Q-history中被重新访问，则重新计算其优先级，移到目标队列的头部；</p><p>7. Q-history按照LRU淘汰数据的索引。</p><h5 id=43分析>4.3. 分析</h5><p>【命中率】</p><p>MQ降低了“缓存污染”带来的问题，命中率比LRU要高。</p><p>【复杂度】</p><p>MQ需要维护多个队列，且需要维护每个数据的访问时间，复杂度比LRU高。</p><p>【代价】</p><p>MQ需要记录每个数据的访问时间，需要定时扫描所有队列，代价比LRU要高。</p><p>注：虽然MQ的队列看起来数量比较多，但由于所有队列之和受限于缓存容量的大小，因此这里多个队列长度之和和一个LRU队列是一样的，因此队列扫描性能也相近。</p><h4 id=5lru类算法对比>5. LRU类算法对比</h4><p>由于不同的访问模型导致命中率变化较大，此处对比仅基于理论定性分析，不做定量分析。</p><table align=center><tbody><tr><td valign=center>对比点</td><td valign=center>对比</td></tr><tr><td valign=center>命中率</td><td valign=center>LRU-2 > MQ(2) > 2Q > LRU</td></tr><tr><td valign=center>复杂度</td><td valign=center>LRU-2 > MQ(2) > 2Q > LRU</td></tr><tr><td valign=center>代价</td><td valign=center>LRU-2  > MQ(2) > 2Q > LRU</td></tr></tbody></table>实际应用中需要根据业务的需求和对数据的访问情况进行选择，并不是命中率越高越好。例如：虽然LRU看起来命中率会低一些，且存在”缓存污染“的问题，但由于其简单和代价小，实际应用中反而应用更多。<p>java中最简单的LRU算法实现，就是利用jdk的LinkedHashMap，覆写其中的removeEldestEntry(Map.Entry)方法即可</p><p>如果你去看LinkedHashMap的源码可知，LRU算法是通过双向链表来实现，当某个位置被命中，通过调整链表的指向将该位置调整到头位置，新加入的内容直接放在链表头，如此一来，最近被命中的内容就向链表头移动，需要替换时，链表最后的位置就是最近最少使用的位置。</p><pre><code>import java.util.ArrayList; 
import java.util.Collection; 
import java.util.LinkedHashMap; 
import java.util.concurrent.locks.Lock; 
import java.util.concurrent.locks.ReentrantLock; 
import java.util.Map; 
   
   
/**
 * 类说明：利用LinkedHashMap实现简单的缓存， 必须实现removeEldestEntry方法，具体参见JDK文档
 * 
 * @author dennis
 * 
 * @param &lt;K&gt;
 * @param &lt;V&gt;
 */ 
public class LRULinkedHashMap&lt;K, V&gt; extends LinkedHashMap&lt;K, V&gt; { 
    private final int maxCapacity; 
   
    private static final float DEFAULT_LOAD_FACTOR = 0.75f; 
   
    private final Lock lock = new ReentrantLock(); 
   
    public LRULinkedHashMap(int maxCapacity) { 
        super(maxCapacity, DEFAULT_LOAD_FACTOR, true); 
        this.maxCapacity = maxCapacity; 
    } 
   
    @Override 
    protected boolean removeEldestEntry(java.util.Map.Entry&lt;K, V&gt; eldest) { 
        return size() &gt; maxCapacity; 
    } 
    @Override 
    public boolean containsKey(Object key) { 
        try { 
            lock.lock(); 
            return super.containsKey(key); 
        } finally { 
            lock.unlock(); 
        } 
    } 
   
       
    @Override 
    public V get(Object key) { 
        try { 
            lock.lock(); 
            return super.get(key); 
        } finally { 
            lock.unlock(); 
        } 
    } 
   
    @Override 
    public V put(K key, V value) { 
        try { 
            lock.lock(); 
            return super.put(key, value); 
        } finally { 
            lock.unlock(); 
        } 
    } 
   
    public int size() { 
        try { 
            lock.lock(); 
            return super.size(); 
        } finally { 
            lock.unlock(); 
        } 
    } 
   
    public void clear() { 
        try { 
            lock.lock(); 
            super.clear(); 
        } finally { 
            lock.unlock(); 
        } 
    } 
   
    public Collection&lt;Map.Entry&lt;K, V&gt;&gt; getAll() { 
        try { 
            lock.lock(); 
            return new ArrayList&lt;Map.Entry&lt;K, V&gt;&gt;(super.entrySet()); 
        } finally { 
            lock.unlock(); 
        } 
    } 
}
</code></pre><p>基于双链表 的LRU实现:</p><p>传统意义的LRU算法是为每一个Cache对象设置一个计数器，每次Cache命中则给计数器+1，而Cache用完，需要淘汰旧内容，放置新内容时，就查看所有的计数器，并将最少使用的内容替换掉。</p><p>它的弊端很明显，如果Cache的数量少，问题不会很大， 但是如果Cache的空间过大，达到10W或者100W以上，一旦需要淘汰，则需要遍历所有计算器，其性能与资源消耗是巨大的。效率也就非常的慢了。</p><p>它的原理： 将Cache的所有位置都用双连表连接起来，当一个位置被命中之后，就将通过调整链表的指向，将该位置调整到链表头的位置，新加入的Cache直接加到链表头中。</p><p>这样，在多次进行Cache操作后，最近被命中的，就会被向链表头方向移动，而没有命中的，而想链表后面移动，链表尾则表示最近最少使用的Cache。</p><p>当需要替换内容时候，链表的最后位置就是最少被命中的位置，我们只需要淘汰链表最后的部分即可。</p><p>上面说了这么多的理论， 下面用代码来实现一个LRU策略的缓存。</p><p>我们用一个对象来表示Cache，并实现双链表，</p><pre><code>public class LRUCache {
    /**
     * 链表节点
     * @author Administrator
     *
     */
    class CacheNode {
        ……
    }
    private int cacheSize;//缓存大小
    private Hashtable nodes;//缓存容器
    private int currentSize;//当前缓存对象数量
    private CacheNode first;//(实现双链表)链表头
    private CacheNode last;//(实现双链表)链表尾
}
                  
 下面给出完整的实现，这个类也被Tomcat所使用（ org.apache.tomcat.util.collections.LRUCache），但是在tomcat6.x版本中，已经被弃用，使用另外其他的缓存类来替代它。

public class LRUCache {
    /**
     * 链表节点
     * @author Administrator
     *
     */
    class CacheNode {
        CacheNode prev;//前一节点
        CacheNode next;//后一节点
        Object value;//值
        Object key;//键
        CacheNode() {
        }
    }
    public LRUCache(int i) {
        currentSize = 0;
        cacheSize = i;
        nodes = new Hashtable(i);//缓存容器
    }
	
    /**
     * 获取缓存中对象
     * @param key
     * @return
     */
    public Object get(Object key) {
        CacheNode node = (CacheNode) nodes.get(key);
        if (node != null) {
            moveToHead(node);
            return node.value;
        } else {
            return null;
        }
    }
	
    /**
     * 添加缓存
     * @param key
     * @param value
     */
    public void put(Object key, Object value) {
        CacheNode node = (CacheNode) nodes.get(key);
		
        if (node == null) {
            //缓存容器是否已经超过大小.
            if (currentSize &gt;= cacheSize) {
                if (last != null)//将最少使用的删除
                    nodes.remove(last.key);
                removeLast();
            } else {
                currentSize++;
            }
			
            node = new CacheNode();
        }
        node.value = value;
        node.key = key;
        //将最新使用的节点放到链表头，表示最新使用的.
        moveToHead(node);
        nodes.put(key, node);
    }
    /**
     * 将缓存删除
     * @param key
     * @return
     */
    public Object remove(Object key) {
        CacheNode node = (CacheNode) nodes.get(key);
        if (node != null) {
            if (node.prev != null) {
                node.prev.next = node.next;
            }
            if (node.next != null) {
                node.next.prev = node.prev;
            }
            if (last == node)
                last = node.prev;
            if (first == node)
                first = node.next;
        }
        return node;
    }
    public void clear() {
        first = null;
        last = null;
    }
    /**
     * 删除链表尾部节点
     *  表示 删除最少使用的缓存对象
     */
    private void removeLast() {
        //链表尾不为空,则将链表尾指向null. 删除连表尾（删除最少使用的缓存对象）
        if (last != null) {
            if (last.prev != null)
                last.prev.next = null;
            else
                first = null;
            last = last.prev;
        }
    }
	
    /**
     * 移动到链表头，表示这个节点是最新使用过的
     * @param node
     */
    private void moveToHead(CacheNode node) {
        if (node == first)
            return;
        if (node.prev != null)
            node.prev.next = node.next;
        if (node.next != null)
            node.next.prev = node.prev;
        if (last == node)
            last = node.prev;
        if (first != null) {
            node.next = first;
            first.prev = node;
        }
        first = node;
        node.prev = null;
        if (last == null)
            last = first;
    }
    private int cacheSize;
    private Hashtable nodes;//缓存容器
    private int currentSize;
    private CacheNode first;//链表头
    private CacheNode last;//链表尾
}
</code></pre><hr><ul class=pager><li class=previous><a href=/2017/03// data-toggle=tooltip data-placement=top title=阿里面试算法题（转载）>&larr;
Previous Post</a></li><li class=next><a href=/2017/03// data-toggle=tooltip data-placement=top title=压缩算法初探（科普向，转载）>Next
Post &rarr;</a></li></ul><div class=post-comment><span id=/2017/03/lru/ class=leancloud_visitors data-flag-title=缓存淘汰算法之LRU（转载）><span class=post-meta-item-text>访问量</span>
<span class=leancloud-visitors-count></span><p></p></span><div id=vcomments></div><script src=//cdn1.lncld.net/static/js/3.0.4/av-min.js></script><script src=//unpkg.com/valine/dist/Valine.min.js></script><script type=text/javascript>new Valine({el:'#vcomments',appId:'UzhnsgbPvx1RFb2kNXUHpPtf-gzGzoHsz',appKey:'OXOvoYGuwMv70Os5GOgaGEWT',notify:true,verify:false,avatar:'retro',placeholder:'说点什么吧...',visitor:true});</script></div></div><div class="col-lg-8 col-lg-offset-2
col-md-10 col-md-offset-1
sidebar-container"><section><hr class="hidden-sm hidden-xs"><h5><a href=/tags/>FEATURED TAGS</a></h5><div class=tags><a href=/tags/bfs title=bfs>bfs</a>
<a href=/tags/binary-search title=binary-search>binary-search</a>
<a href=/tags/brute-force title=brute-force>brute-force</a>
<a href=/tags/dfs title=dfs>dfs</a>
<a href=/tags/dp title=dp>dp</a>
<a href=/tags/greedy title=greedy>greedy</a>
<a href=/tags/kmp title=kmp>kmp</a>
<a href=/tags/leetcode title=leetcode>leetcode</a>
<a href=/tags/math title=math>math</a>
<a href=/tags/number-theory title=number-theory>number-theory</a>
<a href=/tags/rmq title=rmq>rmq</a>
<a href=/tags/stl title=stl>stl</a>
<a href=/tags/%E5%89%8D%E7%BC%80%E5%92%8C title=前缀和>前缀和</a>
<a href=/tags/%E5%8D%9A%E5%BC%88%E8%AE%BA title=博弈论>博弈论</a>
<a href=/tags/%E5%9B%BE%E8%AE%BA title=图论>图论</a>
<a href=/tags/%E5%BF%AB%E9%80%9F%E5%B9%82 title=快速幂>快速幂</a>
<a href=/tags/%E6%95%B0%E4%BD%8Ddp title=数位dp>数位dp</a>
<a href=/tags/%E6%9E%84%E9%80%A0 title=构造>构造</a>
<a href=/tags/%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84 title=树状数组>树状数组</a>
<a href=/tags/%E6%A8%A1%E6%8B%9F title=模拟>模拟</a>
<a href=/tags/%E6%AF%8D%E5%87%BD%E6%95%B0 title=母函数>母函数</a>
<a href=/tags/%E7%9F%A9%E9%98%B5 title=矩阵>矩阵</a>
<a href=/tags/%E7%BA%BF%E6%AE%B5%E6%A0%91 title=线段树>线段树</a>
<a href=/tags/%E8%AE%A1%E7%AE%97%E5%87%A0%E4%BD%95 title=计算几何>计算几何</a></div></section><section><hr><h5>FRIENDS</h5><ul class=list-inline><li><a target=_blank href=https://111qqz.com>111qqz的wordpress博客</a></li></ul></section></div></div></div></article><footer><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><ul class="list-inline text-center"><li><a href rel=alternate type=application/rss+xml title=111qqz的小窝><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-rss fa-stack-1x fa-inverse"></i></span></a></li><li><a href=mailto:hust.111qqz@gmail.com><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-envelope fa-stack-1x fa-inverse"></i></span></a></li><li><a target=_blank href=/img/wechat.jpg><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-wechat fa-stack-1x fa-inverse"></i></span></a></li><li><a target=_blank href=https://github.com/111qqz/><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-github fa-stack-1x fa-inverse"></i></span></a></li></ul><p class="copyright text-muted">Copyright &copy; 111qqz的小窝 2022<br><a href=https://beian.miit.gov.cn/>粤ICP备18103363号</a><br><a href=https://themes.gohugo.io/hugo-theme-cleanwhite>CleanWhite Hugo Theme</a> by <a href=https://zhaohuabing.com>Huabing</a> |
<iframe style=margin-left:2px;margin-bottom:-5px frameborder=0 scrolling=0 width=100px height=20px src="https://ghbtns.com/github-btn.html?user=zhaohuabing&repo=hugo-theme-cleanwhite&type=star&count=true"></iframe></p></div></div></div></footer><script>function async(u,c){var d=document,t='script',o=d.createElement(t),s=d.getElementsByTagName(t)[0];o.src=u;if(c){o.addEventListener('load',function(e){c(null,e);},false);}
s.parentNode.insertBefore(o,s);}</script><script>if($('#tag_cloud').length!==0){async("/js/jquery.tagcloud.js",function(){$.fn.tagcloud.defaults={color:{start:'#bbbbee',end:'#0085a1'},};$('#tag_cloud a').tagcloud();})}</script><script>async("https://cdnjs.cloudflare.com/ajax/libs/fastclick/1.0.6/fastclick.js",function(){var $nav=document.querySelector("nav");if($nav)FastClick.attach($nav);})</script></body></html>
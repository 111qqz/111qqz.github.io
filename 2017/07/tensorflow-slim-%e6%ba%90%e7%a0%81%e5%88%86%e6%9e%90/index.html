<!DOCTYPE html>
<html lang="zh-cn">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    
    <meta property="og:site_name" content="111qqz的小窝">
    <meta property="og:type" content="article">

    
    <meta property="og:image" content="https://111qqz.github.io/img/cat.jpg">
    <meta property="twitter:image" content="https://111qqz.github.io/img/cat.jpg" />
    

    
    <meta name="title" content="tensorflow slim 源码分析" />
    <meta property="og:title" content="tensorflow slim 源码分析" />
    <meta property="twitter:title" content="tensorflow slim 源码分析" />
    

    
    <meta name="description" content="">
    <meta property="og:description" content="" />
    <meta property="twitter:description" content="" />
    

    
    <meta property="twitter:card" content="summary" />
    
    

    <meta name="keyword"  content="ACM,111qqz,商汤科技,hust,华中科技大学">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>tensorflow slim 源码分析-111qqz的小窝</title>

    <link rel="canonical" href="/2017/07/tensorflow-slim-%e6%ba%90%e7%a0%81%e5%88%86%e6%9e%90/">

    <link rel="stylesheet" href="/css/iDisqus.min.css"/>
	
    
    <link rel="stylesheet" href="/css/bootstrap.min.css">

    
    <link rel="stylesheet" href="/css/hux-blog.min.css">

    
    <link rel="stylesheet" href="/css/syntax.css">

    
    <link rel="stylesheet" href="/css/zanshang.css">

    
    <link href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    
    
    <script src="/js/jquery.min.js"></script>
    
    
    <script src="/js/bootstrap.min.js"></script>
    
    
    <script src="/js/hux-blog.min.js"></script>
	
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/styles/docco.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
</head>


<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">111qqz的小窝</a>
        </div>

        
        
        <div id="huxblog_navbar">
            <div class="navbar-collapse">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="/">Home</a>
                    </li>
                    
                    <li>
                        <a href="/categories/acm">acm</a>
                    </li>
                    
                    <li>
                        <a href="/categories/blog">blog</a>
                    </li>
                    
                    <li>
                        <a href="/categories/bzoj">bzoj</a>
                    </li>
                    
                    <li>
                        <a href="/categories/c&#43;&#43;">c&#43;&#43;</a>
                    </li>
                    
                    <li>
                        <a href="/categories/class">class</a>
                    </li>
                    
                    <li>
                        <a href="/categories/codeforces">codeforces</a>
                    </li>
                    
                    <li>
                        <a href="/categories/computer-vision">computer-vision</a>
                    </li>
                    
                    <li>
                        <a href="/categories/deep-learning">deep-learning</a>
                    </li>
                    
                    <li>
                        <a href="/categories/hdoj">hdoj</a>
                    </li>
                    
                    <li>
                        <a href="/categories/hihocoder">hihocoder</a>
                    </li>
                    
                    <li>
                        <a href="/categories/hust-training">hust-training</a>
                    </li>
                    
                    <li>
                        <a href="/categories/leetcode">leetcode</a>
                    </li>
                    
                    <li>
                        <a href="/categories/linux">linux</a>
                    </li>
                    
                    <li>
                        <a href="/categories/os">os</a>
                    </li>
                    
                    <li>
                        <a href="/categories/poj">poj</a>
                    </li>
                    
                    <li>
                        <a href="/categories/sgu">sgu</a>
                    </li>
                    
                    <li>
                        <a href="/categories/tech">tech</a>
                    </li>
                    
                    <li>
                        <a href="/categories/tips">tips</a>
                    </li>
                    
                    <li>
                        <a href="/categories/ural">ural</a>
                    </li>
                    
                    <li>
                        <a href="/categories/uva">uva</a>
                    </li>
                    
                    <li>
                        <a href="/categories/zoj">zoj</a>
                    </li>
                    
                    <li>
                        <a href="/categories/%E4%BC%98%E5%8C%96">优化</a>
                    </li>
                    
                    <li>
                        <a href="/categories/%E5%85%AC%E5%BC%80%E8%AF%BE">公开课</a>
                    </li>
                    
                    <li>
                        <a href="/categories/%E5%85%B6%E4%BB%96">其他</a>
                    </li>
                    
                    <li>
                        <a href="/categories/%E5%85%B6%E4%BB%96oj">其他oj</a>
                    </li>
                    
                    <li>
                        <a href="/categories/%E5%89%8D%E7%AB%AF">前端</a>
                    </li>
                    
                    <li>
                        <a href="/categories/%E5%8D%96%E8%90%8C%E6%89%93%E6%BB%9A%E6%B1%82offer">卖萌打滚求offer</a>
                    </li>
                    
                    <li>
                        <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE">大数据</a>
                    </li>
                    
                    <li>
                        <a href="/categories/%E5%A5%87%E6%8A%80%E6%B7%AB%E5%B7%A7">奇技淫巧</a>
                    </li>
                    
                    <li>
                        <a href="/categories/%E6%8A%80%E6%9C%AF%E7%A7%91%E6%99%AE">技术科普</a>
                    </li>
                    
                    <li>
                        <a href="/categories/%E6%9C%AA%E5%88%86%E7%B1%BB">未分类</a>
                    </li>
                    
                    <li>
                        <a href="/categories/%E6%A8%A1%E6%8B%9F%E8%B5%9B">模拟赛</a>
                    </li>
                    
                    <li>
                        <a href="/categories/%E6%A8%A1%E6%9D%BF%E9%A2%98">模板题</a>
                    </li>
                    
                    <li>
                        <a href="/categories/%E7%99%BD%E4%B9%A6">白书</a>
                    </li>
                    
                    <li>
                        <a href="/categories/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0">算法学习</a>
                    </li>
                    
                    <li>
                        <a href="/categories/%E9%9A%8F%E7%AC%94%E6%9D%82%E8%B0%88">随笔杂谈</a>
                    </li>
                    
                    
		    
                        <li><a href="/top/about/">ABOUT</a></li>
                    

                    
		    <li>
                        <a href="/search">SEARCH <img src="/img/search.png" height="15" style="cursor: pointer;" alt="Search"></a>
		    </li>
                    
                </ul>
            </div>
        </div>
        
    </div>
    
</nav>
<script>
    
    
    
    var $body   = document.body;
    var $toggle = document.querySelector('.navbar-toggle');
    var $navbar = document.querySelector('#huxblog_navbar');
    var $collapse = document.querySelector('.navbar-collapse');

    $toggle.addEventListener('click', handleMagic)
    function handleMagic(e){
        if ($navbar.className.indexOf('in') > 0) {
        
            $navbar.className = " ";
            
            setTimeout(function(){
                
                if($navbar.className.indexOf('in') < 0) {
                    $collapse.style.height = "0px"
                }
            },400)
        }else{
        
            $collapse.style.height = "auto"
            $navbar.className += " in";
        }
    }
</script>




<style type="text/css">
    header.intro-header {
        background-image: url('/img/cat.jpg')
    }
</style>
<header class="intro-header">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="post-heading">
                    <div class="tags">
                        
                        <a class="tag" href="/tags/tensorflow" title="tensorflow">
                            tensorflow
                        </a>
                        
                    </div>
                    <h1>tensorflow slim 源码分析</h1>
                    <h2 class="subheading"></h2>
                    <span class="meta">
			Posted by 
			
			    111qqz
			 
			on 
			Sunday, July 16, 2017
                        
                    </span>
                </div>
            </div>
        </div>
    </div>
</header>




<article>
    <div class="container">
        <div class="row">

            
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                post-container">

                
                <header>
                    <h2>TOC</h2>
                </header>
                
                
                <p>py的源码看起来还是很愉快的。。。（虽然熟练成程度完全不如cpp。。。。</p>

<!-- more -->

<p><a href="https://111qqz.com/wordpress/wp-content/uploads/2017/07/Selection_004.png"><img src="https://111qqz.com/wordpress/wp-content/uploads/2017/07/Selection_004.png" alt="" />
</a></p>

<p>datasets里是数据集相关</p>

<p>deployment是部署相关</p>

<p>nets里给了很多网络结构</p>

<p>preprocessing给了几种预处理的方式</p>

<p>这些都和slim没有太大关系，就不多废话了。</p>

<p>分析的部分见代码注释&hellip;</p>

<p>由于刚刚入门machine learning 一周&hellip;还有很多内容还没有从理论层面接触&hellip;所以源码的理解也十分有限&hellip;希望能以后有机会补充一波</p>

<pre><code># Copyright 2016 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
r&quot;&quot;&quot;Downloads and converts a particular dataset.

Usage:
```shell

$ python download_and_convert_data.py \
    --dataset_name=mnist \
    --dataset_dir=/tmp/mnist

$ python download_and_convert_data.py \
    --dataset_name=cifar10 \
    --dataset_dir=/tmp/cifar10

$ python download_and_convert_data.py \
    --dataset_name=flowers \
    --dataset_dir=/tmp/flowers
```
&quot;&quot;&quot;
from __future__ import absolute_import    #from __future__是为了解决python版本升级导致的兼容问题，没必要纠结
from __future__ import division
from __future__ import print_function

import tensorflow as tf

from datasets import download_and_convert_cifar10
from datasets import download_and_convert_flowers
from datasets import download_and_convert_mnist

FLAGS = tf.app.flags.FLAGS    #FLAGS 用来传递或者设置tensforflow的参数

tf.app.flags.DEFINE_string(   #设置的格式为：('参数名称',参数值,'参数的解释'）
    'dataset_name',
    None,
    'The name of the dataset to convert, one of &quot;cifar10&quot;, &quot;flowers&quot;, &quot;mnist&quot;.')

tf.app.flags.DEFINE_string(
    'dataset_dir',
    None,
    'The directory where the output TFRecords and temporary files are saved.')


def main(_):
  if not FLAGS.dataset_name:
    raise ValueError('You must supply the dataset name with --dataset_name')
  if not FLAGS.dataset_dir:
    raise ValueError('You must supply the dataset directory with --dataset_dir')

  if FLAGS.dataset_name == 'cifar10':                #提供的三个数据集,[cifar10],[flowers],[mnist]
    download_and_convert_cifar10.run(FLAGS.dataset_dir)
  elif FLAGS.dataset_name == 'flowers':
    download_and_convert_flowers.run(FLAGS.dataset_dir)
  elif FLAGS.dataset_name == 'mnist':
    download_and_convert_mnist.run(FLAGS.dataset_dir)
  else:
    raise ValueError(
        'dataset_name [%s] was not recognized.' % FLAGS.dataset_name)  #数据经名字不属于上述三个

if __name__ == '__main__':  #这种写法可以保证在该文件被import的时候不会执行main函数
  tf.app.run()




# coding=utf-8
# Copyright 2016 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
&quot;&quot;&quot;Generic evaluation script that evaluates a model using a given dataset.&quot;&quot;&quot;

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import math
import tensorflow as tf

from datasets import dataset_factory
from nets import nets_factory
from preprocessing import preprocessing_factory

slim = tf.contrib.slim

tf.app.flags.DEFINE_integer(
    'batch_size', 100, 'The number of samples in each batch.')

tf.app.flags.DEFINE_integer(
    'max_num_batches', None,
    'Max number of batches to evaluate by default use all.')

tf.app.flags.DEFINE_string(
    'master', '', 'The address of the TensorFlow master to use.')

tf.app.flags.DEFINE_string(
    'checkpoint_path', '/tmp/tfmodel/',
    'The directory where the model was written to or an absolute path to a '
    'checkpoint file.')

tf.app.flags.DEFINE_string(
    'eval_dir', '/tmp/tfmodel/', 'Directory where the results are saved to.')

tf.app.flags.DEFINE_integer(
    'num_preprocessing_threads', 4,
    'The number of threads used to create the batches.')

tf.app.flags.DEFINE_string(
    'dataset_name', 'imagenet', 'The name of the dataset to load.')

tf.app.flags.DEFINE_string(
    'dataset_split_name', 'test', 'The name of the train/test split.')

tf.app.flags.DEFINE_string(
    'dataset_dir', None, 'The directory where the dataset files are stored.')

tf.app.flags.DEFINE_integer(
    'labels_offset', 0,
    'An offset for the labels in the dataset. This flag is primarily used to '
    'evaluate the VGG and ResNet architectures which do not use a background '
    'class for the ImageNet dataset.')

tf.app.flags.DEFINE_string(
    'model_name', 'inception_v3', 'The name of the architecture to evaluate.')

tf.app.flags.DEFINE_string(
    'preprocessing_name', None, 'The name of the preprocessing to use. If left '
    'as `None`, then the model_name flag is used.')

tf.app.flags.DEFINE_float(
    'moving_average_decay', None,
    'The decay to use for the moving average.'
    'If left as None, then moving averages are not used.')

tf.app.flags.DEFINE_integer(
    'eval_image_size', None, 'Eval image size')

FLAGS = tf.app.flags.FLAGS


def main(_):
  if not FLAGS.dataset_dir:
    raise ValueError('You must supply the dataset directory with --dataset_dir')

  tf.logging.set_verbosity(tf.logging.INFO) #设置log信息的级别，有DEBUG, INFO, WARN, ERROR, or FATAL
  with tf.Graph().as_default():  #overrides the current default graph for the lifetime of the context
                                    #注意不是线程安全的..
    tf_global_step = slim.get_or_create_global_step()
                        #slim.get_or_create_global_step可以参考tf.train.get_or_create_global_step
                        #作用同样是得到global step tensor，参数为graph,参数为空时认为参数为default graph
    ######################
    # Select the dataset #
    ######################
    dataset = dataset_factory.get_dataset(
        FLAGS.dataset_name, FLAGS.dataset_split_name, FLAGS.dataset_dir)

    ####################
    # Select the model #
    ####################
    network_fn = nets_factory.get_network_fn(
        FLAGS.model_name,
        num_classes=(dataset.num_classes - FLAGS.labels_offset),
        is_training=False)

    ##############################################################
    # Create a dataset provider that loads data from the dataset #
    ##############################################################
                                    #读取数据
    provider = slim.dataset_data_provider.DatasetDataProvider(
        dataset,
        shuffle=False,
        common_queue_capacity=2 * FLAGS.batch_size,
        common_queue_min=FLAGS.batch_size)
    [image, label] = provider.get(['image', 'label'])
    label -= FLAGS.labels_offset

    #####################################
    # Select the preprocessing function #
    #####################################
    preprocessing_name = FLAGS.preprocessing_name or FLAGS.model_name
    image_preprocessing_fn = preprocessing_factory.get_preprocessing(
        preprocessing_name,
        is_training=False)
    #python or的用法，flag1 or flag2 or... or flagn,如果最后逻辑值为真，
    # 返回的是（葱左至右）第一个使其为真的值（而不返回布尔值），
    #如果都为假，则返回最后一个假值
    eval_image_size = FLAGS.eval_image_size or network_fn.default_image_size

    image = image_preprocessing_fn(image, eval_image_size, eval_image_size)

    images, labels = tf.train.batch(
        [image, label],
        batch_size=FLAGS.batch_size,
        num_threads=FLAGS.num_preprocessing_threads,
        capacity=5 * FLAGS.batch_size)

    ####################
    # Define the model #
    ####################
    logits, _ = network_fn(images)  #python语法,序列解包

    #移动平均，参考 https://en.wikipedia.org/wiki/Moving_average
    if FLAGS.moving_average_decay:
      variable_averages = tf.train.ExponentialMovingAverage(
          FLAGS.moving_average_decay, tf_global_step)
      variables_to_restore = variable_averages.variables_to_restore(
          slim.get_model_variables())
      variables_to_restore[tf_global_step.op.name] = tf_global_step
    else:
      variables_to_restore = slim.get_variables_to_restore()

    predictions = tf.argmax(logits, 1)
    #tf.argmax(input, axis=None, name=None, dimension=None)
    #Returns the index with the largest value across axes of a tensor.
    #就是返回logits的第一维（行？）最大值的位置索引


    labels = tf.squeeze(labels) #将labels中维度是1的那一维去掉

    # Define the metrics:
    names_to_values, names_to_updates = slim.metrics.aggregate_metric_map({
        'Accuracy': slim.metrics.streaming_accuracy(predictions, labels),
        'Recall_5': slim.metrics.streaming_recall_at_k(
            logits, labels, 5),
    })
    #metrics.aggregate_metric_map在metrics的list很长的时候的一种简便的表达方式
    #metrics直接翻译为【度量】，不是tensorflow的概念.用来监控计算的性能指标


    # Print the summaries to screen.
    for name, value in names_to_values.items():
      summary_name = 'eval/%s' % name
      op = tf.summary.scalar(summary_name, value, collections=[])
      #tf.summary.scalar :Outputs a Summary protocol buffer containing a single scalar value
      op = tf.Print(op, [value], summary_name)
      tf.add_to_collection(tf.GraphKeys.SUMMARIES, op)

    # TODO(sguada) use num_epochs=1
    if FLAGS.max_num_batches:
      num_batches = FLAGS.max_num_batches
    else:
      # This ensures that we make a single pass over all of the data.
      num_batches = math.ceil(dataset.num_samples / float(FLAGS.batch_size))

    if tf.gfile.IsDirectory(FLAGS.checkpoint_path):#返回是否为一个目录
      checkpoint_path = tf.train.latest_checkpoint(FLAGS.checkpoint_path)
    else:
      checkpoint_path = FLAGS.checkpoint_path

    tf.logging.info('Evaluating %s' % checkpoint_path)  #记录log信息

    #Evaluates the model at the given checkpoint path.
    #Evaluates the model at the given checkpoint path.
    slim.evaluation.evaluate_once(
        master=FLAGS.master,
        checkpoint_path=checkpoint_path,
        logdir=FLAGS.eval_dir,
        num_evals=num_batches,
        eval_op=list(names_to_updates.values()),
        variables_to_restore=variables_to_restore)


if __name__ == '__main__':
  tf.app.run()




# Copyright 2017 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
r&quot;&quot;&quot;Saves out a GraphDef containing the architecture of the model.

To use it, run something like this, with a model name defined by slim:

bazel build tensorflow_models/slim:export_inference_graph
bazel-bin/tensorflow_models/slim/export_inference_graph \
--model_name=inception_v3 --output_file=/tmp/inception_v3_inf_graph.pb

If you then want to use the resulting model with your own or pretrained
checkpoints as part of a mobile model, you can run freeze_graph to get a graph
def with the variables inlined as constants using:

bazel build tensorflow/python/tools:freeze_graph
bazel-bin/tensorflow/python/tools/freeze_graph \
--input_graph=/tmp/inception_v3_inf_graph.pb \
--input_checkpoint=/tmp/checkpoints/inception_v3.ckpt \
--input_binary=true --output_graph=/tmp/frozen_inception_v3.pb \
--output_node_names=InceptionV3/Predictions/Reshape_1

The output node names will vary depending on the model, but you can inspect and
estimate them using the summarize_graph tool:

bazel build tensorflow/tools/graph_transforms:summarize_graph
bazel-bin/tensorflow/tools/graph_transforms/summarize_graph \
--in_graph=/tmp/inception_v3_inf_graph.pb

To run the resulting graph in C++, you can look at the label_image sample code:

bazel build tensorflow/examples/label_image:label_image
bazel-bin/tensorflow/examples/label_image/label_image \
--image=${HOME}/Pictures/flowers.jpg \
--input_layer=input \
--output_layer=InceptionV3/Predictions/Reshape_1 \
--graph=/tmp/frozen_inception_v3.pb \
--labels=/tmp/imagenet_slim_labels.txt \
--input_mean=0 \
--input_std=255

&quot;&quot;&quot;

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import tensorflow as tf

from tensorflow.python.platform import gfile
from datasets import dataset_factory
from nets import nets_factory


slim = tf.contrib.slim

tf.app.flags.DEFINE_string(
    'model_name', 'inception_v3', 'The name of the architecture to save.')

tf.app.flags.DEFINE_boolean(
    'is_training', False,
    'Whether to save out a training-focused version of the model.')

tf.app.flags.DEFINE_integer(
    'default_image_size', 224,
    'The image size to use if the model does not define it.')

tf.app.flags.DEFINE_string('dataset_name', 'imagenet',
                           'The name of the dataset to use with the model.')

tf.app.flags.DEFINE_integer(
    'labels_offset', 0,
    'An offset for the labels in the dataset. This flag is primarily used to '
    'evaluate the VGG and ResNet architectures which do not use a background '
    'class for the ImageNet dataset.')

tf.app.flags.DEFINE_string(
    'output_file', '', 'Where to save the resulting file to.')

tf.app.flags.DEFINE_string(
    'dataset_dir', '', 'Directory to save intermediate dataset files to')

FLAGS = tf.app.flags.FLAGS


def main(_):
  if not FLAGS.output_file:
    raise ValueError('You must supply the path to save to with --output_file')
  tf.logging.set_verbosity(tf.logging.INFO)
  with tf.Graph().as_default() as graph:
    dataset = dataset_factory.get_dataset(FLAGS.dataset_name, 'train',
                                          FLAGS.dataset_dir)
    network_fn = nets_factory.get_network_fn(
        FLAGS.model_name,
        num_classes=(dataset.num_classes - FLAGS.labels_offset),
        is_training=FLAGS.is_training)

    #hasattr 是python语法， hasattr(object, name) -&gt; bool，用来判断object中是否有name属性
    if hasattr(network_fn, 'default_image_size'):
      image_size = network_fn.default_image_size
    else:
      image_size = FLAGS.default_image_size
    placeholder = tf.placeholder(name='input', dtype=tf.float32,
                                 shape=[1, image_size, image_size, 3])
    network_fn(placeholder)
    graph_def = graph.as_graph_def()
    #graph.as_graph_def():Returns a serialized（序列化） GraphDef representation of this graph.
    #The serialized GraphDef can be imported into another Graph (using tf.import_graph_def) or used with the C++ Session API.
    #该方法线程安全


    # gfile。GFile 是一个无线程锁的I/O 封装
    with gfile.GFile(FLAGS.output_file, 'wb') as f:
      f.write(graph_def.SerializeToString())


if __name__ == '__main__':
  tf.app.run()





# coding=utf-8
# Copyright 2016 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
&quot;&quot;&quot;Generic training script that trains a model using a given dataset.&quot;&quot;&quot;

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import tensorflow as tf

from datasets import dataset_factory
from deployment import model_deploy
from nets import nets_factory
from preprocessing import preprocessing_factory

slim = tf.contrib.slim

tf.app.flags.DEFINE_string(
    'master', '', 'The address of the TensorFlow master to use.')

tf.app.flags.DEFINE_string(
    'train_dir', '/tmp/tfmodel/',
    'Directory where checkpoints and event logs are written to.')

tf.app.flags.DEFINE_integer('num_clones', 1,
                            'Number of model clones to deploy.')

tf.app.flags.DEFINE_boolean('clone_on_cpu', False,
                            'Use CPUs to deploy clones.')

tf.app.flags.DEFINE_integer('worker_replicas', 1, 'Number of worker replicas.')

tf.app.flags.DEFINE_integer(
    'num_ps_tasks', 0,
    'The number of parameter servers. If the value is 0, then the parameters '
    'are handled locally by the worker.')

tf.app.flags.DEFINE_integer(
    'num_readers', 4,
    'The number of parallel readers that read data from the dataset.')

tf.app.flags.DEFINE_integer(
    'num_preprocessing_threads', 4,
    'The number of threads used to create the batches.')

tf.app.flags.DEFINE_integer(
    'log_every_n_steps', 10,
    'The frequency with which logs are print.')

tf.app.flags.DEFINE_integer(
    'save_summaries_secs', 600,
    'The frequency with which summaries are saved, in seconds.')

tf.app.flags.DEFINE_integer(
    'save_interval_secs', 600,
    'The frequency with which the model is saved, in seconds.')

tf.app.flags.DEFINE_integer(
    'task', 0, 'Task id of the replica running the training.')

######################
# Optimization Flags #
######################

tf.app.flags.DEFINE_float(
    'weight_decay', 0.00004, 'The weight decay on the model weights.')

tf.app.flags.DEFINE_string(
    'optimizer', 'rmsprop',
    'The name of the optimizer, one of &quot;adadelta&quot;, &quot;adagrad&quot;, &quot;adam&quot;,'
    '&quot;ftrl&quot;, &quot;momentum&quot;, &quot;sgd&quot; or &quot;rmsprop&quot;.')

tf.app.flags.DEFINE_float(
    'adadelta_rho', 0.95,
    'The decay rate for adadelta.')

tf.app.flags.DEFINE_float(
    'adagrad_initial_accumulator_value', 0.1,
    'Starting value for the AdaGrad accumulators.')

tf.app.flags.DEFINE_float(
    'adam_beta1', 0.9,
    'The exponential decay rate for the 1st moment estimates.')

tf.app.flags.DEFINE_float(
    'adam_beta2', 0.999,
    'The exponential decay rate for the 2nd moment estimates.')

tf.app.flags.DEFINE_float('opt_epsilon', 1.0, 'Epsilon term for the optimizer.')

tf.app.flags.DEFINE_float('ftrl_learning_rate_power', -0.5,
                          'The learning rate power.')

tf.app.flags.DEFINE_float(
    'ftrl_initial_accumulator_value', 0.1,
    'Starting value for the FTRL accumulators.')

tf.app.flags.DEFINE_float(
    'ftrl_l1', 0.0, 'The FTRL l1 regularization strength.')

tf.app.flags.DEFINE_float(
    'ftrl_l2', 0.0, 'The FTRL l2 regularization strength.')

tf.app.flags.DEFINE_float(
    'momentum', 0.9,
    'The momentum for the MomentumOptimizer and RMSPropOptimizer.')

tf.app.flags.DEFINE_float('rmsprop_decay', 0.9, 'Decay term for RMSProp.')

#######################
# Learning Rate Flags #
#######################

tf.app.flags.DEFINE_string(
    'learning_rate_decay_type',
    'exponential',
    'Specifies how the learning rate is decayed. One of &quot;fixed&quot;, &quot;exponential&quot;,'
    ' or &quot;polynomial&quot;')

tf.app.flags.DEFINE_float('learning_rate', 0.01, 'Initial learning rate.')

tf.app.flags.DEFINE_float(
    'end_learning_rate', 0.0001,
    'The minimal end learning rate used by a polynomial decay learning rate.')

tf.app.flags.DEFINE_float(
    'label_smoothing', 0.0, 'The amount of label smoothing.')

tf.app.flags.DEFINE_float(
    'learning_rate_decay_factor', 0.94, 'Learning rate decay factor.')

tf.app.flags.DEFINE_float(
    'num_epochs_per_decay', 2.0,
    'Number of epochs after which learning rate decays.')

tf.app.flags.DEFINE_bool(
    'sync_replicas', False,
    'Whether or not to synchronize the replicas during training.')

tf.app.flags.DEFINE_integer(
    'replicas_to_aggregate', 1,
    'The Number of gradients to collect before updating params.')

tf.app.flags.DEFINE_float(
    'moving_average_decay', None,
    'The decay to use for the moving average.'
    'If left as None, then moving averages are not used.')

#######################
# Dataset Flags #
#######################

tf.app.flags.DEFINE_string(
    'dataset_name', 'imagenet', 'The name of the dataset to load.')

tf.app.flags.DEFINE_string(
    'dataset_split_name', 'train', 'The name of the train/test split.')

tf.app.flags.DEFINE_string(
    'dataset_dir', None, 'The directory where the dataset files are stored.')

tf.app.flags.DEFINE_integer(
    'labels_offset', 0,
    'An offset for the labels in the dataset. This flag is primarily used to '
    'evaluate the VGG and ResNet architectures which do not use a background '
    'class for the ImageNet dataset.')

tf.app.flags.DEFINE_string(
    'model_name', 'inception_v3', 'The name of the architecture to train.')

tf.app.flags.DEFINE_string(
    'preprocessing_name', None, 'The name of the preprocessing to use. If left '
    'as `None`, then the model_name flag is used.')

tf.app.flags.DEFINE_integer(
    'batch_size', 32, 'The number of samples in each batch.')

tf.app.flags.DEFINE_integer(
    'train_image_size', None, 'Train image size')

tf.app.flags.DEFINE_integer('max_number_of_steps', None,
                            'The maximum number of training steps.')

#####################
# Fine-Tuning Flags #
#####################

tf.app.flags.DEFINE_string(
    'checkpoint_path', None,
    'The path to a checkpoint from which to fine-tune.')

tf.app.flags.DEFINE_string(
    'checkpoint_exclude_scopes', None,
    'Comma-separated list of scopes of variables to exclude when restoring '
    'from a checkpoint.')

tf.app.flags.DEFINE_string(
    'trainable_scopes', None,
    'Comma-separated list of scopes to filter the set of variables to train.'
    'By default, None would train all the variables.')

tf.app.flags.DEFINE_boolean(
    'ignore_missing_vars', False,
    'When restoring a checkpoint would ignore missing variables.')

FLAGS = tf.app.flags.FLAGS


def _configure_learning_rate(num_samples_per_epoch, global_step):
  &quot;&quot;&quot;Configures the learning rate.

  Args:
    num_samples_per_epoch: The number of samples in each epoch of training.
    global_step: The global_step tensor.

  Returns:
    A `Tensor` representing the learning rate.

  Raises:
    ValueError: if
  &quot;&quot;&quot;
  decay_steps = int(num_samples_per_epoch / FLAGS.batch_size *
                    FLAGS.num_epochs_per_decay)
  if FLAGS.sync_replicas:
    decay_steps /= FLAGS.replicas_to_aggregate
      #dacay,衰退


    #下面是几种学习速率的变化形式，可以是指数型衰退，可以是固定不变，也可以使多项式型衰退。
  if FLAGS.learning_rate_decay_type == 'exponential':
    return tf.train.exponential_decay(FLAGS.learning_rate,
                                      global_step,
                                      decay_steps,
                                      FLAGS.learning_rate_decay_factor,
                                      staircase=True,
                                      name='exponential_decay_learning_rate')
  elif FLAGS.learning_rate_decay_type == 'fixed':
    return tf.constant(FLAGS.learning_rate, name='fixed_learning_rate')
  elif FLAGS.learning_rate_decay_type == 'polynomial':
    return tf.train.polynomial_decay(FLAGS.learning_rate,
                                     global_step,
                                     decay_steps,
                                     FLAGS.end_learning_rate,
                                     power=1.0,
                                     cycle=False,
                                     name='polynomial_decay_learning_rate')
  else:
    raise ValueError('learning_rate_decay_type [%s] was not recognized',
                     FLAGS.learning_rate_decay_type)



#选择优化方法（优化器，大概是求偏导的具体数值计算方法？），tf内置了许多优化方法，类比梯度下降，细节黑箱即可。
def _configure_optimizer(learning_rate):
  &quot;&quot;&quot;Configures the optimizer used for training.

  Args:
    learning_rate: A scalar or `Tensor` learning rate.

  Returns:
    An instance of an optimizer.

  Raises:
    ValueError: if FLAGS.optimizer is not recognized.
  &quot;&quot;&quot;
  if FLAGS.optimizer == 'adadelta':
    optimizer = tf.train.AdadeltaOptimizer(
        learning_rate,
        rho=FLAGS.adadelta_rho,
        epsilon=FLAGS.opt_epsilon)
  elif FLAGS.optimizer == 'adagrad':
    optimizer = tf.train.AdagradOptimizer(
        learning_rate,
        initial_accumulator_value=FLAGS.adagrad_initial_accumulator_value)
  elif FLAGS.optimizer == 'adam':
    optimizer = tf.train.AdamOptimizer(
        learning_rate,
        beta1=FLAGS.adam_beta1,
        beta2=FLAGS.adam_beta2,
        epsilon=FLAGS.opt_epsilon)
  elif FLAGS.optimizer == 'ftrl':
    optimizer = tf.train.FtrlOptimizer(
        learning_rate,
        learning_rate_power=FLAGS.ftrl_learning_rate_power,
        initial_accumulator_value=FLAGS.ftrl_initial_accumulator_value,
        l1_regularization_strength=FLAGS.ftrl_l1,
        l2_regularization_strength=FLAGS.ftrl_l2)
  elif FLAGS.optimizer == 'momentum':
    optimizer = tf.train.MomentumOptimizer(
        learning_rate,
        momentum=FLAGS.momentum,
        name='Momentum')
  elif FLAGS.optimizer == 'rmsprop':
    optimizer = tf.train.RMSPropOptimizer(
        learning_rate,
        decay=FLAGS.rmsprop_decay,
        momentum=FLAGS.momentum,
        epsilon=FLAGS.opt_epsilon)
  elif FLAGS.optimizer == 'sgd':
    optimizer = tf.train.GradientDescentOptimizer(learning_rate)
  else:
    raise ValueError('Optimizer [%s] was not recognized', FLAGS.optimizer)
  return optimizer


def _get_init_fn():
  &quot;&quot;&quot;Returns a function run by the chief worker to warm-start the training.

  Note that the init_fn is only run when initializing the model during the very
  first global step.

  Returns:
    An init function run by the supervisor.
  &quot;&quot;&quot;
  if FLAGS.checkpoint_path is None:
    return None

  # Warn the user if a checkpoint exists in the train_dir. Then we'll be
  # ignoring the checkpoint anyway.
  if tf.train.latest_checkpoint(FLAGS.train_dir):
    tf.logging.info(
        'Ignoring --checkpoint_path because a checkpoint already exists in %s'
        % FLAGS.train_dir)
    return None

  exclusions = []  #python的list数据类型
  if FLAGS.checkpoint_exclude_scopes:
    exclusions = [scope.strip()
                  for scope in FLAGS.checkpoint_exclude_scopes.split(',')]

  # TODO(sguada) variables.filter_variables()
  variables_to_restore = []
  for var in slim.get_model_variables():
    excluded = False
    for exclusion in exclusions:
      if var.op.name.startswith(exclusion):
        excluded = True
        break
    if not excluded:
      variables_to_restore.append(var)

  if tf.gfile.IsDirectory(FLAGS.checkpoint_path):
    checkpoint_path = tf.train.latest_checkpoint(FLAGS.checkpoint_path)
  else:
    checkpoint_path = FLAGS.checkpoint_path

  tf.logging.info('Fine-tuning from %s' % checkpoint_path)

  return slim.assign_from_checkpoint_fn(
      checkpoint_path,
      variables_to_restore,
      ignore_missing_vars=FLAGS.ignore_missing_vars)


def _get_variables_to_train():
  &quot;&quot;&quot;Returns a list of variables to train.

  Returns:
    A list of variables to train by the optimizer.
  &quot;&quot;&quot;
  if FLAGS.trainable_scopes is None:
    return tf.trainable_variables()
  else:
    scopes = [scope.strip() for scope in FLAGS.trainable_scopes.split(',')]

  variables_to_train = []
  for scope in scopes:
    variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope)
    variables_to_train.extend(variables)
  return variables_to_train


def main(_):
  if not FLAGS.dataset_dir:
    raise ValueError('You must supply the dataset directory with --dataset_dir')

  tf.logging.set_verbosity(tf.logging.INFO)
  with tf.Graph().as_default():
    #######################
    # Config model_deploy #
    #######################
    deploy_config = model_deploy.DeploymentConfig(
        num_clones=FLAGS.num_clones,
        clone_on_cpu=FLAGS.clone_on_cpu,
        replica_id=FLAGS.task,
        num_replicas=FLAGS.worker_replicas,
        num_ps_tasks=FLAGS.num_ps_tasks)

    # Create global_step
    with tf.device(deploy_config.variables_device()):
      global_step = slim.create_global_step()

    ######################
    # Select the dataset #
    ######################
    dataset = dataset_factory.get_dataset(
        FLAGS.dataset_name, FLAGS.dataset_split_name, FLAGS.dataset_dir)

    ######################
    # Select the network #
    ######################
    network_fn = nets_factory.get_network_fn(
        FLAGS.model_name,
        num_classes=(dataset.num_classes - FLAGS.labels_offset),
        weight_decay=FLAGS.weight_decay,
        is_training=True)

    #####################################
    # Select the preprocessing function #
    #####################################
    preprocessing_name = FLAGS.preprocessing_name or FLAGS.model_name
    image_preprocessing_fn = preprocessing_factory.get_preprocessing(
        preprocessing_name,
        is_training=True)

    ##############################################################
    # Create a dataset provider that loads data from the dataset #
    ##############################################################
    with tf.device(deploy_config.inputs_device()):
      provider = slim.dataset_data_provider.DatasetDataProvider(  #还是定义一些数据的读取方式
          dataset,
          num_readers=FLAGS.num_readers,
          common_queue_capacity=20 * FLAGS.batch_size,
          common_queue_min=10 * FLAGS.batch_size)
      [image, label] = provider.get(['image', 'label'])
      label -= FLAGS.labels_offset

      train_image_size = FLAGS.train_image_size or network_fn.default_image_size

      image = image_preprocessing_fn(image, train_image_size, train_image_size)

      images, labels = tf.train.batch(
          [image, label],
          batch_size=FLAGS.batch_size,
          num_threads=FLAGS.num_preprocessing_threads,
          capacity=5 * FLAGS.batch_size)
      labels = slim.one_hot_encoding(    #one-hot是一种向量编码方式，n维向量只有为相应值的位置为1，其余都为0
          labels, dataset.num_classes - FLAGS.labels_offset)
      batch_queue = slim.prefetch_queue.prefetch_queue(
          [images, labels], capacity=2 * deploy_config.num_clones)

    ####################
    # Define the model #
    ####################
    #通过复制多个网络来实现并行
    def clone_fn(batch_queue):
      &quot;&quot;&quot;Allows data parallelism by creating multiple clones of network_fn.&quot;&quot;&quot;
      with tf.device(deploy_config.inputs_device()):
        images, labels = batch_queue.dequeue()  #dequeue，双端队列。。
      logits, end_points = network_fn(images)

      #############################
      # Specify the loss function #
      #############################
      if 'AuxLogits' in end_points:
        tf.losses.softmax_cross_entropy(   #softmax函数对应使用的cost function(loss function)
                                            #是corss_entropy,也就是交叉熵
            logits=end_points['AuxLogits'], onehot_labels=labels,
            label_smoothing=FLAGS.label_smoothing, weights=0.4, scope='aux_loss')
      tf.losses.softmax_cross_entropy(
          logits=logits, onehot_labels=labels,
          label_smoothing=FLAGS.label_smoothing, weights=1.0)
      #Label Smoothing Regularization，一种防止overfit的优化方法
      return end_points

    # Gather initial summaries.
    summaries = set(tf.get_collection(tf.GraphKeys.SUMMARIES))

    clones = model_deploy.create_clones(deploy_config, clone_fn, [batch_queue])
    first_clone_scope = deploy_config.clone_scope(0)
    # Gather update_ops from the first clone. These contain, for example,
    # the updates for the batch_norm variables created by network_fn.
    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS, first_clone_scope)

    # Add summaries for end_points.
    end_points = clones[0].outputs
    for end_point in end_points:
      x = end_points[end_point]
      summaries.add(tf.summary.histogram('activations/' + end_point, x))
      summaries.add(tf.summary.scalar('sparsity/' + end_point,
                                      tf.nn.zero_fraction(x)))

    # Add summaries for losses.
    for loss in tf.get_collection(tf.GraphKeys.LOSSES, first_clone_scope):
      summaries.add(tf.summary.scalar('losses/%s' % loss.op.name, loss))

    # Add summaries for variables.
    for variable in slim.get_model_variables():
      summaries.add(tf.summary.histogram(variable.op.name, variable))
        #突然画图

    #################################
    # Configure the moving averages #  #参考moving averages的wiki
    #################################
    if FLAGS.moving_average_decay:
      moving_average_variables = slim.get_model_variables()
      variable_averages = tf.train.ExponentialMovingAverage(
          FLAGS.moving_average_decay, global_step)
    else:
      moving_average_variables, variable_averages = None, None

    #########################################
    # Configure the optimization procedure. #
    #########################################
    with tf.device(deploy_config.optimizer_device()):
      learning_rate = _configure_learning_rate(dataset.num_samples, global_step)
      optimizer = _configure_optimizer(learning_rate)
      summaries.add(tf.summary.scalar('learning_rate', learning_rate))


    #在分布式系统上训练的同步...
    if FLAGS.sync_replicas:
      # If sync_replicas is enabled, the averaging will be done in the chief
      # queue runner.
      optimizer = tf.train.SyncReplicasOptimizer(
          opt=optimizer,
          replicas_to_aggregate=FLAGS.replicas_to_aggregate,
          variable_averages=variable_averages,
          variables_to_average=moving_average_variables,
          replica_id=tf.constant(FLAGS.task, tf.int32, shape=()),
          total_num_replicas=FLAGS.worker_replicas)
    elif FLAGS.moving_average_decay:
      # Update ops executed locally by trainer.
      update_ops.append(variable_averages.apply(moving_average_variables))

    # Variables to train.
    variables_to_train = _get_variables_to_train()

    #  and returns a train_tensor and summary_op
    total_loss, clones_gradients = model_deploy.optimize_clones(
        clones,
        optimizer,
        var_list=variables_to_train)
    # Add total_loss to summary.
    summaries.add(tf.summary.scalar('total_loss', total_loss))

    # Create gradient updates.
    grad_updates = optimizer.apply_gradients(clones_gradients,
                                             global_step=global_step)
    update_ops.append(grad_updates)

    update_op = tf.group(*update_ops)
    with tf.control_dependencies([update_op]):
      train_tensor = tf.identity(total_loss, name='train_op')

    # Add the summaries from the first clone. These contain the summaries
    # created by model_fn and either optimize_clones() or _gather_clone_loss().
    summaries |= set(tf.get_collection(tf.GraphKeys.SUMMARIES,
                                       first_clone_scope))

    # Merge all summaries together.
    summary_op = tf.summary.merge(list(summaries), name='summary_op')


    ###########################
    # Kicks off the training. #
    ###########################
    slim.learning.train(
        train_tensor,
        logdir=FLAGS.train_dir,
        master=FLAGS.master,
        is_chief=(FLAGS.task == 0),
        init_fn=_get_init_fn(),
        summary_op=summary_op,
        number_of_steps=FLAGS.max_number_of_steps,
        log_every_n_steps=FLAGS.log_every_n_steps,
        save_summaries_secs=FLAGS.save_summaries_secs,
        save_interval_secs=FLAGS.save_interval_secs,
        sync_optimizer=optimizer if FLAGS.sync_replicas else None)


if __name__ == '__main__':
  tf.app.run()
</code></pre>


                
                
<div class="entry-shang text-center">
    
	    <p>「真诚赞赏，手留余香」</p>
	
	<button class="zs show-zs btn btn-bred">赞赏支持</button>
</div>
<div class="zs-modal-bg"></div>
<div class="zs-modal-box">
	<div class="zs-modal-head">
		<button type="button" class="close">×</button>
		<span class="author"><a href="https://111qqz.github.io"><img src="/img/favicon.png" />111qqz的小窝</a></span>
        
	        <p class="tip"><i></i><span>真诚赞赏，手留余香</span></p>
		
 
	</div>
	<div class="zs-modal-body">
		<div class="zs-modal-btns">
			<button class="btn btn-blink" data-num="2">2元</button>
			<button class="btn btn-blink" data-num="5">5元</button>
			<button class="btn btn-blink" data-num="10">10元</button>
			<button class="btn btn-blink" data-num="50">50元</button>
			<button class="btn btn-blink" data-num="100">100元</button>
			<button class="btn btn-blink" data-num="1">任意金额</button>
		</div>
		<div class="zs-modal-pay">
			<button class="btn btn-bred" id="pay-text">2元</button>
			<p>使用<span id="pay-type">微信</span>扫描二维码完成支付</p>
			<img src="/img/reward/wechat-2.png"  id="pay-image"/>
		</div>
	</div>
	<div class="zs-modal-footer">
		<label><input type="radio" name="zs-type" value="wechat" class="zs-type" checked="checked"><span ><span class="zs-wechat"><img src="/img/reward/wechat-btn.png"/></span></label>
		<label><input type="radio" name="zs-type" value="alipay" class="zs-type" class="zs-alipay"><img src="/img/reward/alipay-btn.png"/></span></label>
	</div>
</div>
<script type="text/javascript" src="/js/reward.js"></script>

                

                <hr>
                <ul class="pager">
                    
                    <li class="previous">
                        <a href="/2017/07/%e5%ae%9e%e4%b9%a0%e8%ae%b0%e5%bd%95/" data-toggle="tooltip" data-placement="top" title="实习记录">&larr;
                            Previous Post</a>
                    </li>
                    
                    
                    <li class="next">
                        <a href="/2017/07/cs231n_linear-classification/" data-toggle="tooltip" data-placement="top" title="stanford CS231n notes：Linear classification">Next
                            Post &rarr;</a>
                    </li>
                    
                </ul>

                
<div id="disqus-comment"></div>

<div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "111qqz" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>



            </div>
            
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                sidebar-container">

                
                
                <section>
                    <hr class="hidden-sm hidden-xs">
                    <h5><a href="/tags/">FEATURED TAGS</a></h5>
                    <div class="tags">
                        
                        
                        
                        
                        
                        <a href="/tags/01%E8%83%8C%E5%8C%85" title="01背包">
                            01背包
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/6.828" title="6.828">
                            6.828
                        </a>
                        
                        
                        
                        <a href="/tags/ac%E8%87%AA%E5%8A%A8%E6%9C%BA" title="ac自动机">
                            ac自动机
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/anti-sg" title="anti-sg">
                            anti-sg
                        </a>
                        
                        
                        
                        <a href="/tags/archlinux" title="archlinux">
                            archlinux
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/bfs" title="bfs">
                            bfs
                        </a>
                        
                        
                        
                        <a href="/tags/binary-search" title="binary-search">
                            binary-search
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/bitset%E4%BC%98%E5%8C%96" title="bitset优化">
                            bitset优化
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/brute-force" title="brute-force">
                            brute-force
                        </a>
                        
                        
                        
                        <a href="/tags/bsgs" title="bsgs">
                            bsgs
                        </a>
                        
                        
                        
                        <a href="/tags/c&#43;&#43;11" title="c&#43;&#43;11">
                            c&#43;&#43;11
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/cdq%E5%88%86%E6%B2%BB" title="cdq分治">
                            cdq分治
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/cpp" title="cpp">
                            cpp
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/cuda" title="cuda">
                            cuda
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/deep-learning" title="deep-learning">
                            deep-learning
                        </a>
                        
                        
                        
                        <a href="/tags/dfs" title="dfs">
                            dfs
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/dijkstra" title="dijkstra">
                            dijkstra
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/docker" title="docker">
                            docker
                        </a>
                        
                        
                        
                        <a href="/tags/dp" title="dp">
                            dp
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/floyd" title="floyd">
                            floyd
                        </a>
                        
                        
                        
                        <a href="/tags/floyd-%E5%88%A4%E5%9C%88" title="floyd-判圈">
                            floyd-判圈
                        </a>
                        
                        
                        
                        <a href="/tags/future" title="future">
                            future
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/gcd" title="gcd">
                            gcd
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/geekos" title="geekos">
                            geekos
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/greedy" title="greedy">
                            greedy
                        </a>
                        
                        
                        
                        <a href="/tags/grpc" title="grpc">
                            grpc
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/halide" title="halide">
                            halide
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/hash" title="hash">
                            hash
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/istio" title="istio">
                            istio
                        </a>
                        
                        
                        
                        <a href="/tags/java" title="java">
                            java
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/k-means" title="k-means">
                            k-means
                        </a>
                        
                        
                        
                        <a href="/tags/k-sum" title="k-sum">
                            k-sum
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/kd-tree" title="kd-tree">
                            kd-tree
                        </a>
                        
                        
                        
                        <a href="/tags/km" title="km">
                            km
                        </a>
                        
                        
                        
                        <a href="/tags/kmp" title="kmp">
                            kmp
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/lazy%E6%A0%87%E8%AE%B0" title="lazy标记">
                            lazy标记
                        </a>
                        
                        
                        
                        <a href="/tags/lca" title="lca">
                            lca
                        </a>
                        
                        
                        
                        <a href="/tags/leveldb" title="leveldb">
                            leveldb
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/linux" title="linux">
                            linux
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/lis" title="lis">
                            lis
                        </a>
                        
                        
                        
                        <a href="/tags/log" title="log">
                            log
                        </a>
                        
                        
                        
                        <a href="/tags/lru" title="lru">
                            lru
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/lucas%E5%AE%9A%E7%90%86" title="lucas定理">
                            lucas定理
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/manacher" title="manacher">
                            manacher
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/map" title="map">
                            map
                        </a>
                        
                        
                        
                        <a href="/tags/math" title="math">
                            math
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/microservice" title="microservice">
                            microservice
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/mst" title="mst">
                            mst
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/mysql" title="mysql">
                            mysql
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/nim%E6%B8%B8%E6%88%8F" title="nim游戏">
                            nim游戏
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/number-theory" title="number-theory">
                            number-theory
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/pca" title="pca">
                            pca
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/promise" title="promise">
                            promise
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/python" title="python">
                            python
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/qt" title="qt">
                            qt
                        </a>
                        
                        
                        
                        <a href="/tags/react" title="react">
                            react
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/reid" title="reid">
                            reid
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/rmq" title="rmq">
                            rmq
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/security" title="security">
                            security
                        </a>
                        
                        
                        
                        <a href="/tags/set" title="set">
                            set
                        </a>
                        
                        
                        
                        <a href="/tags/sg%E5%87%BD%E6%95%B0" title="sg函数">
                            sg函数
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/sj%E5%AE%9A%E7%90%86" title="sj定理">
                            sj定理
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/sortings" title="sortings">
                            sortings
                        </a>
                        
                        
                        
                        <a href="/tags/spfa" title="spfa">
                            spfa
                        </a>
                        
                        
                        
                        <a href="/tags/spring" title="spring">
                            spring
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/steam" title="steam">
                            steam
                        </a>
                        
                        
                        
                        <a href="/tags/stl" title="stl">
                            stl
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/tarjan" title="tarjan">
                            tarjan
                        </a>
                        
                        
                        
                        <a href="/tags/tensorflow" title="tensorflow">
                            tensorflow
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/thrust" title="thrust">
                            thrust
                        </a>
                        
                        
                        
                        <a href="/tags/tree" title="tree">
                            tree
                        </a>
                        
                        
                        
                        <a href="/tags/trie" title="trie">
                            trie
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/tsp" title="tsp">
                            tsp
                        </a>
                        
                        
                        
                        <a href="/tags/two-pointer" title="two-pointer">
                            two-pointer
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/vector" title="vector">
                            vector
                        </a>
                        
                        
                        
                        <a href="/tags/vim" title="vim">
                            vim
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/wordpress" title="wordpress">
                            wordpress
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/%E4%B8%89%E5%88%86" title="三分">
                            三分
                        </a>
                        
                        
                        
                        <a href="/tags/%E4%B8%AD%E5%9B%BD%E5%89%A9%E4%BD%99%E5%AE%9A%E7%90%86" title="中国剩余定理">
                            中国剩余定理
                        </a>
                        
                        
                        
                        <a href="/tags/%E4%B8%BB%E5%B8%AD%E6%A0%91" title="主席树">
                            主席树
                        </a>
                        
                        
                        
                        <a href="/tags/%E4%B9%B1%E6%90%9E" title="乱搞">
                            乱搞
                        </a>
                        
                        
                        
                        <a href="/tags/%E4%BA%8C%E5%88%86" title="二分">
                            二分
                        </a>
                        
                        
                        
                        <a href="/tags/%E4%BA%8C%E5%88%86%E5%9B%BE" title="二分图">
                            二分图
                        </a>
                        
                        
                        
                        <a href="/tags/%E4%BA%8C%E5%88%86%E5%9B%BE%E5%8C%B9%E9%85%8D" title="二分图匹配">
                            二分图匹配
                        </a>
                        
                        
                        
                        <a href="/tags/%E4%BA%8C%E5%88%86%E5%9B%BE%E6%9C%80%E4%BD%B3%E5%8C%B9%E9%85%8D" title="二分图最佳匹配">
                            二分图最佳匹配
                        </a>
                        
                        
                        
                        <a href="/tags/%E4%BA%8C%E6%AC%A1%E5%89%A9%E4%BD%99" title="二次剩余">
                            二次剩余
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/%E4%BA%A4%E5%8F%89%E6%9F%93%E8%89%B2%E6%B3%95" title="交叉染色法">
                            交叉染色法
                        </a>
                        
                        
                        
                        <a href="/tags/%E4%BC%98%E5%85%88%E9%98%9F%E5%88%97" title="优先队列">
                            优先队列
                        </a>
                        
                        
                        
                        <a href="/tags/%E4%BC%A0%E9%80%92%E9%97%AD%E5%8C%85" title="传递闭包">
                            传递闭包
                        </a>
                        
                        
                        
                        <a href="/tags/%E4%BD%8D%E8%BF%90%E7%AE%97" title="位运算">
                            位运算
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/%E5%88%86%E5%9D%97" title="分块">
                            分块
                        </a>
                        
                        
                        
                        <a href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F" title="分布式">
                            分布式
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/%E5%88%86%E6%B2%BB" title="分治">
                            分治
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/%E5%89%8D%E7%BC%80%E5%92%8C" title="前缀和">
                            前缀和
                        </a>
                        
                        
                        
                        <a href="/tags/%E5%89%A9%E4%BD%99%E7%B3%BB" title="剩余系">
                            剩余系
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/%E5%8C%88%E7%89%99%E5%88%A9%E7%AE%97%E6%B3%95" title="匈牙利算法">
                            匈牙利算法
                        </a>
                        
                        
                        
                        <a href="/tags/%E5%8C%BA%E9%97%B4dp" title="区间dp">
                            区间dp
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/%E5%8C%BA%E9%97%B4%E7%AC%ACk%E5%A4%A7" title="区间第k大">
                            区间第k大
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/%E5%8D%95%E8%B0%83%E6%A0%88" title="单调栈">
                            单调栈
                        </a>
                        
                        
                        
                        <a href="/tags/%E5%8D%95%E8%B0%83%E9%98%9F%E5%88%97" title="单调队列">
                            单调队列
                        </a>
                        
                        
                        
                        <a href="/tags/%E5%8D%9A%E5%BC%88%E8%AE%BA" title="博弈论">
                            博弈论
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/%E5%8F%8D%E7%B4%A0%E6%95%B0" title="反素数">
                            反素数
                        </a>
                        
                        
                        
                        <a href="/tags/%E5%8F%AF%E6%8C%81%E4%B9%85%E5%8C%96%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84" title="可持久化数据结构">
                            可持久化数据结构
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/%E5%90%8E%E7%BC%80%E6%95%B0%E7%BB%84" title="后缀数组">
                            后缀数组
                        </a>
                        
                        
                        
                        <a href="/tags/%E5%90%8E%E7%BC%80%E8%87%AA%E5%8A%A8%E6%9C%BA" title="后缀自动机">
                            后缀自动机
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/%E5%9B%9E%E6%96%87%E4%B8%B2" title="回文串">
                            回文串
                        </a>
                        
                        
                        
                        <a href="/tags/%E5%9B%9E%E6%96%87%E8%87%AA%E5%8A%A8%E6%9C%BA" title="回文自动机">
                            回文自动机
                        </a>
                        
                        
                        
                        <a href="/tags/%E5%9B%BE%E8%AE%BA" title="图论">
                            图论
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2" title="字符串">
                            字符串
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%BE%AA%E7%8E%AF%E5%90%8C%E6%9E%84" title="字符串循环同构">
                            字符串循环同构
                        </a>
                        
                        
                        
                        <a href="/tags/%E5%AE%8C%E5%85%A8%E8%83%8C%E5%8C%85" title="完全背包">
                            完全背包
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/%E5%AE%B9%E6%96%A5%E5%8E%9F%E7%90%86" title="容斥原理">
                            容斥原理
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/%E5%B0%BA%E5%8F%96" title="尺取">
                            尺取
                        </a>
                        
                        
                        
                        <a href="/tags/%E5%B0%BA%E5%8F%96%E6%B3%95" title="尺取法">
                            尺取法
                        </a>
                        
                        
                        
                        <a href="/tags/%E5%B1%80%E9%83%A8%E6%95%8F%E6%84%9Fhash" title="局部敏感hash">
                            局部敏感hash
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/%E5%B7%B4%E4%BB%80%E5%8D%9A%E5%A5%95" title="巴什博奕">
                            巴什博奕
                        </a>
                        
                        
                        
                        <a href="/tags/%E5%B9%B6%E6%9F%A5%E9%9B%86" title="并查集">
                            并查集
                        </a>
                        
                        
                        
                        <a href="/tags/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97" title="并行计算">
                            并行计算
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/%E5%BE%AA%E7%8E%AF%E8%8A%82" title="循环节">
                            循环节
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/%E5%BF%AB%E9%80%9F%E5%B9%82" title="快速幂">
                            快速幂
                        </a>
                        
                        
                        
                        <a href="/tags/%E5%BF%AB%E9%80%9F%E7%AD%9B" title="快速筛">
                            快速筛
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/%E6%80%9D%E7%BB%B4%E9%A2%98" title="思维题">
                            思维题
                        </a>
                        
                        
                        
                        <a href="/tags/%E6%89%93%E8%A1%A8" title="打表">
                            打表
                        </a>
                        
                        
                        
                        <a href="/tags/%E6%89%A9%E5%B1%95bsgs" title="扩展bsgs">
                            扩展bsgs
                        </a>
                        
                        
                        
                        <a href="/tags/%E6%89%A9%E5%B1%95%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E7%AE%97%E6%B3%95" title="扩展欧几里得算法">
                            扩展欧几里得算法
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/%E6%89%AB%E6%8F%8F%E7%BA%BF" title="扫描线">
                            扫描线
                        </a>
                        
                        
                        
                        <a href="/tags/%E6%8A%BD%E5%B1%89%E5%8E%9F%E7%90%86" title="抽屉原理">
                            抽屉原理
                        </a>
                        
                        
                        
                        <a href="/tags/%E6%8B%86%E7%82%B9" title="拆点">
                            拆点
                        </a>
                        
                        
                        
                        <a href="/tags/%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F" title="拓扑排序">
                            拓扑排序
                        </a>
                        
                        
                        
                        <a href="/tags/%E6%8B%AC%E5%8F%B7%E5%8C%B9%E9%85%8D" title="括号匹配">
                            括号匹配
                        </a>
                        
                        
                        
                        <a href="/tags/%E6%8C%87%E6%95%B0%E5%BE%AA%E7%8E%AF%E8%8A%82" title="指数循环节">
                            指数循环节
                        </a>
                        
                        
                        
                        <a href="/tags/%E6%8E%92%E5%88%97%E7%BB%84%E5%90%88" title="排列组合">
                            排列组合
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/%E6%95%B0%E4%BD%8Ddp" title="数位dp">
                            数位dp
                        </a>
                        
                        
                        
                        <a href="/tags/%E6%95%B0%E5%80%BC%E8%AE%A1%E7%AE%97%E6%96%B9%E6%B3%95" title="数值计算方法">
                            数值计算方法
                        </a>
                        
                        
                        
                        <a href="/tags/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86" title="数字图像处理">
                            数字图像处理
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84" title="数据结构">
                            数据结构
                        </a>
                        
                        
                        
                        <a href="/tags/%E6%95%B0%E8%AE%BA" title="数论">
                            数论
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/%E6%96%90%E6%B3%A2%E9%82%A3%E5%A5%91" title="斐波那契">
                            斐波那契
                        </a>
                        
                        
                        
                        <a href="/tags/%E6%96%9C%E7%8E%87%E4%BC%98%E5%8C%96" title="斜率优化">
                            斜率优化
                        </a>
                        
                        
                        
                        <a href="/tags/%E6%97%A0%E5%90%91%E5%9B%BE%E7%9A%84%E7%8E%AF" title="无向图的环">
                            无向图的环
                        </a>
                        
                        
                        
                        <a href="/tags/%E6%9B%BC%E5%93%88%E9%A1%BF%E8%B7%9D%E7%A6%BB" title="曼哈顿距离">
                            曼哈顿距离
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/%E6%9C%80%E5%A4%A7%E8%BF%9E%E7%BB%AD%E5%8C%BA%E9%97%B4%E5%92%8C" title="最大连续区间和">
                            最大连续区间和
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/%E6%9C%80%E5%B0%8F%E7%94%9F%E6%88%90%E6%A0%91" title="最小生成树">
                            最小生成树
                        </a>
                        
                        
                        
                        <a href="/tags/%E6%9C%80%E5%B0%8F%E8%A1%A8%E7%A4%BA%E6%B3%95" title="最小表示法">
                            最小表示法
                        </a>
                        
                        
                        
                        <a href="/tags/%E6%9C%80%E5%B0%8F%E8%A6%86%E7%9B%96%E5%AD%90%E4%B8%B2" title="最小覆盖子串">
                            最小覆盖子串
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/%E6%9C%80%E5%B0%8F%E8%B7%AF%E5%BE%84%E8%A6%86%E7%9B%96" title="最小路径覆盖">
                            最小路径覆盖
                        </a>
                        
                        
                        
                        <a href="/tags/%E6%9C%80%E5%B0%8F%E9%A1%B6%E7%82%B9%E8%A6%86%E7%9B%96" title="最小顶点覆盖">
                            最小顶点覆盖
                        </a>
                        
                        
                        
                        <a href="/tags/%E6%9C%80%E7%9F%AD%E8%B7%AF" title="最短路">
                            最短路
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/%E6%9C%80%E9%95%BF%E5%85%AC%E5%85%B1%E5%AD%97%E4%B8%B2" title="最长公共字串">
                            最长公共字串
                        </a>
                        
                        
                        
                        <a href="/tags/%E6%9C%80%E9%95%BF%E8%B7%AF" title="最长路">
                            最长路
                        </a>
                        
                        
                        
                        <a href="/tags/%E6%9E%84%E9%80%A0" title="构造">
                            构造
                        </a>
                        
                        
                        
                        <a href="/tags/%E6%9E%9A%E4%B8%BE%E5%AD%90%E9%9B%86" title="枚举子集">
                            枚举子集
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/%E6%A0%91%E5%BD%A2dp" title="树形dp">
                            树形dp
                        </a>
                        
                        
                        
                        <a href="/tags/%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84" title="树状数组">
                            树状数组
                        </a>
                        
                        
                        
                        <a href="/tags/%E6%A0%91%E7%9A%84%E7%9B%B4%E5%BE%84" title="树的直径">
                            树的直径
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/%E6%A6%82%E7%8E%87" title="概率">
                            概率
                        </a>
                        
                        
                        
                        <a href="/tags/%E6%A8%A1%E6%8B%9F" title="模拟">
                            模拟
                        </a>
                        
                        
                        
                        <a href="/tags/%E6%A8%A1%E6%8B%9F%E9%80%80%E7%81%AB" title="模拟退火">
                            模拟退火
                        </a>
                        
                        
                        
                        <a href="/tags/%E6%AC%A1%E5%B0%8F%E7%94%9F%E6%88%90%E6%A0%91" title="次小生成树">
                            次小生成树
                        </a>
                        
                        
                        
                        <a href="/tags/%E6%AC%A7%E6%8B%89%E5%87%BD%E6%95%B0" title="欧拉函数">
                            欧拉函数
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/%E6%AF%8D%E5%87%BD%E6%95%B0" title="母函数">
                            母函数
                        </a>
                        
                        
                        
                        <a href="/tags/%E6%B0%B4" title="水">
                            水
                        </a>
                        
                        
                        
                        <a href="/tags/%E6%B0%B4%E9%A2%98" title="水题">
                            水题
                        </a>
                        
                        
                        
                        <a href="/tags/%E6%B3%B0%E5%8B%92%E5%B1%95%E5%BC%80" title="泰勒展开">
                            泰勒展开
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/%E7%88%AC%E8%99%AB" title="爬虫">
                            爬虫
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/%E7%9F%A9%E9%98%B5" title="矩阵">
                            矩阵
                        </a>
                        
                        
                        
                        <a href="/tags/%E7%9F%A9%E9%98%B5%E5%BF%AB%E9%80%9F%E5%B9%82" title="矩阵快速幂">
                            矩阵快速幂
                        </a>
                        
                        
                        
                        <a href="/tags/%E7%A6%BB%E6%95%A3%E5%8C%96" title="离散化">
                            离散化
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/%E7%BA%BF%E6%AE%B5%E6%A0%91" title="线段树">
                            线段树
                        </a>
                        
                        
                        
                        <a href="/tags/%E7%BB%84%E5%90%88%E6%95%B0%E5%AD%A6" title="组合数学">
                            组合数学
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/%E8%8E%AB%E9%98%9F%E7%AE%97%E6%B3%95" title="莫队算法">
                            莫队算法
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/%E8%A3%B4%E8%9C%80%E5%AE%9A%E7%90%86" title="裴蜀定理">
                            裴蜀定理
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/%E8%AE%A1%E6%95%B0%E6%8E%92%E5%BA%8F" title="计数排序">
                            计数排序
                        </a>
                        
                        
                        
                        <a href="/tags/%E8%AE%A1%E6%95%B0%E9%97%AE%E9%A2%98" title="计数问题">
                            计数问题
                        </a>
                        
                        
                        
                        <a href="/tags/%E8%AE%A1%E7%AE%97%E5%87%A0%E4%BD%95" title="计算几何">
                            计算几何
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/%E8%AE%B0%E5%BF%86%E5%8C%96%E6%90%9C%E7%B4%A2" title="记忆化搜索">
                            记忆化搜索
                        </a>
                        
                        
                        
                        <a href="/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F" title="设计模式">
                            设计模式
                        </a>
                        
                        
                        
                        <a href="/tags/%E8%B4%9D%E5%B0%94%E6%95%B0" title="贝尔数">
                            贝尔数
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/%E8%B4%B9%E9%A9%AC%E5%B0%8F%E5%AE%9A%E7%90%86" title="费马小定理">
                            费马小定理
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/%E8%B7%AF%E5%BE%84%E8%AE%B0%E5%BD%95" title="路径记录">
                            路径记录
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/%E8%BE%93%E5%85%A5%E6%8C%82" title="输入挂">
                            输入挂
                        </a>
                        
                        
                        
                        <a href="/tags/%E8%BE%9B%E6%99%AE%E6%A3%AE%E7%A7%AF%E5%88%86" title="辛普森积分">
                            辛普森积分
                        </a>
                        
                        
                        
                        <a href="/tags/%E8%BF%9E%E9%80%9A%E6%80%A7" title="连通性">
                            连通性
                        </a>
                        
                        
                        
                        <a href="/tags/%E9%80%86%E5%85%83" title="逆元">
                            逆元
                        </a>
                        
                        
                        
                        <a href="/tags/%E9%80%86%E5%BA%8F%E5%AF%B9" title="逆序对">
                            逆序对
                        </a>
                        
                        
                        
                        <a href="/tags/%E9%80%92%E6%8E%A8" title="递推">
                            递推
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/%E9%94%99%E6%8E%92%E5%85%AC%E5%BC%8F" title="错排公式">
                            错排公式
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/%E9%AB%98%E7%B2%BE%E5%BA%A6" title="高精度">
                            高精度
                        </a>
                        
                        
                    </div>
                </section>
                

                
                
                <section>
                    <hr>
                    <h5>FRIENDS</h5>
                    <ul class="list-inline">
                        
                        <li><a target="_blank" href="https://111qqz.com">111qqz的wordpress博客</a></li>
                        
                    </ul>
                </section>
                
            </div>
        </div>
    </div>
</article>




<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                   
                   <li>
                       <a href="" rel="alternate" type="application/rss+xml" title="111qqz的小窝" >
                           <span class="fa-stack fa-lg">
                               <i class="fa fa-circle fa-stack-2x"></i>
                               <i class="fa fa-rss fa-stack-1x fa-inverse"></i>
                           </span>
                       </a>
                   </li>
                   
                    
                    <li>
                        <a href="mailto:hust.111qqz@gmail.com">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-envelope fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
		    
                    
                    
                    
                    

                    

		    
                    
                    <li>
                        <a target="_blank" href="/your%20wechat%20qr%20code%20image">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-wechat fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
		    
                    
                    <li>
                        <a target="_blank" href="https://github.com/111qqz/">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
		    
                    
                    <li>
                        <a target="_blank" href="https://www.linkedin.com/in/yourlinkedinid">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-linkedin fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
		    
                    
                </ul>
		<p class="copyright text-muted">
                    Copyright &copy; 111qqz的小窝 2019
                    <br>
                    <a href="https://themes.gohugo.io/hugo-theme-cleanwhite">CleanWhite Hugo Theme</a> by <a href="https://zhaohuabing.com">Huabing</a> |
                    <iframe
                        style="margin-left: 2px; margin-bottom:-5px;"
                        frameborder="0" scrolling="0" width="100px" height="20px"
                        src="https://ghbtns.com/github-btn.html?user=zhaohuabing&repo=hugo-theme-cleanwhite&type=star&count=true" >
                    </iframe>
                </p>
            </div>
        </div>
    </div>
</footer>




<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>






<script>
    
    if($('#tag_cloud').length !== 0){
        async("/js/jquery.tagcloud.js",function(){
            $.fn.tagcloud.defaults = {
                
                color: {start: '#bbbbee', end: '#0085a1'},
            };
            $('#tag_cloud a').tagcloud();
        })
    }
</script>


<script>
    async("https://cdnjs.cloudflare.com/ajax/libs/fastclick/1.0.6/fastclick.js", function(){
        var $nav = document.querySelector("nav");
        if($nav) FastClick.attach($nav);
    })
</script>






</body>
</html>

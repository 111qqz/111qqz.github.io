<!doctype html><html lang=zh-cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta property="og:site_name" content="111qqz的小窝"><meta property="og:type" content="article"><meta property="og:image" content="https://111qqz.github.io/img/2.png"><meta property="twitter:image" content="https://111qqz.github.io/img/2.png"><meta name=title content="caffe 源码学习笔记(6) reshape layer"><meta property="og:title" content="caffe 源码学习笔记(6) reshape layer"><meta property="twitter:title" content="caffe 源码学习笔记(6) reshape layer"><meta name=description content><meta property="og:description" content><meta property="twitter:description" content><meta property="twitter:card" content="summary"><meta name=keyword content="ACM,111qqz,商汤科技,hust,华中科技大学"><link rel="shortcut icon" href=/img/favicon.ico><title>caffe 源码学习笔记(6) reshape layer-111qqz的小窝</title><link rel=canonical href=/2020/04/caffe-source-code-analysis-part6><link rel=stylesheet href=/css/iDisqus.min.css><link rel=stylesheet href=/css/bootstrap.min.css><link rel=stylesheet href=/css/hux-blog.min.css><link rel=stylesheet href=/css/syntax.css><link rel=stylesheet href=/css/zanshang.css><link href=//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css rel=stylesheet type=text/css><script src=/js/jquery.min.js></script><script src=/js/bootstrap.min.js></script><script src=/js/hux-blog.min.js></script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/styles/docco.min.css><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/highlight.min.js></script><script>hljs.initHighlightingOnLoad();</script><link rel=stylesheet href=/css/hux-blog.min.css><link rel=stylesheet href=/css/hux-blog.min-custom.css><script data-ad-client=ca-pub-2010211964550865 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><nav class="navbar navbar-default navbar-custom navbar-fixed-top"><div class=container-fluid><div class="navbar-header page-scroll"><button type=button class=navbar-toggle>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span><span class=icon-bar></span><span class=icon-bar></span></button>
<a class=navbar-brand href=/>111qqz的小窝</a></div><div id=huxblog_navbar><div class=navbar-collapse><ul class="nav navbar-nav navbar-right"><li><a href=/>Home</a></li><li><a href=/categories/acm/>ACM-ICPC</a></li><li><a href=/categories/deep-learning/>深度学习</a></li><li><a href=/categories/mooc/>公开课</a></li><li><a href=/categories/%e5%85%b6%e4%bb%96/>其他</a></li><li><a href=/top/about/>ABOUT</a></li><li><a href=/search>SEARCH <img src=/img/search.png height=15 style=cursor:pointer alt=Search></a></li></ul></div></div></div></nav><script>var $body=document.body;var $toggle=document.querySelector('.navbar-toggle');var $navbar=document.querySelector('#huxblog_navbar');var $collapse=document.querySelector('.navbar-collapse');$toggle.addEventListener('click',handleMagic)
function handleMagic(e){if($navbar.className.indexOf('in')>0){$navbar.className=" ";setTimeout(function(){if($navbar.className.indexOf('in')<0){$collapse.style.height="0px"}},400)}else{$collapse.style.height="auto"
$navbar.className+=" in";}}</script><style type=text/css>header.intro-header{background-image:url(/img/2.png)}</style><header class=intro-header><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class=post-heading><div class=tags><a class=tag href=/tags/caffe title=caffe>caffe</a></div><h1>caffe 源码学习笔记(6) reshape layer</h1><h2 class=subheading></h2><span class=meta>Posted by
111qqz
on
Thursday, April 9, 2020
<span id=/2020/04/caffe-source-code-analysis-part6 class="leancloud_visitors meta_data_item" data-flag-title><span class=post-meta-item-icon><span class="octicon octicon-eye"></span></span><i class="fa fa-eye"></i><span class=old-visitors-count style=display:none></span><span class=leancloud-visitors-count></span></span><script src=https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js></script><script>AV.initialize("UzhnsgbPvx1RFb2kNXUHpPtf-gzGzoHsz","OXOvoYGuwMv70Os5GOgaGEWT");</script><script type=text/javascript>function showTime(Counter){var query=new AV.Query(Counter);var entries=[];var $visitors=$(".leancloud_visitors");console.log("aaa")
$visitors.each(function(){entries.push($(this).attr("id").trim());});query.containedIn('url',entries);query.find().done(function(results){var COUNT_CONTAINER_REF='.leancloud-visitors-count';var OLD_COUNT_CONTAINER_REF='.old-visitors-count';for(var i=0;i<results.length;i++){var item=results[i];var url=item.get('url');var time=item.get('time');var element=document.getElementById(url);$(element).find(COUNT_CONTAINER_REF).text(time);}
for(var i=0;i<entries.length;i++){var url=entries[i];var element=document.getElementById(url);var countSpan=$(element).find(COUNT_CONTAINER_REF);if(countSpan.text()==''){var oldCountSpan=$(element).find(OLD_COUNT_CONTAINER_REF).text();if(oldCountSpan!=''){countSpan.text(0+parseInt(oldCountSpan));}else{countSpan.text(0);}}}}).fail(function(object,error){console.log("Error: "+error.code+" "+error.message);});}
function addCount(Counter){var $visitors=$(".leancloud_visitors");var url=$visitors.attr('id').trim();var title=$visitors.attr('data-flag-title').trim();var query=new AV.Query(Counter);con
query.equalTo("url",url);query.find({success:function(results){if(results.length>0){var counter=results[0];counter.fetchWhenSave(true);counter.increment("time");counter.save(null,{success:function(counter){var $element=$(document.getElementById(url));$element.find('.leancloud-visitors-count').text(counter.get('time'));},error:function(counter,error){console.log('Failed to save Visitor num, with error message: '+error.message);}});}else{var newcounter=new Counter();var acl=new AV.ACL();acl.setPublicReadAccess(true);acl.setPublicWriteAccess(true);newcounter.setACL(acl);newcounter.set("title",title);newcounter.set("url",url);var OLD_COUNT_CONTAINER_REF='.old-visitors-count';var $element=$(document.getElementById(url));var oldCountSpan=$element.find(OLD_COUNT_CONTAINER_REF).text();if(oldCountSpan!=''){newcounter.set("time",parseInt(oldCountSpan)+1);}else{newcounter.set("time",1);}
newcounter.save(null,{success:function(newcounter){var $element=$(document.getElementById(url));$element.find('.leancloud-visitors-count').text(newcounter.get('time'));},error:function(newcounter,error){console.log('Failed to create');}});}},error:function(error){console.log('Error:'+error.code+" "+error.message);}});}
$(function(){var Counter=AV.Object.extend("Counter");console.log("miao miao miao")
if($('.leancloud_visitors').length==1){addCount(Counter);}else{showTime(Counter);}});</script></span></div></div></div></div></header><article><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2
col-md-10 col-md-offset-1
post-container"><header><h2>TOC</h2></header><nav id=TableOfContents><ol><li><a href=#背景>背景　</a></li><li><a href=#proto>proto</a></li><li><a href=#c实现>c++实现</a></li></ol></nav><h2 id=背景>背景　</h2><p>最近在魔改 tensorRT 的caffe parser
之前caffe模型转到trt模型时，有一个修改是需要将reshape　layer的param末尾补1,比较繁琐，于是看了下caffe的reshape layer的实现．</p><h2 id=proto>proto</h2><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-protobuf data-lang=protobuf><span style=color:#960050;background-color:#1e0010>
</span><span style=color:#960050;background-color:#1e0010></span><span style=color:#66d9ef>message</span> <span style=color:#a6e22e>ReshapeParameter</span> {<span style=color:#960050;background-color:#1e0010>
</span><span style=color:#960050;background-color:#1e0010></span>  <span style=color:#75715e>// Specify the output dimensions. If some of the dimensions are set to 0,
</span><span style=color:#75715e></span>  <span style=color:#75715e>// the corresponding dimension from the bottom layer is used (unchanged).
</span><span style=color:#75715e></span>  <span style=color:#75715e>// Exactly one dimension may be set to -1, in which case its value is
</span><span style=color:#75715e></span>  <span style=color:#75715e>// inferred from the count of the bottom blob and the remaining dimensions.
</span><span style=color:#75715e></span>  <span style=color:#75715e>// For example, suppose we want to reshape a 2D blob &#34;input&#34; with shape 2 x 8:
</span><span style=color:#75715e></span>  <span style=color:#75715e>//
</span><span style=color:#75715e></span>  <span style=color:#75715e>//   layer {
</span><span style=color:#75715e></span>  <span style=color:#75715e>//     type: &#34;Reshape&#34; bottom: &#34;input&#34; top: &#34;output&#34;
</span><span style=color:#75715e></span>  <span style=color:#75715e>//     reshape_param { ... }
</span><span style=color:#75715e></span>  <span style=color:#75715e>//   }
</span><span style=color:#75715e></span>  <span style=color:#75715e>//
</span><span style=color:#75715e></span>  <span style=color:#75715e>// If &#34;input&#34; is 2D with shape 2 x 8, then the following reshape_param
</span><span style=color:#75715e></span>  <span style=color:#75715e>// specifications are all equivalent, producing a 3D blob &#34;output&#34; with shape
</span><span style=color:#75715e></span>  <span style=color:#75715e>// 2 x 2 x 4:
</span><span style=color:#75715e></span>  <span style=color:#75715e>//
</span><span style=color:#75715e></span>  <span style=color:#75715e>//   reshape_param { shape { dim:  2  dim: 2  dim:  4 } }
</span><span style=color:#75715e></span>  <span style=color:#75715e>//   reshape_param { shape { dim:  0  dim: 2  dim:  4 } }
</span><span style=color:#75715e></span>  <span style=color:#75715e>//   reshape_param { shape { dim:  0  dim: 2  dim: -1 } }
</span><span style=color:#75715e></span>  <span style=color:#75715e>//   reshape_param { shape { dim:  0  dim:-1  dim:  4 } }
</span><span style=color:#75715e></span>  <span style=color:#75715e>//
</span><span style=color:#75715e></span>  <span style=color:#66d9ef>optional</span> BlobShape shape <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>;<span style=color:#960050;background-color:#1e0010>
</span><span style=color:#960050;background-color:#1e0010></span><span style=color:#960050;background-color:#1e0010>
</span><span style=color:#960050;background-color:#1e0010></span>  <span style=color:#75715e>// axis and num_axes control the portion of the bottom blob&#39;s shape that are
</span><span style=color:#75715e></span>  <span style=color:#75715e>// replaced by (included in) the reshape. By default (axis == 0 and
</span><span style=color:#75715e></span>  <span style=color:#75715e>// num_axes == -1), the entire bottom blob shape is included in the reshape,
</span><span style=color:#75715e></span>  <span style=color:#75715e>// and hence the shape field must specify the entire output shape.
</span><span style=color:#75715e></span>  <span style=color:#75715e>//
</span><span style=color:#75715e></span>  <span style=color:#75715e>// axis may be non-zero to retain some portion of the beginning of the input
</span><span style=color:#75715e></span>  <span style=color:#75715e>// shape (and may be negative to index from the end; e.g., -1 to begin the
</span><span style=color:#75715e></span>  <span style=color:#75715e>// reshape after the last axis, including nothing in the reshape,
</span><span style=color:#75715e></span>  <span style=color:#75715e>// -2 to include only the last axis, etc.).
</span><span style=color:#75715e></span>  <span style=color:#75715e>//
</span><span style=color:#75715e></span>  <span style=color:#75715e>// For example, suppose &#34;input&#34; is a 2D blob with shape 2 x 8.
</span><span style=color:#75715e></span>  <span style=color:#75715e>// Then the following ReshapeLayer specifications are all equivalent,
</span><span style=color:#75715e></span>  <span style=color:#75715e>// producing a blob &#34;output&#34; with shape 2 x 2 x 4:
</span><span style=color:#75715e></span>  <span style=color:#75715e>//
</span><span style=color:#75715e></span>  <span style=color:#75715e>//   reshape_param { shape { dim: 2  dim: 2  dim: 4 } }
</span><span style=color:#75715e></span>  <span style=color:#75715e>//   reshape_param { shape { dim: 2  dim: 4 } axis:  1 }
</span><span style=color:#75715e></span>  <span style=color:#75715e>//   reshape_param { shape { dim: 2  dim: 4 } axis: -3 }
</span><span style=color:#75715e></span>  <span style=color:#75715e>//
</span><span style=color:#75715e></span>  <span style=color:#75715e>// num_axes specifies the extent of the reshape.
</span><span style=color:#75715e></span>  <span style=color:#75715e>// If num_axes &gt;= 0 (and axis &gt;= 0), the reshape will be performed only on
</span><span style=color:#75715e></span>  <span style=color:#75715e>// input axes in the range [axis, axis+num_axes].
</span><span style=color:#75715e></span>  <span style=color:#75715e>// num_axes may also be -1, the default, to include all remaining axes
</span><span style=color:#75715e></span>  <span style=color:#75715e>// (starting from axis).
</span><span style=color:#75715e></span>  <span style=color:#75715e>//
</span><span style=color:#75715e></span>  <span style=color:#75715e>// For example, suppose &#34;input&#34; is a 2D blob with shape 2 x 8.
</span><span style=color:#75715e></span>  <span style=color:#75715e>// Then the following ReshapeLayer specifications are equivalent,
</span><span style=color:#75715e></span>  <span style=color:#75715e>// producing a blob &#34;output&#34; with shape 1 x 2 x 8.
</span><span style=color:#75715e></span>  <span style=color:#75715e>//
</span><span style=color:#75715e></span>  <span style=color:#75715e>//   reshape_param { shape { dim:  1  dim: 2  dim:  8 } }
</span><span style=color:#75715e></span>  <span style=color:#75715e>//   reshape_param { shape { dim:  1  dim: 2  }  num_axes: 1 }
</span><span style=color:#75715e></span>  <span style=color:#75715e>//   reshape_param { shape { dim:  1  }  num_axes: 0 }
</span><span style=color:#75715e></span>  <span style=color:#75715e>//
</span><span style=color:#75715e></span>  <span style=color:#75715e>// On the other hand, these would produce output blob shape 2 x 1 x 8:
</span><span style=color:#75715e></span>  <span style=color:#75715e>//
</span><span style=color:#75715e></span>  <span style=color:#75715e>//   reshape_param { shape { dim: 2  dim: 1  dim: 8  }  }
</span><span style=color:#75715e></span>  <span style=color:#75715e>//   reshape_param { shape { dim: 1 }  axis: 1  num_axes: 0 }
</span><span style=color:#75715e></span>  <span style=color:#75715e>//
</span><span style=color:#75715e></span>  <span style=color:#66d9ef>optional</span> <span style=color:#66d9ef>int32</span> axis <span style=color:#f92672>=</span> <span style=color:#ae81ff>2</span> [<span style=color:#66d9ef>default</span> <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>];<span style=color:#960050;background-color:#1e0010>
</span><span style=color:#960050;background-color:#1e0010></span>  <span style=color:#66d9ef>optional</span> <span style=color:#66d9ef>int32</span> num_axes <span style=color:#f92672>=</span> <span style=color:#ae81ff>3</span> [<span style=color:#66d9ef>default</span> <span style=color:#f92672>=</span> <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>];<span style=color:#960050;background-color:#1e0010>
</span><span style=color:#960050;background-color:#1e0010></span>}<span style=color:#960050;background-color:#1e0010>
</span><span style=color:#960050;background-color:#1e0010></span><span style=color:#960050;background-color:#1e0010>
</span></code></pre></div><p>emmm,是不是稍微复杂了点．．　其实主要复杂在两个可选参数axis和num_axes上．　
如果不考虑这两个参数，那么　reshape的维度只有两点需要注意．一个是0表示该维度不变，一个是-1表示该维度是需要推断出来．</p><blockquote><p>0 means “copy the respective dimension of the bottom layer”. That is, if the bottom has 2 as its 1st dimension, the top will have 2 as its 1st dimension as well, given dim: 0 as the 1st target dimension.</p></blockquote><blockquote><p>-1 stands for “infer this from the other dimensions”. This behavior is similar to that of -1 in numpy’s or [] for MATLAB’s reshape: this dimension is calculated to keep the overall element count the same as in the bottom layer. At most one -1 can be used in a reshape operation.</p></blockquote><p>然后axis和num_axes两个参数可以一起看．</p><p>其实就是表示只对输入维度的[axis, axis+num_axes]做reshape,其他维护维持现状．</p><p>不过axis的使用例子写错了，所以弄得有些费解,还是看了代码才弄清楚．给caffe提了个pr <a href=https://github.com/BVLC/caffe/pull/6936>fix an error of axis parameter in the example of ReshapeParameter #6936</a> 能不能merge随缘吧2333</p><p>然后还有两个case，其一是num_axes的默认情况，表示要处理"all remaining axes&rdquo;
另外一个是axis为负数，此时不使用num_axes　参数</p><p>值得一提的是</p><blockquote><p>specifying reshape_param { shape { dim: 0 dim: -1 } } makes the layer behave in exactly the same way as the Flatten layer.</p></blockquote><h2 id=c实现>c++实现</h2><p>先看 LayerSetUp. 我们似乎很少关注layer的这部分．．原因是大部分layer这部分其实都没什么好关注的</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c++ data-lang=c++>
<span style=color:#66d9ef>template</span> <span style=color:#f92672>&lt;</span><span style=color:#66d9ef>typename</span> Dtype<span style=color:#f92672>&gt;</span>
<span style=color:#66d9ef>void</span> ReshapeLayer<span style=color:#f92672>&lt;</span>Dtype<span style=color:#f92672>&gt;</span><span style=color:#f92672>:</span><span style=color:#f92672>:</span>LayerSetUp(<span style=color:#66d9ef>const</span> vector<span style=color:#f92672>&lt;</span>Blob<span style=color:#f92672>&lt;</span>Dtype<span style=color:#f92672>&gt;</span><span style=color:#f92672>*</span><span style=color:#f92672>&gt;</span><span style=color:#f92672>&amp;</span> bottom,
    <span style=color:#66d9ef>const</span> vector<span style=color:#f92672>&lt;</span>Blob<span style=color:#f92672>&lt;</span>Dtype<span style=color:#f92672>&gt;</span><span style=color:#f92672>*</span><span style=color:#f92672>&gt;</span><span style=color:#f92672>&amp;</span> top) {
  CHECK_NE(top[<span style=color:#ae81ff>0</span>], bottom[<span style=color:#ae81ff>0</span>]) <span style=color:#f92672>&lt;</span><span style=color:#f92672>&lt;</span> <span style=color:#66d9ef>this</span><span style=color:#f92672>-</span><span style=color:#f92672>&gt;</span>type() <span style=color:#f92672>&lt;</span><span style=color:#f92672>&lt;</span> <span style=color:#e6db74></span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74> Layer does not </span><span style=color:#e6db74>&#34;</span>
      <span style=color:#e6db74></span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>allow in-place computation.</span><span style=color:#e6db74>&#34;</span>;
  inferred_axis_ <span style=color:#f92672>=</span> <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>;
  copy_axes_.clear();
  <span style=color:#66d9ef>const</span> BlobShape<span style=color:#f92672>&amp;</span> top_blob_shape <span style=color:#f92672>=</span> <span style=color:#66d9ef>this</span><span style=color:#f92672>-</span><span style=color:#f92672>&gt;</span>layer_param_.reshape_param().shape();
  <span style=color:#66d9ef>const</span> <span style=color:#66d9ef>int</span> top_num_axes <span style=color:#f92672>=</span> top_blob_shape.dim_size();
  constant_count_ <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>;
  <span style=color:#66d9ef>for</span> (<span style=color:#66d9ef>int</span> i <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; i <span style=color:#f92672>&lt;</span> top_num_axes; <span style=color:#f92672>+</span><span style=color:#f92672>+</span>i) {
    <span style=color:#66d9ef>const</span> <span style=color:#66d9ef>int</span> top_dim <span style=color:#f92672>=</span> top_blob_shape.dim(i);
    <span style=color:#66d9ef>if</span> (top_dim <span style=color:#f92672>=</span><span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>) {
      copy_axes_.push_back(i);
    } <span style=color:#66d9ef>else</span> <span style=color:#a6e22e>if</span> (top_dim <span style=color:#f92672>=</span><span style=color:#f92672>=</span> <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>) {
      CHECK_EQ(inferred_axis_, <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>) <span style=color:#f92672>&lt;</span><span style=color:#f92672>&lt;</span> <span style=color:#e6db74></span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>new shape contains multiple </span><span style=color:#e6db74>&#34;</span>
          <span style=color:#f92672>&lt;</span><span style=color:#f92672>&lt;</span> <span style=color:#e6db74></span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>-1 dims; at most a single (1) value of -1 may be specified</span><span style=color:#e6db74>&#34;</span>;
      inferred_axis_ <span style=color:#f92672>=</span> i;
    } <span style=color:#66d9ef>else</span> {
      constant_count_ <span style=color:#f92672>*</span><span style=color:#f92672>=</span> top_dim;
    }
  }
}

</code></pre></div><p>特殊处理了dim为0和-1的情况，然后把需要变换的维度count放在constant_count_，盲猜是之后做推断用．</p><p>接下来我们看下Reshape</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c++ data-lang=c++><span style=color:#66d9ef>template</span> <span style=color:#f92672>&lt;</span><span style=color:#66d9ef>typename</span> Dtype<span style=color:#f92672>&gt;</span>
<span style=color:#66d9ef>void</span> ReshapeLayer<span style=color:#f92672>&lt;</span>Dtype<span style=color:#f92672>&gt;</span><span style=color:#f92672>:</span><span style=color:#f92672>:</span>Reshape(<span style=color:#66d9ef>const</span> vector<span style=color:#f92672>&lt;</span>Blob<span style=color:#f92672>&lt;</span>Dtype<span style=color:#f92672>&gt;</span><span style=color:#f92672>*</span><span style=color:#f92672>&gt;</span><span style=color:#f92672>&amp;</span> bottom,
    <span style=color:#66d9ef>const</span> vector<span style=color:#f92672>&lt;</span>Blob<span style=color:#f92672>&lt;</span>Dtype<span style=color:#f92672>&gt;</span><span style=color:#f92672>*</span><span style=color:#f92672>&gt;</span><span style=color:#f92672>&amp;</span> top) {
  <span style=color:#66d9ef>const</span> <span style=color:#66d9ef>int</span> input_start_axis <span style=color:#f92672>=</span> <span style=color:#66d9ef>this</span><span style=color:#f92672>-</span><span style=color:#f92672>&gt;</span>layer_param_.reshape_param().axis();
  <span style=color:#66d9ef>const</span> <span style=color:#66d9ef>int</span> start_axis <span style=color:#f92672>=</span> (input_start_axis <span style=color:#f92672>&gt;</span><span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>) <span style=color:#f92672>?</span> input_start_axis :
      bottom[<span style=color:#ae81ff>0</span>]<span style=color:#f92672>-</span><span style=color:#f92672>&gt;</span>num_axes() <span style=color:#f92672>+</span> input_start_axis <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>;
  CHECK_GE(start_axis, <span style=color:#ae81ff>0</span>) <span style=color:#f92672>&lt;</span><span style=color:#f92672>&lt;</span> <span style=color:#e6db74></span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>axis </span><span style=color:#e6db74>&#34;</span> <span style=color:#f92672>&lt;</span><span style=color:#f92672>&lt;</span> input_start_axis <span style=color:#f92672>&lt;</span><span style=color:#f92672>&lt;</span> <span style=color:#e6db74></span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74> out of range</span><span style=color:#e6db74>&#34;</span>;
  CHECK_LE(start_axis, bottom[<span style=color:#ae81ff>0</span>]<span style=color:#f92672>-</span><span style=color:#f92672>&gt;</span>num_axes()) <span style=color:#f92672>&lt;</span><span style=color:#f92672>&lt;</span> <span style=color:#e6db74></span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>axis </span><span style=color:#e6db74>&#34;</span> <span style=color:#f92672>&lt;</span><span style=color:#f92672>&lt;</span> input_start_axis
      <span style=color:#f92672>&lt;</span><span style=color:#f92672>&lt;</span> <span style=color:#e6db74></span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74> out of range for </span><span style=color:#e6db74>&#34;</span> <span style=color:#f92672>&lt;</span><span style=color:#f92672>&lt;</span> bottom[<span style=color:#ae81ff>0</span>]<span style=color:#f92672>-</span><span style=color:#f92672>&gt;</span>num_axes() <span style=color:#f92672>&lt;</span><span style=color:#f92672>&lt;</span> <span style=color:#e6db74></span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>-D input blob</span><span style=color:#e6db74>&#34;</span>;
  <span style=color:#66d9ef>const</span> <span style=color:#66d9ef>int</span> num_axes <span style=color:#f92672>=</span> <span style=color:#66d9ef>this</span><span style=color:#f92672>-</span><span style=color:#f92672>&gt;</span>layer_param_.reshape_param().num_axes();
  CHECK_GE(num_axes, <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>) <span style=color:#f92672>&lt;</span><span style=color:#f92672>&lt;</span> <span style=color:#e6db74></span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>num_axes must be &gt;= 0, or -1 for all</span><span style=color:#e6db74>&#34;</span>;
  <span style=color:#66d9ef>const</span> <span style=color:#66d9ef>int</span> end_axis <span style=color:#f92672>=</span>
      (num_axes <span style=color:#f92672>=</span><span style=color:#f92672>=</span> <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>) <span style=color:#f92672>?</span> bottom[<span style=color:#ae81ff>0</span>]<span style=color:#f92672>-</span><span style=color:#f92672>&gt;</span>num_axes() <span style=color:#f92672>:</span> (start_axis <span style=color:#f92672>+</span> num_axes);
  CHECK_LE(end_axis, bottom[<span style=color:#ae81ff>0</span>]<span style=color:#f92672>-</span><span style=color:#f92672>&gt;</span>num_axes())
      <span style=color:#f92672>&lt;</span><span style=color:#f92672>&lt;</span> <span style=color:#e6db74></span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>end_axis = axis + num_axes is out of range</span><span style=color:#e6db74>&#34;</span>;
  <span style=color:#66d9ef>const</span> <span style=color:#66d9ef>int</span> num_axes_replaced <span style=color:#f92672>=</span> end_axis <span style=color:#f92672>-</span> start_axis;
  <span style=color:#66d9ef>const</span> <span style=color:#66d9ef>int</span> num_axes_retained <span style=color:#f92672>=</span> bottom[<span style=color:#ae81ff>0</span>]<span style=color:#f92672>-</span><span style=color:#f92672>&gt;</span>num_axes() <span style=color:#f92672>-</span> num_axes_replaced;
  <span style=color:#66d9ef>const</span> BlobShape<span style=color:#f92672>&amp;</span> top_blob_shape <span style=color:#f92672>=</span> <span style=color:#66d9ef>this</span><span style=color:#f92672>-</span><span style=color:#f92672>&gt;</span>layer_param_.reshape_param().shape();
  <span style=color:#66d9ef>const</span> <span style=color:#66d9ef>int</span> num_new_axes <span style=color:#f92672>=</span> top_blob_shape.dim_size();
  vector<span style=color:#f92672>&lt;</span><span style=color:#66d9ef>int</span><span style=color:#f92672>&gt;</span> top_shape(num_axes_retained <span style=color:#f92672>+</span> num_new_axes);
  <span style=color:#66d9ef>int</span> top_shape_index <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>;
  <span style=color:#66d9ef>for</span> (<span style=color:#66d9ef>int</span> i <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; i <span style=color:#f92672>&lt;</span> start_axis; <span style=color:#f92672>+</span><span style=color:#f92672>+</span>i) {
    top_shape[top_shape_index<span style=color:#f92672>+</span><span style=color:#f92672>+</span>] <span style=color:#f92672>=</span> bottom[<span style=color:#ae81ff>0</span>]<span style=color:#f92672>-</span><span style=color:#f92672>&gt;</span>shape(i);
  }
  <span style=color:#66d9ef>for</span> (<span style=color:#66d9ef>int</span> i <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; i <span style=color:#f92672>&lt;</span> num_new_axes; <span style=color:#f92672>+</span><span style=color:#f92672>+</span>i) {
    top_shape[top_shape_index<span style=color:#f92672>+</span><span style=color:#f92672>+</span>] <span style=color:#f92672>=</span> top_blob_shape.dim(i);
  }
  <span style=color:#66d9ef>for</span> (<span style=color:#66d9ef>int</span> i <span style=color:#f92672>=</span> end_axis; i <span style=color:#f92672>&lt;</span> bottom[<span style=color:#ae81ff>0</span>]<span style=color:#f92672>-</span><span style=color:#f92672>&gt;</span>num_axes(); <span style=color:#f92672>+</span><span style=color:#f92672>+</span>i) {
    top_shape[top_shape_index<span style=color:#f92672>+</span><span style=color:#f92672>+</span>] <span style=color:#f92672>=</span> bottom[<span style=color:#ae81ff>0</span>]<span style=color:#f92672>-</span><span style=color:#f92672>&gt;</span>shape(i);
  }
  CHECK_EQ(top_shape_index, top_shape.size());
  <span style=color:#66d9ef>for</span> (<span style=color:#66d9ef>int</span> i <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; i <span style=color:#f92672>&lt;</span> copy_axes_.size(); <span style=color:#f92672>+</span><span style=color:#f92672>+</span>i) {
    <span style=color:#66d9ef>const</span> <span style=color:#66d9ef>int</span> copy_axis_index <span style=color:#f92672>=</span> copy_axes_[i];
    CHECK_GT(bottom[<span style=color:#ae81ff>0</span>]<span style=color:#f92672>-</span><span style=color:#f92672>&gt;</span>num_axes(), start_axis <span style=color:#f92672>+</span> copy_axis_index)
        <span style=color:#f92672>&lt;</span><span style=color:#f92672>&lt;</span> <span style=color:#e6db74></span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>new shape contains a 0, but there was no corresponding bottom axis </span><span style=color:#e6db74>&#34;</span>
        <span style=color:#f92672>&lt;</span><span style=color:#f92672>&lt;</span> <span style=color:#e6db74></span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>to copy</span><span style=color:#e6db74>&#34;</span>;
    top_shape[start_axis <span style=color:#f92672>+</span> copy_axis_index] <span style=color:#f92672>=</span>
        bottom[<span style=color:#ae81ff>0</span>]<span style=color:#f92672>-</span><span style=color:#f92672>&gt;</span>shape(start_axis <span style=color:#f92672>+</span> copy_axis_index);
  }
  <span style=color:#66d9ef>if</span> (inferred_axis_ <span style=color:#f92672>&gt;</span><span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>) {
    <span style=color:#75715e>// A -1 dim was specified; infer the correct dimension by computing the
</span><span style=color:#75715e></span>    <span style=color:#75715e>// product of the other dimensions.
</span><span style=color:#75715e></span>    <span style=color:#66d9ef>int</span> explicit_count <span style=color:#f92672>=</span> constant_count_;
    explicit_count <span style=color:#f92672>*</span><span style=color:#f92672>=</span> bottom[<span style=color:#ae81ff>0</span>]<span style=color:#f92672>-</span><span style=color:#f92672>&gt;</span>count(<span style=color:#ae81ff>0</span>, start_axis);
    explicit_count <span style=color:#f92672>*</span><span style=color:#f92672>=</span> bottom[<span style=color:#ae81ff>0</span>]<span style=color:#f92672>-</span><span style=color:#f92672>&gt;</span>count(end_axis);
    <span style=color:#66d9ef>for</span> (<span style=color:#66d9ef>int</span> i <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; i <span style=color:#f92672>&lt;</span> copy_axes_.size(); <span style=color:#f92672>+</span><span style=color:#f92672>+</span>i) {
      <span style=color:#66d9ef>const</span> <span style=color:#66d9ef>int</span> copy_axis_index <span style=color:#f92672>=</span> copy_axes_[i];
      explicit_count <span style=color:#f92672>*</span><span style=color:#f92672>=</span> top_shape[start_axis <span style=color:#f92672>+</span> copy_axis_index];
    }
    CHECK_EQ(<span style=color:#ae81ff>0</span>, bottom[<span style=color:#ae81ff>0</span>]<span style=color:#f92672>-</span><span style=color:#f92672>&gt;</span>count() <span style=color:#f92672>%</span> explicit_count) <span style=color:#f92672>&lt;</span><span style=color:#f92672>&lt;</span> <span style=color:#e6db74></span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>bottom count (</span><span style=color:#e6db74>&#34;</span>
        <span style=color:#f92672>&lt;</span><span style=color:#f92672>&lt;</span> bottom[<span style=color:#ae81ff>0</span>]<span style=color:#f92672>-</span><span style=color:#f92672>&gt;</span>count() <span style=color:#f92672>&lt;</span><span style=color:#f92672>&lt;</span> <span style=color:#e6db74></span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>) must be divisible by the product of </span><span style=color:#e6db74>&#34;</span>
        <span style=color:#f92672>&lt;</span><span style=color:#f92672>&lt;</span> <span style=color:#e6db74></span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>the specified dimensions (</span><span style=color:#e6db74>&#34;</span> <span style=color:#f92672>&lt;</span><span style=color:#f92672>&lt;</span> explicit_count <span style=color:#f92672>&lt;</span><span style=color:#f92672>&lt;</span> <span style=color:#e6db74></span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>)</span><span style=color:#e6db74>&#34;</span>;
    <span style=color:#66d9ef>const</span> <span style=color:#66d9ef>int</span> inferred_dim <span style=color:#f92672>=</span> bottom[<span style=color:#ae81ff>0</span>]<span style=color:#f92672>-</span><span style=color:#f92672>&gt;</span>count() <span style=color:#f92672>/</span> explicit_count;
    top_shape[start_axis <span style=color:#f92672>+</span> inferred_axis_] <span style=color:#f92672>=</span> inferred_dim;
  }
  top[<span style=color:#ae81ff>0</span>]<span style=color:#f92672>-</span><span style=color:#f92672>&gt;</span>Reshape(top_shape);
  CHECK_EQ(top[<span style=color:#ae81ff>0</span>]<span style=color:#f92672>-</span><span style=color:#f92672>&gt;</span>count(), bottom[<span style=color:#ae81ff>0</span>]<span style=color:#f92672>-</span><span style=color:#f92672>&gt;</span>count())
      <span style=color:#f92672>&lt;</span><span style=color:#f92672>&lt;</span> <span style=color:#e6db74></span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>output count must match input count</span><span style=color:#e6db74>&#34;</span>;
  top[<span style=color:#ae81ff>0</span>]<span style=color:#f92672>-</span><span style=color:#f92672>&gt;</span>ShareData(<span style=color:#f92672>*</span>bottom[<span style=color:#ae81ff>0</span>]);
  top[<span style=color:#ae81ff>0</span>]<span style=color:#f92672>-</span><span style=color:#f92672>&gt;</span>ShareDiff(<span style=color:#f92672>*</span>bottom[<span style=color:#ae81ff>0</span>]);
}

INSTANTIATE_CLASS(ReshapeLayer);
REGISTER_LAYER_CLASS(Reshape);

}  <span style=color:#75715e>// namespace caffe
</span><span style=color:#75715e></span>
</code></pre></div><p>代码似乎有些长，实际上很简单．后半部分是推断维度的，前半部分也很直观，就是做了比较多的check．</p><p>然后Reshape Layer是没有Forward函数的，因为没有做任何计算，只是改变了blob的reshape,也不存在数据的拷贝．</p><hr><ul class=pager><li class=previous><a href=/2020/04/caffe-source-code-analysis-part5 data-toggle=tooltip data-placement=top title="caffe 源码学习笔记(5) 卷积">&larr;
Previous Post</a></li><li class=next><a href=/2020/04/Install-nvidia-Driver-on-Thinkpad-T430-Manjaro data-toggle=tooltip data-placement=top title="thinkpad t430 manjaro系统安装nvidia驱动">Next
Post &rarr;</a></li></ul><div class=post-comment><span id=/2020/04/caffe-source-code-analysis-part6 class=leancloud_visitors data-flag-title="caffe 源码学习笔记(6) reshape layer"><span class=post-meta-item-text>访问量 "/2020/04/caffe-source-code-analysis-part6"</span>
<span class=leancloud-visitors-count></span><p></p></span><div id=vcomments></div><script src=//cdn1.lncld.net/static/js/3.0.4/av-min.js></script><script src=//unpkg.com/valine/dist/Valine.min.js></script><script type=text/javascript>new Valine({el:'#vcomments',appId:'UzhnsgbPvx1RFb2kNXUHpPtf-gzGzoHsz',appKey:'OXOvoYGuwMv70Os5GOgaGEWT',notify:true,verify:false,avatar:'retro',placeholder:'说点什么吧...',visitor:true});</script></div></div><div class="col-lg-8 col-lg-offset-2
col-md-10 col-md-offset-1
sidebar-container"><section><hr class="hidden-sm hidden-xs"><h5><a href=/tags/>FEATURED TAGS</a></h5><div class=tags><a href=/tags/bfs title=bfs>bfs</a>
<a href=/tags/binary-search title=binary-search>binary-search</a>
<a href=/tags/brute-force title=brute-force>brute-force</a>
<a href=/tags/dfs title=dfs>dfs</a>
<a href=/tags/dp title=dp>dp</a>
<a href=/tags/greedy title=greedy>greedy</a>
<a href=/tags/kmp title=kmp>kmp</a>
<a href=/tags/leetcode title=leetcode>leetcode</a>
<a href=/tags/math title=math>math</a>
<a href=/tags/number-theory title=number-theory>number-theory</a>
<a href=/tags/rmq title=rmq>rmq</a>
<a href=/tags/stl title=stl>stl</a>
<a href=/tags/%E5%89%8D%E7%BC%80%E5%92%8C title=前缀和>前缀和</a>
<a href=/tags/%E5%8D%9A%E5%BC%88%E8%AE%BA title=博弈论>博弈论</a>
<a href=/tags/%E5%9B%BE%E8%AE%BA title=图论>图论</a>
<a href=/tags/%E5%BF%AB%E9%80%9F%E5%B9%82 title=快速幂>快速幂</a>
<a href=/tags/%E6%95%B0%E4%BD%8Ddp title=数位dp>数位dp</a>
<a href=/tags/%E6%9E%84%E9%80%A0 title=构造>构造</a>
<a href=/tags/%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84 title=树状数组>树状数组</a>
<a href=/tags/%E6%A8%A1%E6%8B%9F title=模拟>模拟</a>
<a href=/tags/%E6%AF%8D%E5%87%BD%E6%95%B0 title=母函数>母函数</a>
<a href=/tags/%E7%9F%A9%E9%98%B5 title=矩阵>矩阵</a>
<a href=/tags/%E7%BA%BF%E6%AE%B5%E6%A0%91 title=线段树>线段树</a>
<a href=/tags/%E8%AE%A1%E7%AE%97%E5%87%A0%E4%BD%95 title=计算几何>计算几何</a></div></section><section><hr><h5>FRIENDS</h5><ul class=list-inline><li><a target=_blank href=https://111qqz.com>111qqz的wordpress博客</a></li></ul></section></div></div></div></article><footer><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><ul class="list-inline text-center"><li><a href rel=alternate type=application/rss+xml title=111qqz的小窝><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-rss fa-stack-1x fa-inverse"></i></span></a></li><li><a href=mailto:hust.111qqz@gmail.com><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-envelope fa-stack-1x fa-inverse"></i></span></a></li><li><a target=_blank href=/img/wechat.jpg><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-wechat fa-stack-1x fa-inverse"></i></span></a></li><li><a target=_blank href=https://github.com/111qqz/><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-github fa-stack-1x fa-inverse"></i></span></a></li></ul><p class="copyright text-muted">Copyright &copy; 111qqz的小窝 2022<br><a href=https://beian.miit.gov.cn/>粤ICP备18103363号</a><br><a href=https://themes.gohugo.io/hugo-theme-cleanwhite>CleanWhite Hugo Theme</a> by <a href=https://zhaohuabing.com>Huabing</a> |
<iframe style=margin-left:2px;margin-bottom:-5px frameborder=0 scrolling=0 width=100px height=20px src="https://ghbtns.com/github-btn.html?user=zhaohuabing&repo=hugo-theme-cleanwhite&type=star&count=true"></iframe></p></div></div></div></footer><script>function async(u,c){var d=document,t='script',o=d.createElement(t),s=d.getElementsByTagName(t)[0];o.src=u;if(c){o.addEventListener('load',function(e){c(null,e);},false);}
s.parentNode.insertBefore(o,s);}</script><script>if($('#tag_cloud').length!==0){async("/js/jquery.tagcloud.js",function(){$.fn.tagcloud.defaults={color:{start:'#bbbbee',end:'#0085a1'},};$('#tag_cloud a').tagcloud();})}</script><script>async("https://cdnjs.cloudflare.com/ajax/libs/fastclick/1.0.6/fastclick.js",function(){var $nav=document.querySelector("nav");if($nav)FastClick.attach($nav);})</script></body></html>
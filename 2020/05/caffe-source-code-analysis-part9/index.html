<!doctype html><html lang=zh-cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta property="og:site_name" content="111qqz的小窝"><meta property="og:type" content="article"><meta property="og:image" content="https://111qqz.github.io/img/2.png"><meta property="twitter:image" content="https://111qqz.github.io/img/2.png"><meta name=title content="caffe 源码学习笔记(9) reduce layer"><meta property="og:title" content="caffe 源码学习笔记(9) reduce layer"><meta property="twitter:title" content="caffe 源码学习笔记(9) reduce layer"><meta name=description content><meta property="og:description" content><meta property="twitter:description" content><meta property="twitter:card" content="summary"><meta name=keyword content="ACM,111qqz,商汤科技,hust,华中科技大学"><link rel="shortcut icon" href=/img/favicon.ico><title>caffe 源码学习笔记(9) reduce layer-111qqz的小窝</title><link rel=canonical href=/2020/05/caffe-source-code-analysis-part9><link rel=stylesheet href=/css/iDisqus.min.css><link rel=stylesheet href=/css/bootstrap.min.css><link rel=stylesheet href=/css/hux-blog.min.css><link rel=stylesheet href=/css/syntax.css><link rel=stylesheet href=/css/zanshang.css><link href=//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css rel=stylesheet type=text/css><script src=/js/jquery.min.js></script><script src=/js/bootstrap.min.js></script><script src=/js/hux-blog.min.js></script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/styles/docco.min.css><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/highlight.min.js></script><script>hljs.initHighlightingOnLoad();</script><link rel=stylesheet href=/css/hux-blog.min.css><link rel=stylesheet href=/css/hux-blog.min-custom.css></head><nav class="navbar navbar-default navbar-custom navbar-fixed-top"><div class=container-fluid><div class="navbar-header page-scroll"><button type=button class=navbar-toggle>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span><span class=icon-bar></span><span class=icon-bar></span></button>
<a class=navbar-brand href=/>111qqz的小窝</a></div><div id=huxblog_navbar><div class=navbar-collapse><ul class="nav navbar-nav navbar-right"><li><a href=/>Home</a></li><li><a href=/categories/acm/>ACM-ICPC</a></li><li><a href=/categories/deep-learning/>深度学习</a></li><li><a href=/categories/mooc/>公开课</a></li><li><a href=/categories/%e5%85%b6%e4%bb%96/>其他</a></li><li><a href=/top/about/>ABOUT</a></li><li><a href=/search>SEARCH <img src=/img/search.png height=15 style=cursor:pointer alt=Search></a></li></ul></div></div></div></nav><script>var $body=document.body;var $toggle=document.querySelector('.navbar-toggle');var $navbar=document.querySelector('#huxblog_navbar');var $collapse=document.querySelector('.navbar-collapse');$toggle.addEventListener('click',handleMagic)
function handleMagic(e){if($navbar.className.indexOf('in')>0){$navbar.className=" ";setTimeout(function(){if($navbar.className.indexOf('in')<0){$collapse.style.height="0px"}},400)}else{$collapse.style.height="auto"
$navbar.className+=" in";}}</script><style type=text/css>header.intro-header{background-image:url(/img/2.png)}</style><header class=intro-header><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class=post-heading><div class=tags><a class=tag href=/tags/caffe title=caffe>caffe</a></div><h1>caffe 源码学习笔记(9) reduce layer</h1><h2 class=subheading></h2><span class=meta>Posted by
111qqz
on
Sunday, May 3, 2020</span></div></div></div></div></header><article><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2
col-md-10 col-md-offset-1
post-container"><header><h2>TOC</h2></header><nav id=TableOfContents><ol><li><a href=#背景>背景</a></li><li><a href=#proto>proto</a></li><li><a href=#c-代码>c++ 代码</a></li></ol></nav><h2 id=背景>背景</h2><p>其实没什么背景,继续啃caffe代码而已2333</p><p>reduce layer其实就是做reduce操作,把一个任意shape的blob通过某种运算变成一个scalar.</p><p>caffe目前支持求和(SUM),绝对值的和(ASUM),平方和(SUMSQ),以及对得到的scalar的总数求平均的求和(MEAN).</p><p>说句题外话,TensorRT支持的操作是求和,求积,max,min和ave. 还是有一些gap的</p><h2 id=proto>proto</h2><p>先看proto</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-protobuf data-lang=protobuf><span style=color:#960050;background-color:#1e0010>
</span><span style=color:#960050;background-color:#1e0010></span><span style=color:#66d9ef>message</span> <span style=color:#a6e22e>ReductionParameter</span> {<span style=color:#960050;background-color:#1e0010>
</span><span style=color:#960050;background-color:#1e0010></span>  <span style=color:#66d9ef>enum</span> ReductionOp {<span style=color:#960050;background-color:#1e0010>
</span><span style=color:#960050;background-color:#1e0010></span>    SUM <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>;<span style=color:#960050;background-color:#1e0010>
</span><span style=color:#960050;background-color:#1e0010></span>    ASUM <span style=color:#f92672>=</span> <span style=color:#ae81ff>2</span>;<span style=color:#960050;background-color:#1e0010>
</span><span style=color:#960050;background-color:#1e0010></span>    SUMSQ <span style=color:#f92672>=</span> <span style=color:#ae81ff>3</span>;<span style=color:#960050;background-color:#1e0010>
</span><span style=color:#960050;background-color:#1e0010></span>    MEAN <span style=color:#f92672>=</span> <span style=color:#ae81ff>4</span>;<span style=color:#960050;background-color:#1e0010>
</span><span style=color:#960050;background-color:#1e0010></span>  }<span style=color:#960050;background-color:#1e0010>
</span><span style=color:#960050;background-color:#1e0010></span><span style=color:#960050;background-color:#1e0010>
</span><span style=color:#960050;background-color:#1e0010></span>  <span style=color:#66d9ef>optional</span> ReductionOp operation <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span> [<span style=color:#66d9ef>default</span> <span style=color:#f92672>=</span> SUM]; <span style=color:#75715e>// reduction operation
</span><span style=color:#75715e></span><span style=color:#960050;background-color:#1e0010>
</span><span style=color:#960050;background-color:#1e0010></span>  <span style=color:#75715e>// The first axis to reduce to a scalar -- may be negative to index from the
</span><span style=color:#75715e></span>  <span style=color:#75715e>// end (e.g., -1 for the last axis).
</span><span style=color:#75715e></span>  <span style=color:#75715e>// (Currently, only reduction along ALL &#34;tail&#34; axes is supported; reduction
</span><span style=color:#75715e></span>  <span style=color:#75715e>// of axis M through N, where N &lt; num_axes - 1, is unsupported.)
</span><span style=color:#75715e></span>  <span style=color:#75715e>// Suppose we have an n-axis bottom Blob with shape:
</span><span style=color:#75715e></span>  <span style=color:#75715e>//     (d0, d1, d2, ..., d(m-1), dm, d(m+1), ..., d(n-1)).
</span><span style=color:#75715e></span>  <span style=color:#75715e>// If axis == m, the output Blob will have shape
</span><span style=color:#75715e></span>  <span style=color:#75715e>//     (d0, d1, d2, ..., d(m-1)),
</span><span style=color:#75715e></span>  <span style=color:#75715e>// and the ReductionOp operation is performed (d0 * d1 * d2 * ... * d(m-1))
</span><span style=color:#75715e></span>  <span style=color:#75715e>// times, each including (dm * d(m+1) * ... * d(n-1)) individual data.
</span><span style=color:#75715e></span>  <span style=color:#75715e>// If axis == 0 (the default), the output Blob always has the empty shape
</span><span style=color:#75715e></span>  <span style=color:#75715e>// (count 1), performing reduction across the entire input --
</span><span style=color:#75715e></span>  <span style=color:#75715e>// often useful for creating new loss functions.
</span><span style=color:#75715e></span>  <span style=color:#66d9ef>optional</span> <span style=color:#66d9ef>int32</span> axis <span style=color:#f92672>=</span> <span style=color:#ae81ff>2</span> [<span style=color:#66d9ef>default</span> <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>];<span style=color:#960050;background-color:#1e0010>
</span><span style=color:#960050;background-color:#1e0010></span><span style=color:#960050;background-color:#1e0010>
</span><span style=color:#960050;background-color:#1e0010></span>  <span style=color:#66d9ef>optional</span> <span style=color:#66d9ef>float</span> coeff <span style=color:#f92672>=</span> <span style=color:#ae81ff>3</span> [<span style=color:#66d9ef>default</span> <span style=color:#f92672>=</span> <span style=color:#ae81ff>1.0</span>]; <span style=color:#75715e>// coefficient for output
</span><span style=color:#75715e></span>}<span style=color:#960050;background-color:#1e0010>
</span><span style=color:#960050;background-color:#1e0010></span><span style=color:#960050;background-color:#1e0010>
</span></code></pre></div><p>operation不用说,表示要进行哪种reduce操作.
coeff也比较简单,就是最后结果中每个元素都可以乘一个额外的系数,默认是1.</p><p>axis的含义是,从axis这个维度开始做reduce.</p><p>比如blob的shape是(a,b,c,axis,d,e)</p><p>那么就需要对 (axis,d,e)这部分做a*b*c次reduce,得到 a*b*c个标量.</p><p><strong>需要注意,目前只支持从某个维度一直到最后的维度都去做reduce,不支持中间的几个维度去做reduce</strong></p><h2 id=c-代码>c++ 代码</h2><p>头文件中有两个成员变量num_,dim_值得一说</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c++ data-lang=c++>
<span style=color:#66d9ef>template</span> <span style=color:#f92672>&lt;</span><span style=color:#66d9ef>typename</span> Dtype<span style=color:#f92672>&gt;</span>
<span style=color:#66d9ef>class</span> <span style=color:#a6e22e>ReductionLayer</span> <span style=color:#f92672>:</span> <span style=color:#66d9ef>public</span> Layer<span style=color:#f92672>&lt;</span>Dtype<span style=color:#f92672>&gt;</span> {
 <span style=color:#66d9ef>public</span><span style=color:#f92672>:</span>
<span style=color:#75715e>//    ...省略无关部分
</span><span style=color:#75715e></span>
  <span style=color:#75715e>/// @brief the reduction operation performed by the layer
</span><span style=color:#75715e></span>  ReductionParameter_ReductionOp op_;
  <span style=color:#75715e>/// @brief a scalar coefficient applied to all outputs
</span><span style=color:#75715e></span>  Dtype coeff_;
  <span style=color:#75715e>/// @brief the index of the first input axis to reduce
</span><span style=color:#75715e></span>  <span style=color:#66d9ef>int</span> axis_;
  <span style=color:#75715e>/// @brief the number of reductions performed
</span><span style=color:#75715e></span>  <span style=color:#66d9ef>int</span> num_;
  <span style=color:#75715e>/// @brief the input size of each reduction
</span><span style=color:#75715e></span>  <span style=color:#66d9ef>int</span> dim_;
  <span style=color:#75715e>/// @brief a helper Blob used for summation (op_ == SUM)
</span><span style=color:#75715e></span>  Blob<span style=color:#f92672>&lt;</span>Dtype<span style=color:#f92672>&gt;</span> sum_multiplier_;
};


num_表示的是要做reduce操作的次数
dim_表示的是每次reduce的维度部分的count

Reshape部分,<span style=color:#960050;background-color:#1e0010>主</span><span style=color:#960050;background-color:#1e0010>要</span><span style=color:#960050;background-color:#1e0010>就</span><span style=color:#960050;background-color:#1e0010>是</span><span style=color:#960050;background-color:#1e0010>计</span><span style=color:#960050;background-color:#1e0010>算</span><span style=color:#960050;background-color:#1e0010>了</span><span style=color:#960050;background-color:#1e0010>几</span><span style=color:#960050;background-color:#1e0010>个</span><span style=color:#960050;background-color:#1e0010>成</span><span style=color:#960050;background-color:#1e0010>员</span><span style=color:#960050;background-color:#1e0010>变</span><span style=color:#960050;background-color:#1e0010>量</span> num_,dim_,coeff_
<span style=color:#960050;background-color:#1e0010>`</span><span style=color:#960050;background-color:#1e0010>`</span><span style=color:#960050;background-color:#1e0010>`</span>c<span style=color:#f92672>+</span><span style=color:#f92672>+</span>

<span style=color:#66d9ef>template</span> <span style=color:#f92672>&lt;</span><span style=color:#66d9ef>typename</span> Dtype<span style=color:#f92672>&gt;</span>
<span style=color:#66d9ef>void</span> ReductionLayer<span style=color:#f92672>&lt;</span>Dtype<span style=color:#f92672>&gt;</span><span style=color:#f92672>:</span><span style=color:#f92672>:</span>Reshape(<span style=color:#66d9ef>const</span> vector<span style=color:#f92672>&lt;</span>Blob<span style=color:#f92672>&lt;</span>Dtype<span style=color:#f92672>&gt;</span><span style=color:#f92672>*</span><span style=color:#f92672>&gt;</span><span style=color:#f92672>&amp;</span> bottom,
      <span style=color:#66d9ef>const</span> vector<span style=color:#f92672>&lt;</span>Blob<span style=color:#f92672>&lt;</span>Dtype<span style=color:#f92672>&gt;</span><span style=color:#f92672>*</span><span style=color:#f92672>&gt;</span><span style=color:#f92672>&amp;</span> top) {
  axis_ <span style=color:#f92672>=</span> bottom[<span style=color:#ae81ff>0</span>]<span style=color:#f92672>-</span><span style=color:#f92672>&gt;</span>CanonicalAxisIndex(
      <span style=color:#66d9ef>this</span><span style=color:#f92672>-</span><span style=color:#f92672>&gt;</span>layer_param_.reduction_param().axis());
  <span style=color:#75715e>// In the output, we&#39;ll keep all axes up to the reduction axis, but
</span><span style=color:#75715e></span>  <span style=color:#75715e>// throw away any after that.
</span><span style=color:#75715e></span>  <span style=color:#75715e>// Note: currently reducing along non-tail axes is not supported; otherwise,
</span><span style=color:#75715e></span>  <span style=color:#75715e>// we&#39;d need to also copy any axes following an &#34;end_axis&#34;.
</span><span style=color:#75715e></span>  vector<span style=color:#f92672>&lt;</span><span style=color:#66d9ef>int</span><span style=color:#f92672>&gt;</span> top_shape(bottom[<span style=color:#ae81ff>0</span>]<span style=color:#f92672>-</span><span style=color:#f92672>&gt;</span>shape().begin(),
                        bottom[<span style=color:#ae81ff>0</span>]<span style=color:#f92672>-</span><span style=color:#f92672>&gt;</span>shape().begin() <span style=color:#f92672>+</span> axis_);
  top[<span style=color:#ae81ff>0</span>]<span style=color:#f92672>-</span><span style=color:#f92672>&gt;</span>Reshape(top_shape);
  <span style=color:#75715e>//  count都是左闭又开,一个参数就是到末尾
</span><span style=color:#75715e></span>  num_ <span style=color:#f92672>=</span> bottom[<span style=color:#ae81ff>0</span>]<span style=color:#f92672>-</span><span style=color:#f92672>&gt;</span>count(<span style=color:#ae81ff>0</span>, axis_);
  <span style=color:#75715e>//  num_表示的是要做reduce操作的次数
</span><span style=color:#75715e></span>  <span style=color:#75715e>//  range [0,axis_)
</span><span style=color:#75715e></span>  dim_ <span style=color:#f92672>=</span> bottom[<span style=color:#ae81ff>0</span>]<span style=color:#f92672>-</span><span style=color:#f92672>&gt;</span>count(axis_);
  <span style=color:#75715e>//  dim_表示的是reduce操作部分的count
</span><span style=color:#75715e></span>  <span style=color:#75715e>//  range [axis_,num_axes())
</span><span style=color:#75715e></span>  CHECK_EQ(num_, top[<span style=color:#ae81ff>0</span>]<span style=color:#f92672>-</span><span style=color:#f92672>&gt;</span>count());
  <span style=color:#66d9ef>if</span> (op_ <span style=color:#f92672>=</span><span style=color:#f92672>=</span> ReductionParameter_ReductionOp_SUM <span style=color:#f92672>|</span><span style=color:#f92672>|</span>
      op_ <span style=color:#f92672>=</span><span style=color:#f92672>=</span> ReductionParameter_ReductionOp_MEAN) {
    vector<span style=color:#f92672>&lt;</span><span style=color:#66d9ef>int</span><span style=color:#f92672>&gt;</span> sum_mult_shape(<span style=color:#ae81ff>1</span>, dim_);
    <span style=color:#75715e>// sum_mult_shape[0] = dim_
</span><span style=color:#75715e></span>    sum_multiplier_.Reshape(sum_mult_shape);

    caffe_set(dim_, Dtype(<span style=color:#ae81ff>1</span>), sum_multiplier_.mutable_cpu_data());
    <span style=color:#75715e>// sum_multiplier_是dim_长度的vector,值都为1
</span><span style=color:#75715e></span>  }
  coeff_ <span style=color:#f92672>=</span> <span style=color:#66d9ef>this</span><span style=color:#f92672>-</span><span style=color:#f92672>&gt;</span>layer_param().reduction_param().coeff();
  <span style=color:#66d9ef>if</span> (op_ <span style=color:#f92672>=</span><span style=color:#f92672>=</span> ReductionParameter_ReductionOp_MEAN) {
    coeff_ <span style=color:#f92672>/</span><span style=color:#f92672>=</span> dim_;
  }
}

</code></pre></div><p>注意到求和的计算是通过构造了一个dim_长度的都是为1的向量来和bottom做点积实现的.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c++ data-lang=c++>
<span style=color:#66d9ef>template</span> <span style=color:#f92672>&lt;</span><span style=color:#66d9ef>typename</span> Dtype<span style=color:#f92672>&gt;</span>
<span style=color:#66d9ef>void</span> ReductionLayer<span style=color:#f92672>&lt;</span>Dtype<span style=color:#f92672>&gt;</span><span style=color:#f92672>:</span><span style=color:#f92672>:</span>Forward_cpu(
    <span style=color:#66d9ef>const</span> vector<span style=color:#f92672>&lt;</span>Blob<span style=color:#f92672>&lt;</span>Dtype<span style=color:#f92672>&gt;</span><span style=color:#f92672>*</span><span style=color:#f92672>&gt;</span><span style=color:#f92672>&amp;</span> bottom, <span style=color:#66d9ef>const</span> vector<span style=color:#f92672>&lt;</span>Blob<span style=color:#f92672>&lt;</span>Dtype<span style=color:#f92672>&gt;</span><span style=color:#f92672>*</span><span style=color:#f92672>&gt;</span><span style=color:#f92672>&amp;</span> top) {
  <span style=color:#66d9ef>const</span> Dtype<span style=color:#f92672>*</span> bottom_data <span style=color:#f92672>=</span> bottom[<span style=color:#ae81ff>0</span>]<span style=color:#f92672>-</span><span style=color:#f92672>&gt;</span>cpu_data();
  <span style=color:#66d9ef>const</span> Dtype<span style=color:#f92672>*</span> mult_data <span style=color:#f92672>=</span> NULL;
  <span style=color:#66d9ef>if</span> (sum_multiplier_.count() <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>0</span>) {
    mult_data <span style=color:#f92672>=</span> sum_multiplier_.cpu_data();
  }
  Dtype<span style=color:#f92672>*</span> top_data <span style=color:#f92672>=</span> top[<span style=color:#ae81ff>0</span>]<span style=color:#f92672>-</span><span style=color:#f92672>&gt;</span>mutable_cpu_data();
  <span style=color:#75715e>// 得到num_个结果
</span><span style=color:#75715e></span>  <span style=color:#66d9ef>for</span> (<span style=color:#66d9ef>int</span> i <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; i <span style=color:#f92672>&lt;</span> num_; <span style=color:#f92672>+</span><span style=color:#f92672>+</span>i) {
    <span style=color:#66d9ef>switch</span> (op_) {
    <span style=color:#66d9ef>case</span> ReductionParameter_ReductionOp_SUM:
    <span style=color:#66d9ef>case</span> ReductionParameter_ReductionOp_MEAN:
      <span style=color:#f92672>*</span>top_data <span style=color:#f92672>=</span> caffe_cpu_dot(dim_, mult_data, bottom_data);
      <span style=color:#66d9ef>break</span>;
    <span style=color:#66d9ef>case</span> ReductionParameter_ReductionOp_ASUM:
      <span style=color:#f92672>*</span>top_data <span style=color:#f92672>=</span> caffe_cpu_asum(dim_, bottom_data);
      <span style=color:#66d9ef>break</span>;
    <span style=color:#66d9ef>case</span> ReductionParameter_ReductionOp_SUMSQ:
      <span style=color:#f92672>*</span>top_data <span style=color:#f92672>=</span> caffe_cpu_dot(dim_, bottom_data, bottom_data);
      <span style=color:#66d9ef>break</span>;
    <span style=color:#66d9ef>default</span><span style=color:#f92672>:</span>
      LOG(FATAL) <span style=color:#f92672>&lt;</span><span style=color:#f92672>&lt;</span> <span style=color:#e6db74></span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>Unknown reduction op: </span><span style=color:#e6db74>&#34;</span>
          <span style=color:#f92672>&lt;</span><span style=color:#f92672>&lt;</span> ReductionParameter_ReductionOp_Name(op_);
    }
    bottom_data <span style=color:#f92672>+</span><span style=color:#f92672>=</span> dim_;
    <span style=color:#f92672>+</span><span style=color:#f92672>+</span>top_data;
  }
  <span style=color:#75715e>//  coeff_是每一个位置的系数,默认为1
</span><span style=color:#75715e></span>  <span style=color:#75715e>//  此时才真的把系数放在每一个元素上
</span><span style=color:#75715e></span>  <span style=color:#66d9ef>if</span> (coeff_ <span style=color:#f92672>!</span><span style=color:#f92672>=</span> Dtype(<span style=color:#ae81ff>1</span>)) {
    <span style=color:#75715e>// Reset the top_data pointer.
</span><span style=color:#75715e></span>    top_data <span style=color:#f92672>=</span> top[<span style=color:#ae81ff>0</span>]<span style=color:#f92672>-</span><span style=color:#f92672>&gt;</span>mutable_cpu_data();
    caffe_scal(num_, coeff_, top_data);
  }
}
</code></pre></div><div class="entry-shang text-center"><p>「真诚赞赏，手留余香」</p><button class="zs show-zs btn btn-bred">赞赏支持</button></div><div class=zs-modal-bg></div><div class=zs-modal-box><div class=zs-modal-head><button type=button class=close>×</button>
<span class=author><a href=https://111qqz.github.io><img src=/img/favicon.png>111qqz的小窝</a></span><p class=tip><i></i><span>真诚赞赏，手留余香</span></p></div><div class=zs-modal-body><div class=zs-modal-btns><button class="btn btn-blink" data-num=2>2元</button>
<button class="btn btn-blink" data-num=5>5元</button>
<button class="btn btn-blink" data-num=10>10元</button>
<button class="btn btn-blink" data-num=50>50元</button>
<button class="btn btn-blink" data-num=100>100元</button>
<button class="btn btn-blink" data-num=1>任意金额</button></div><div class=zs-modal-pay><button class="btn btn-bred" id=pay-text>2元</button><p>使用<span id=pay-type>微信</span>扫描二维码完成支付</p><img src=/img/reward/wechat-2.png id=pay-image></div></div><div class=zs-modal-footer><label><input type=radio name=zs-type value=wechat class=zs-type checked><span><span class=zs-wechat><img src=/img/reward/wechat-btn.png></span></label>
<label><input type=radio name=zs-type value=alipay class=zs-type class=zs-alipay><img src=/img/reward/alipay-btn.png></span></label></div></div><script type=text/javascript src=/js/reward.js></script><hr><ul class=pager><li class=previous><a href=/2020/05/retinanet-notes data-toggle=tooltip data-placement=top title="Focal Loss for Dense Object Detection(RetinaNet) 学习笔记">&larr;
Previous Post</a></li><li class=next><a href=/2020/05/caffe-source-code-analysis-part10 data-toggle=tooltip data-placement=top title="caffe 源码学习笔记(10) eltwise layer">Next
Post &rarr;</a></li></ul><div id=git-comments></div><link rel=stylesheet href=https://imsun.github.io/gitment/style/default.css><script src=https://ihtcboy.com/script/gitment.browser.js></script><script>var gitment=new Gitment({id:decodeURI(window.location.pathname),owner:'111qqz',repo:'111qqz.github.io',oauth:{client_id:'8839ce5e58d5197e2490',client_secret:'2d475a8a7e27a8b509847a6c60f692b8cbaa274e',}})
gitment.render('git-comments')</script></div><div class="col-lg-8 col-lg-offset-2
col-md-10 col-md-offset-1
sidebar-container"><section><hr class="hidden-sm hidden-xs"><h5><a href=/tags/>FEATURED TAGS</a></h5><div class=tags><a href=/tags/bfs title=bfs>bfs</a>
<a href=/tags/binary-search title=binary-search>binary-search</a>
<a href=/tags/brute-force title=brute-force>brute-force</a>
<a href=/tags/c++ title=c++>c++</a>
<a href=/tags/caffe title=caffe>caffe</a>
<a href=/tags/dfs title=dfs>dfs</a>
<a href=/tags/dp title=dp>dp</a>
<a href=/tags/greedy title=greedy>greedy</a>
<a href=/tags/hash title=hash>hash</a>
<a href=/tags/km title=km>km</a>
<a href=/tags/kmp title=kmp>kmp</a>
<a href=/tags/leetcode title=leetcode>leetcode</a>
<a href=/tags/math title=math>math</a>
<a href=/tags/number-theory title=number-theory>number-theory</a>
<a href=/tags/rmq title=rmq>rmq</a>
<a href=/tags/sg%E5%87%BD%E6%95%B0 title=sg函数>sg函数</a>
<a href=/tags/stl title=stl>stl</a>
<a href=/tags/tensorflow title=tensorflow>tensorflow</a>
<a href=/tags/%E4%BA%8C%E5%88%86%E5%9B%BE%E6%9C%80%E4%BD%B3%E5%8C%B9%E9%85%8D title=二分图最佳匹配>二分图最佳匹配</a>
<a href=/tags/%E5%88%86%E5%9D%97 title=分块>分块</a>
<a href=/tags/%E5%89%8D%E7%BC%80%E5%92%8C title=前缀和>前缀和</a>
<a href=/tags/%E5%8C%88%E7%89%99%E5%88%A9%E7%AE%97%E6%B3%95 title=匈牙利算法>匈牙利算法</a>
<a href=/tags/%E5%8C%BA%E9%97%B4dp title=区间dp>区间dp</a>
<a href=/tags/%E5%8D%9A%E5%BC%88%E8%AE%BA title=博弈论>博弈论</a>
<a href=/tags/%E5%90%8E%E7%BC%80%E8%87%AA%E5%8A%A8%E6%9C%BA title=后缀自动机>后缀自动机</a>
<a href=/tags/%E5%9B%BE%E8%AE%BA title=图论>图论</a>
<a href=/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2 title=字符串>字符串</a>
<a href=/tags/%E5%BF%AB%E9%80%9F%E5%B9%82 title=快速幂>快速幂</a>
<a href=/tags/%E6%95%B0%E4%BD%8Ddp title=数位dp>数位dp</a>
<a href=/tags/%E6%9E%84%E9%80%A0 title=构造>构造</a>
<a href=/tags/%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84 title=树状数组>树状数组</a>
<a href=/tags/%E6%A6%82%E7%8E%87 title=概率>概率</a>
<a href=/tags/%E6%A8%A1%E6%8B%9F title=模拟>模拟</a>
<a href=/tags/%E6%AF%8D%E5%87%BD%E6%95%B0 title=母函数>母函数</a>
<a href=/tags/%E7%9F%A9%E9%98%B5 title=矩阵>矩阵</a>
<a href=/tags/%E7%A6%BB%E6%95%A3%E5%8C%96 title=离散化>离散化</a>
<a href=/tags/%E7%BA%BF%E6%AE%B5%E6%A0%91 title=线段树>线段树</a>
<a href=/tags/%E8%AE%A1%E7%AE%97%E5%87%A0%E4%BD%95 title=计算几何>计算几何</a></div></section><section><hr><h5>FRIENDS</h5><ul class=list-inline><li><a target=_blank href=https://111qqz.com>111qqz的wordpress博客</a></li></ul></section></div></div></div></article><footer><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><ul class="list-inline text-center"><li><a href rel=alternate type=application/rss+xml title=111qqz的小窝><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-rss fa-stack-1x fa-inverse"></i></span></a></li><li><a href=mailto:hust.111qqz@gmail.com><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-envelope fa-stack-1x fa-inverse"></i></span></a></li><li><a target=_blank href=/img/wechat.jpg><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-wechat fa-stack-1x fa-inverse"></i></span></a></li><li><a target=_blank href=https://github.com/111qqz/><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-github fa-stack-1x fa-inverse"></i></span></a></li></ul><p class="copyright text-muted">Copyright &copy; 111qqz的小窝 2021<br><a href=https://themes.gohugo.io/hugo-theme-cleanwhite>CleanWhite Hugo Theme</a> by <a href=https://zhaohuabing.com>Huabing</a> |
<iframe style=margin-left:2px;margin-bottom:-5px frameborder=0 scrolling=0 width=100px height=20px src="https://ghbtns.com/github-btn.html?user=zhaohuabing&repo=hugo-theme-cleanwhite&type=star&count=true"></iframe></p></div></div></div></footer><script>function async(u,c){var d=document,t='script',o=d.createElement(t),s=d.getElementsByTagName(t)[0];o.src=u;if(c){o.addEventListener('load',function(e){c(null,e);},false);}
s.parentNode.insertBefore(o,s);}</script><script>if($('#tag_cloud').length!==0){async("/js/jquery.tagcloud.js",function(){$.fn.tagcloud.defaults={color:{start:'#bbbbee',end:'#0085a1'},};$('#tag_cloud a').tagcloud();})}</script><script>async("https://cdnjs.cloudflare.com/ajax/libs/fastclick/1.0.6/fastclick.js",function(){var $nav=document.querySelector("nav");if($nav)FastClick.attach($nav);})</script></body></html>